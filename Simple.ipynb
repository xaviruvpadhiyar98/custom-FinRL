{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from YahooDownloader import YahooDownloader\n",
    "from envs.StockTradingEnv import StockTradingEnv\n",
    "from FeatureEngineer import FeatureEngineer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from agents.stablebaselines3.models import DRLAgent\n",
    "from pathlib import Path\n",
    "import config\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use(\"Agg\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dirs\n",
    "\n",
    "for dir in config.DIRS:\n",
    "    Path(dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n",
      "Shape of DataFrame: (2474, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>1495.785400</td>\n",
       "      <td>1528.226194</td>\n",
       "      <td>1490.494022</td>\n",
       "      <td>1521.104983</td>\n",
       "      <td>501708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>1096.644165</td>\n",
       "      <td>1112.422026</td>\n",
       "      <td>1091.088796</td>\n",
       "      <td>1091.088796</td>\n",
       "      <td>1908002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>1524.962158</td>\n",
       "      <td>1560.122829</td>\n",
       "      <td>1498.406269</td>\n",
       "      <td>1503.005362</td>\n",
       "      <td>2655273</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>1115.427490</td>\n",
       "      <td>1120.163095</td>\n",
       "      <td>1099.717886</td>\n",
       "      <td>1099.899982</td>\n",
       "      <td>3915576</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>1577.876343</td>\n",
       "      <td>1590.387813</td>\n",
       "      <td>1530.154818</td>\n",
       "      <td>1534.012126</td>\n",
       "      <td>2169635</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>2022-07-14</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>2998.750000</td>\n",
       "      <td>3057.000000</td>\n",
       "      <td>2967.000000</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>4764908</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>5915.200195</td>\n",
       "      <td>5928.250000</td>\n",
       "      <td>5812.850098</td>\n",
       "      <td>5855.000000</td>\n",
       "      <td>569859</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>2994.600098</td>\n",
       "      <td>3028.899902</td>\n",
       "      <td>2953.000000</td>\n",
       "      <td>3018.550049</td>\n",
       "      <td>4574806</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>6059.799805</td>\n",
       "      <td>6068.100098</td>\n",
       "      <td>5931.350098</td>\n",
       "      <td>5969.899902</td>\n",
       "      <td>966155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>3063.500000</td>\n",
       "      <td>3076.949951</td>\n",
       "      <td>3014.300049</td>\n",
       "      <td>3023.000000</td>\n",
       "      <td>3201850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2474 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date            tic        close         high          low  \\\n",
       "0     2017-07-18  BAJFINANCE.NS  1495.785400  1528.226194  1490.494022   \n",
       "1     2017-07-18         TCS.NS  1096.644165  1112.422026  1091.088796   \n",
       "2     2017-07-19  BAJFINANCE.NS  1524.962158  1560.122829  1498.406269   \n",
       "3     2017-07-19         TCS.NS  1115.427490  1120.163095  1099.717886   \n",
       "4     2017-07-20  BAJFINANCE.NS  1577.876343  1590.387813  1530.154818   \n",
       "...          ...            ...          ...          ...          ...   \n",
       "2469  2022-07-14         TCS.NS  2998.750000  3057.000000  2967.000000   \n",
       "2470  2022-07-15  BAJFINANCE.NS  5915.200195  5928.250000  5812.850098   \n",
       "2471  2022-07-15         TCS.NS  2994.600098  3028.899902  2953.000000   \n",
       "2472  2022-07-18  BAJFINANCE.NS  6059.799805  6068.100098  5931.350098   \n",
       "2473  2022-07-18         TCS.NS  3063.500000  3076.949951  3014.300049   \n",
       "\n",
       "             open   volume  day  \n",
       "0     1521.104983   501708    1  \n",
       "1     1091.088796  1908002    1  \n",
       "2     1503.005362  2655273    2  \n",
       "3     1099.899982  3915576    2  \n",
       "4     1534.012126  2169635    3  \n",
       "...           ...      ...  ...  \n",
       "2469  3056.000000  4764908    3  \n",
       "2470  5855.000000   569859    4  \n",
       "2471  3018.550049  4574806    4  \n",
       "2472  5969.899902   966155    0  \n",
       "2473  3023.000000  3201850    0  \n",
       "\n",
       "[2474 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = [\"TCS.NS\",\"BAJFINANCE.NS\"]\n",
    "# tickers = [\"BAJFINANCE.NS\"]\n",
    "df = YahooDownloader(tickers=tickers).download_data().post_process()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>sma_30</th>\n",
       "      <th>sma_60</th>\n",
       "      <th>ema_8</th>\n",
       "      <th>ema_21</th>\n",
       "      <th>macd</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>rsi_70</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>1941.697266</td>\n",
       "      <td>1964.148708</td>\n",
       "      <td>1850.655550</td>\n",
       "      <td>1859.408593</td>\n",
       "      <td>4271734</td>\n",
       "      <td>3</td>\n",
       "      <td>1449.144971</td>\n",
       "      <td>1433.447021</td>\n",
       "      <td>1536.559197</td>\n",
       "      <td>1481.452241</td>\n",
       "      <td>37.085981</td>\n",
       "      <td>51.375125</td>\n",
       "      <td>50.566001</td>\n",
       "      <td>5.543868</td>\n",
       "      <td>100.247713</td>\n",
       "      <td>2211.754829</td>\n",
       "      <td>776.299954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>1123.364990</td>\n",
       "      <td>1127.154962</td>\n",
       "      <td>1119.232432</td>\n",
       "      <td>1122.406015</td>\n",
       "      <td>870636</td>\n",
       "      <td>3</td>\n",
       "      <td>1448.654073</td>\n",
       "      <td>1432.599198</td>\n",
       "      <td>1444.738262</td>\n",
       "      <td>1448.898855</td>\n",
       "      <td>3.532069</td>\n",
       "      <td>49.046142</td>\n",
       "      <td>49.522296</td>\n",
       "      <td>1.210606</td>\n",
       "      <td>-68.992014</td>\n",
       "      <td>2236.894709</td>\n",
       "      <td>733.709664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>1870.485718</td>\n",
       "      <td>1953.318408</td>\n",
       "      <td>1860.397486</td>\n",
       "      <td>1948.422673</td>\n",
       "      <td>2856329</td>\n",
       "      <td>4</td>\n",
       "      <td>1454.009757</td>\n",
       "      <td>1435.962779</td>\n",
       "      <td>1539.348808</td>\n",
       "      <td>1487.224933</td>\n",
       "      <td>36.802514</td>\n",
       "      <td>51.138170</td>\n",
       "      <td>50.469197</td>\n",
       "      <td>5.732939</td>\n",
       "      <td>92.077751</td>\n",
       "      <td>2265.687403</td>\n",
       "      <td>766.901567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>1128.160034</td>\n",
       "      <td>1129.712545</td>\n",
       "      <td>1119.917768</td>\n",
       "      <td>1120.465706</td>\n",
       "      <td>1021134</td>\n",
       "      <td>4</td>\n",
       "      <td>1453.780684</td>\n",
       "      <td>1435.312834</td>\n",
       "      <td>1447.973525</td>\n",
       "      <td>1454.582670</td>\n",
       "      <td>3.232837</td>\n",
       "      <td>49.067498</td>\n",
       "      <td>49.532609</td>\n",
       "      <td>1.427871</td>\n",
       "      <td>-68.270763</td>\n",
       "      <td>2265.357211</td>\n",
       "      <td>729.929032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-11</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>1899.415405</td>\n",
       "      <td>1914.251111</td>\n",
       "      <td>1877.260847</td>\n",
       "      <td>1879.189441</td>\n",
       "      <td>1098804</td>\n",
       "      <td>0</td>\n",
       "      <td>1460.885335</td>\n",
       "      <td>1439.287154</td>\n",
       "      <td>1548.293943</td>\n",
       "      <td>1495.022009</td>\n",
       "      <td>38.419611</td>\n",
       "      <td>51.191657</td>\n",
       "      <td>50.500827</td>\n",
       "      <td>5.638889</td>\n",
       "      <td>89.108563</td>\n",
       "      <td>2288.148142</td>\n",
       "      <td>760.681178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>2022-07-14</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>2998.750000</td>\n",
       "      <td>3057.000000</td>\n",
       "      <td>2967.000000</td>\n",
       "      <td>3056.000000</td>\n",
       "      <td>4764908</td>\n",
       "      <td>3</td>\n",
       "      <td>4460.650635</td>\n",
       "      <td>4446.844592</td>\n",
       "      <td>4281.323820</td>\n",
       "      <td>4401.866931</td>\n",
       "      <td>-61.297325</td>\n",
       "      <td>48.994083</td>\n",
       "      <td>49.548551</td>\n",
       "      <td>0.286303</td>\n",
       "      <td>-78.125898</td>\n",
       "      <td>7169.210360</td>\n",
       "      <td>1642.890699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>5915.200195</td>\n",
       "      <td>5928.250000</td>\n",
       "      <td>5812.850098</td>\n",
       "      <td>5855.000000</td>\n",
       "      <td>569859</td>\n",
       "      <td>4</td>\n",
       "      <td>4472.241374</td>\n",
       "      <td>4445.325753</td>\n",
       "      <td>4644.407459</td>\n",
       "      <td>4539.442682</td>\n",
       "      <td>68.028367</td>\n",
       "      <td>50.953533</td>\n",
       "      <td>50.333868</td>\n",
       "      <td>3.523310</td>\n",
       "      <td>75.146501</td>\n",
       "      <td>7288.785011</td>\n",
       "      <td>1682.726976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>2994.600098</td>\n",
       "      <td>3028.899902</td>\n",
       "      <td>2953.000000</td>\n",
       "      <td>3018.550049</td>\n",
       "      <td>4574806</td>\n",
       "      <td>4</td>\n",
       "      <td>4462.580363</td>\n",
       "      <td>4438.050871</td>\n",
       "      <td>4277.783601</td>\n",
       "      <td>4399.002447</td>\n",
       "      <td>-64.405682</td>\n",
       "      <td>49.003329</td>\n",
       "      <td>49.550287</td>\n",
       "      <td>0.376095</td>\n",
       "      <td>-77.670007</td>\n",
       "      <td>7201.576530</td>\n",
       "      <td>1586.125380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>BAJFINANCE.NS</td>\n",
       "      <td>6059.799805</td>\n",
       "      <td>6068.100098</td>\n",
       "      <td>5931.350098</td>\n",
       "      <td>5969.899902</td>\n",
       "      <td>966155</td>\n",
       "      <td>0</td>\n",
       "      <td>4477.215877</td>\n",
       "      <td>4439.061597</td>\n",
       "      <td>4673.787202</td>\n",
       "      <td>4549.984025</td>\n",
       "      <td>77.086772</td>\n",
       "      <td>51.037913</td>\n",
       "      <td>50.372868</td>\n",
       "      <td>3.615149</td>\n",
       "      <td>80.656999</td>\n",
       "      <td>7382.808127</td>\n",
       "      <td>1616.887502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>TCS.NS</td>\n",
       "      <td>3063.500000</td>\n",
       "      <td>3076.949951</td>\n",
       "      <td>3014.300049</td>\n",
       "      <td>3023.000000</td>\n",
       "      <td>3201850</td>\n",
       "      <td>0</td>\n",
       "      <td>4469.133431</td>\n",
       "      <td>4433.087972</td>\n",
       "      <td>4315.945601</td>\n",
       "      <td>4414.849114</td>\n",
       "      <td>-51.956866</td>\n",
       "      <td>49.058669</td>\n",
       "      <td>49.571327</td>\n",
       "      <td>0.320285</td>\n",
       "      <td>-73.473000</td>\n",
       "      <td>7343.356190</td>\n",
       "      <td>1522.514499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2404 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date            tic        close         high          low  \\\n",
       "0     2017-09-07  BAJFINANCE.NS  1941.697266  1964.148708  1850.655550   \n",
       "0     2017-09-07         TCS.NS  1123.364990  1127.154962  1119.232432   \n",
       "1     2017-09-08  BAJFINANCE.NS  1870.485718  1953.318408  1860.397486   \n",
       "1     2017-09-08         TCS.NS  1128.160034  1129.712545  1119.917768   \n",
       "2     2017-09-11  BAJFINANCE.NS  1899.415405  1914.251111  1877.260847   \n",
       "...          ...            ...          ...          ...          ...   \n",
       "1199  2022-07-14         TCS.NS  2998.750000  3057.000000  2967.000000   \n",
       "1200  2022-07-15  BAJFINANCE.NS  5915.200195  5928.250000  5812.850098   \n",
       "1200  2022-07-15         TCS.NS  2994.600098  3028.899902  2953.000000   \n",
       "1201  2022-07-18  BAJFINANCE.NS  6059.799805  6068.100098  5931.350098   \n",
       "1201  2022-07-18         TCS.NS  3063.500000  3076.949951  3014.300049   \n",
       "\n",
       "             open   volume  day       sma_30       sma_60        ema_8  \\\n",
       "0     1859.408593  4271734    3  1449.144971  1433.447021  1536.559197   \n",
       "0     1122.406015   870636    3  1448.654073  1432.599198  1444.738262   \n",
       "1     1948.422673  2856329    4  1454.009757  1435.962779  1539.348808   \n",
       "1     1120.465706  1021134    4  1453.780684  1435.312834  1447.973525   \n",
       "2     1879.189441  1098804    0  1460.885335  1439.287154  1548.293943   \n",
       "...           ...      ...  ...          ...          ...          ...   \n",
       "1199  3056.000000  4764908    3  4460.650635  4446.844592  4281.323820   \n",
       "1200  5855.000000   569859    4  4472.241374  4445.325753  4644.407459   \n",
       "1200  3018.550049  4574806    4  4462.580363  4438.050871  4277.783601   \n",
       "1201  5969.899902   966155    0  4477.215877  4439.061597  4673.787202   \n",
       "1201  3023.000000  3201850    0  4469.133431  4433.087972  4315.945601   \n",
       "\n",
       "           ema_21       macd     rsi_30     rsi_70     dx_30      cci_30  \\\n",
       "0     1481.452241  37.085981  51.375125  50.566001  5.543868  100.247713   \n",
       "0     1448.898855   3.532069  49.046142  49.522296  1.210606  -68.992014   \n",
       "1     1487.224933  36.802514  51.138170  50.469197  5.732939   92.077751   \n",
       "1     1454.582670   3.232837  49.067498  49.532609  1.427871  -68.270763   \n",
       "2     1495.022009  38.419611  51.191657  50.500827  5.638889   89.108563   \n",
       "...           ...        ...        ...        ...       ...         ...   \n",
       "1199  4401.866931 -61.297325  48.994083  49.548551  0.286303  -78.125898   \n",
       "1200  4539.442682  68.028367  50.953533  50.333868  3.523310   75.146501   \n",
       "1200  4399.002447 -64.405682  49.003329  49.550287  0.376095  -77.670007   \n",
       "1201  4549.984025  77.086772  51.037913  50.372868  3.615149   80.656999   \n",
       "1201  4414.849114 -51.956866  49.058669  49.571327  0.320285  -73.473000   \n",
       "\n",
       "          boll_ub      boll_lb  \n",
       "0     2211.754829   776.299954  \n",
       "0     2236.894709   733.709664  \n",
       "1     2265.687403   766.901567  \n",
       "1     2265.357211   729.929032  \n",
       "2     2288.148142   760.681178  \n",
       "...           ...          ...  \n",
       "1199  7169.210360  1642.890699  \n",
       "1200  7288.785011  1682.726976  \n",
       "1200  7201.576530  1586.125380  \n",
       "1201  7382.808127  1616.887502  \n",
       "1201  7343.356190  1522.514499  \n",
       "\n",
       "[2404 rows x 19 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe_df = FeatureEngineer(df).post_process()\n",
    "fe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1778\n",
      "Number of testing samples: 626\n"
     ]
    }
   ],
   "source": [
    "fe_df.index = fe_df[\"date\"].factorize()[0]\n",
    "\n",
    "# make sure test_size is always even\n",
    "train, trade = train_test_split(fe_df, shuffle=False, test_size=0.26)\n",
    "\n",
    "print(f\"Number of training samples: {len(train)}\")\n",
    "print(f\"Number of testing samples: {len(trade)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how state_space is calculated -\n",
    "1 = [HMAX]</br>\n",
    "2 * STOCK_DIMENSION = [\"DATE\", \"CLOSE\"] * len(TICKERS)</br>\n",
    "(len(tech_indicator_list) * NumOfTickers) = len(['sma_30', 'sma_60', 'ema_8', 'ema_21', 'macd', 'rsi_30', 'rsi_70','dx_30', 'cci_30', 'boll_ub', 'boll_lb']) * len(TICKERS)</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to results\n",
      "Logging to results\n",
      "Using cuda device\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 107         |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 4           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.84       |\n",
      "|    explained_variance | 0.801       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.617      |\n",
      "|    reward             | -0.36754996 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.0443      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 142         |\n",
      "|    iterations         | 200         |\n",
      "|    time_elapsed       | 7           |\n",
      "|    total_timesteps    | 1000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.83       |\n",
      "|    explained_variance | 0.0513      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 199         |\n",
      "|    policy_loss        | -0.128      |\n",
      "|    reward             | 0.008261109 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 0.0106      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 157        |\n",
      "|    iterations         | 300        |\n",
      "|    time_elapsed       | 9          |\n",
      "|    total_timesteps    | 1500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.86      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 299        |\n",
      "|    policy_loss        | 0.189      |\n",
      "|    reward             | 0.09205614 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 0.0133     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 169         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 11          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.89       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.0945     |\n",
      "|    reward             | 0.060726933 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.00188     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 177        |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 14         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.93      |\n",
      "|    explained_variance | 0.208      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 0.785      |\n",
      "|    reward             | -0.1245188 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.0899     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 184        |\n",
      "|    iterations         | 600        |\n",
      "|    time_elapsed       | 16         |\n",
      "|    total_timesteps    | 3000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -2.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 599        |\n",
      "|    policy_loss        | -0.215     |\n",
      "|    reward             | -0.1453558 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.00951    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 188         |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 18          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -2.98       |\n",
      "|    explained_variance | 0.0376      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.831       |\n",
      "|    reward             | -0.10276538 |\n",
      "|    std                | 1.07        |\n",
      "|    value_loss         | 0.114       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 189          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 21           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -2.98        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.125       |\n",
      "|    reward             | -0.085686326 |\n",
      "|    std                | 1.08         |\n",
      "|    value_loss         | 0.00293      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 191           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -2.99         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.269        |\n",
      "|    reward             | -0.0032226562 |\n",
      "|    std                | 1.08          |\n",
      "|    value_loss         | 0.00674       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 193          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 25           |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.02        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.645        |\n",
      "|    reward             | -0.064503126 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.0375       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 195          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.03        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | -0.164       |\n",
      "|    reward             | -0.055883203 |\n",
      "|    std                | 1.1          |\n",
      "|    value_loss         | 0.00541      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 197           |\n",
      "|    iterations         | 1200          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 6000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -3.06         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1199          |\n",
      "|    policy_loss        | 0.218         |\n",
      "|    reward             | -0.0031015626 |\n",
      "|    std                | 1.12          |\n",
      "|    value_loss         | 0.0111        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 198          |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.08        |\n",
      "|    explained_variance | 0.207        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -1.25        |\n",
      "|    reward             | -0.030271094 |\n",
      "|    std                | 1.13         |\n",
      "|    value_loss         | 0.155        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 200         |\n",
      "|    iterations         | 1400        |\n",
      "|    time_elapsed       | 34          |\n",
      "|    total_timesteps    | 7000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.1        |\n",
      "|    explained_variance | 0.0367      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1399        |\n",
      "|    policy_loss        | 0.000353    |\n",
      "|    reward             | -0.18860781 |\n",
      "|    std                | 1.14        |\n",
      "|    value_loss         | 0.00615     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 201         |\n",
      "|    iterations         | 1500        |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 7500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1499        |\n",
      "|    policy_loss        | -0.817      |\n",
      "|    reward             | -0.45868394 |\n",
      "|    std                | 1.15        |\n",
      "|    value_loss         | 0.0839      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 202       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.11     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 1.28      |\n",
      "|    reward             | 0.8558758 |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.319     |\n",
      "-------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 10\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 240571.05\n",
      "total_reward: 140571.05\n",
      "total_cost: 254.41\n",
      "total_trades: 1622\n",
      "Sharpe: 1.023\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 203          |\n",
      "|    iterations         | 1700         |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 8500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.13        |\n",
      "|    explained_variance | 0.524        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1699         |\n",
      "|    policy_loss        | -0.515       |\n",
      "|    reward             | -0.110221095 |\n",
      "|    std                | 1.15         |\n",
      "|    value_loss         | 0.0291       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 204         |\n",
      "|    iterations         | 1800        |\n",
      "|    time_elapsed       | 44          |\n",
      "|    total_timesteps    | 9000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.14       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1799        |\n",
      "|    policy_loss        | -0.629      |\n",
      "|    reward             | 0.020635938 |\n",
      "|    std                | 1.16        |\n",
      "|    value_loss         | 0.0666      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 204          |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.16        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | -0.782       |\n",
      "|    reward             | 0.0035398437 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 0.0636       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 2000         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 10000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.18        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1999         |\n",
      "|    policy_loss        | -0.113       |\n",
      "|    reward             | -0.049858984 |\n",
      "|    std                | 1.19         |\n",
      "|    value_loss         | 0.00264      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 205          |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.2         |\n",
      "|    explained_variance | -0.000694    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | 0.299        |\n",
      "|    reward             | -0.009604834 |\n",
      "|    std                | 1.2          |\n",
      "|    value_loss         | 0.017        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 206         |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 53          |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.23       |\n",
      "|    explained_variance | 0.0533      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | -0.107      |\n",
      "|    reward             | 0.004759375 |\n",
      "|    std                | 1.22        |\n",
      "|    value_loss         | 0.0022      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 206        |\n",
      "|    iterations         | 2300       |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 11500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2299       |\n",
      "|    policy_loss        | 0.486      |\n",
      "|    reward             | 0.15086094 |\n",
      "|    std                | 1.23       |\n",
      "|    value_loss         | 0.0523     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 207         |\n",
      "|    iterations         | 2400        |\n",
      "|    time_elapsed       | 57          |\n",
      "|    total_timesteps    | 12000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.27       |\n",
      "|    explained_variance | -2.26       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2399        |\n",
      "|    policy_loss        | 0.281       |\n",
      "|    reward             | -0.00557666 |\n",
      "|    std                | 1.24        |\n",
      "|    value_loss         | 0.00681     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 208       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.28     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 0.162     |\n",
      "|    reward             | 0.0467947 |\n",
      "|    std                | 1.25      |\n",
      "|    value_loss         | 0.00368   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 208        |\n",
      "|    iterations         | 2600       |\n",
      "|    time_elapsed       | 62         |\n",
      "|    total_timesteps    | 13000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.29      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2599       |\n",
      "|    policy_loss        | -0.36      |\n",
      "|    reward             | 0.09914893 |\n",
      "|    std                | 1.25       |\n",
      "|    value_loss         | 0.0407     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 2700        |\n",
      "|    time_elapsed       | 64          |\n",
      "|    total_timesteps    | 13500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.32       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2699        |\n",
      "|    policy_loss        | 0.00652     |\n",
      "|    reward             | 0.055190735 |\n",
      "|    std                | 1.27        |\n",
      "|    value_loss         | 0.00333     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 208        |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 67         |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.35      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -0.601     |\n",
      "|    reward             | 0.19843477 |\n",
      "|    std                | 1.29       |\n",
      "|    value_loss         | 0.0623     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 2900         |\n",
      "|    time_elapsed       | 69           |\n",
      "|    total_timesteps    | 14500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.37        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2899         |\n",
      "|    policy_loss        | -0.79        |\n",
      "|    reward             | -0.039063793 |\n",
      "|    std                | 1.31         |\n",
      "|    value_loss         | 0.0621       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 209        |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 71         |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | -0.333     |\n",
      "|    reward             | -0.1554921 |\n",
      "|    std                | 1.31       |\n",
      "|    value_loss         | 0.0199     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 208       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.41     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -0.345    |\n",
      "|    reward             | 0.0       |\n",
      "|    std                | 1.33      |\n",
      "|    value_loss         | 0.0171    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 3200        |\n",
      "|    time_elapsed       | 76          |\n",
      "|    total_timesteps    | 16000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.42       |\n",
      "|    explained_variance | 0.00161     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3199        |\n",
      "|    policy_loss        | 0.653       |\n",
      "|    reward             | -0.44693282 |\n",
      "|    std                | 1.34        |\n",
      "|    value_loss         | 0.0601      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 208         |\n",
      "|    iterations         | 3300        |\n",
      "|    time_elapsed       | 78          |\n",
      "|    total_timesteps    | 16500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.46       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3299        |\n",
      "|    policy_loss        | -0.565      |\n",
      "|    reward             | 0.037409056 |\n",
      "|    std                | 1.36        |\n",
      "|    value_loss         | 0.03        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 209        |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 81         |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.48      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | -0.538     |\n",
      "|    reward             | -0.0815125 |\n",
      "|    std                | 1.38       |\n",
      "|    value_loss         | 0.0404     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 209         |\n",
      "|    iterations         | 3500        |\n",
      "|    time_elapsed       | 83          |\n",
      "|    total_timesteps    | 17500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.53       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3499        |\n",
      "|    policy_loss        | -0.369      |\n",
      "|    reward             | -0.23310831 |\n",
      "|    std                | 1.41        |\n",
      "|    value_loss         | 0.0089      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 209         |\n",
      "|    iterations         | 3600        |\n",
      "|    time_elapsed       | 85          |\n",
      "|    total_timesteps    | 18000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.55       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3599        |\n",
      "|    policy_loss        | 0.0947      |\n",
      "|    reward             | -0.04868921 |\n",
      "|    std                | 1.43        |\n",
      "|    value_loss         | 0.00136     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 209          |\n",
      "|    iterations         | 3700         |\n",
      "|    time_elapsed       | 88           |\n",
      "|    total_timesteps    | 18500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.59        |\n",
      "|    explained_variance | -0.0154      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3699         |\n",
      "|    policy_loss        | -0.124       |\n",
      "|    reward             | -0.057111133 |\n",
      "|    std                | 1.46         |\n",
      "|    value_loss         | 0.00374      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 210          |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 90           |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.62        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 0.17         |\n",
      "|    reward             | -0.019628515 |\n",
      "|    std                | 1.48         |\n",
      "|    value_loss         | 0.0037       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 210        |\n",
      "|    iterations         | 3900       |\n",
      "|    time_elapsed       | 92         |\n",
      "|    total_timesteps    | 19500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.65      |\n",
      "|    explained_variance | 0.0831     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3899       |\n",
      "|    policy_loss        | 0.947      |\n",
      "|    reward             | 0.13361353 |\n",
      "|    std                | 1.5        |\n",
      "|    value_loss         | 0.0793     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 210          |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 94           |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.67        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | -0.0248      |\n",
      "|    reward             | -0.045968555 |\n",
      "|    std                | 1.52         |\n",
      "|    value_loss         | 0.00064      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 211          |\n",
      "|    iterations         | 4100         |\n",
      "|    time_elapsed       | 97           |\n",
      "|    total_timesteps    | 20500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.69        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4099         |\n",
      "|    policy_loss        | 0.0494       |\n",
      "|    reward             | 0.0010455566 |\n",
      "|    std                | 1.53         |\n",
      "|    value_loss         | 0.00194      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 211         |\n",
      "|    iterations         | 4200        |\n",
      "|    time_elapsed       | 99          |\n",
      "|    total_timesteps    | 21000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.71       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4199        |\n",
      "|    policy_loss        | 0.0243      |\n",
      "|    reward             | -0.13706836 |\n",
      "|    std                | 1.54        |\n",
      "|    value_loss         | 0.00282     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 211         |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 101         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.73       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -0.655      |\n",
      "|    reward             | 0.030669617 |\n",
      "|    std                | 1.57        |\n",
      "|    value_loss         | 0.0347      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 211        |\n",
      "|    iterations         | 4400       |\n",
      "|    time_elapsed       | 103        |\n",
      "|    total_timesteps    | 22000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.76      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4399       |\n",
      "|    policy_loss        | -2.26      |\n",
      "|    reward             | -0.2623526 |\n",
      "|    std                | 1.59       |\n",
      "|    value_loss         | 0.44       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 211         |\n",
      "|    iterations         | 4500        |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 22500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.79       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4499        |\n",
      "|    policy_loss        | -0.678      |\n",
      "|    reward             | -0.09763946 |\n",
      "|    std                | 1.61        |\n",
      "|    value_loss         | 0.0454      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 4600        |\n",
      "|    time_elapsed       | 108         |\n",
      "|    total_timesteps    | 23000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.81       |\n",
      "|    explained_variance | -0.0664     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4599        |\n",
      "|    policy_loss        | 0.502       |\n",
      "|    reward             | 0.026684815 |\n",
      "|    std                | 1.63        |\n",
      "|    value_loss         | 0.0217      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 212        |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | -0.74      |\n",
      "|    reward             | 0.15443207 |\n",
      "|    std                | 1.65       |\n",
      "|    value_loss         | 0.0467     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 112         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | 0.891       |\n",
      "|    reward             | -0.25226405 |\n",
      "|    std                | 1.65        |\n",
      "|    value_loss         | 0.0652      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 4900         |\n",
      "|    time_elapsed       | 115          |\n",
      "|    total_timesteps    | 24500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.88        |\n",
      "|    explained_variance | -40          |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4899         |\n",
      "|    policy_loss        | -0.509       |\n",
      "|    reward             | -0.055525262 |\n",
      "|    std                | 1.68         |\n",
      "|    value_loss         | 0.0261       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 212          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 117          |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -3.89        |\n",
      "|    explained_variance | -10.6        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | -0.476       |\n",
      "|    reward             | -0.005653662 |\n",
      "|    std                | 1.69         |\n",
      "|    value_loss         | 0.0342       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 212         |\n",
      "|    iterations         | 5100        |\n",
      "|    time_elapsed       | 119         |\n",
      "|    total_timesteps    | 25500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.92       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5099        |\n",
      "|    policy_loss        | 0.444       |\n",
      "|    reward             | -0.05978789 |\n",
      "|    std                | 1.71        |\n",
      "|    value_loss         | 0.0123      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 213         |\n",
      "|    iterations         | 5200        |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 26000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.92       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5199        |\n",
      "|    policy_loss        | 0.395       |\n",
      "|    reward             | -0.09252568 |\n",
      "|    std                | 1.72        |\n",
      "|    value_loss         | 0.0214      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 213         |\n",
      "|    iterations         | 5300        |\n",
      "|    time_elapsed       | 124         |\n",
      "|    total_timesteps    | 26500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.94       |\n",
      "|    explained_variance | -0.0887     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5299        |\n",
      "|    policy_loss        | -0.0801     |\n",
      "|    reward             | 0.023938851 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 0.00937     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 213         |\n",
      "|    iterations         | 5400        |\n",
      "|    time_elapsed       | 126         |\n",
      "|    total_timesteps    | 27000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.95       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5399        |\n",
      "|    policy_loss        | 0.26        |\n",
      "|    reward             | -0.03173492 |\n",
      "|    std                | 1.74        |\n",
      "|    value_loss         | 0.00738     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 213         |\n",
      "|    iterations         | 5500        |\n",
      "|    time_elapsed       | 128         |\n",
      "|    total_timesteps    | 27500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.96       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5499        |\n",
      "|    policy_loss        | -0.891      |\n",
      "|    reward             | -0.34207544 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 0.0453      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 213        |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 131        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | -0.255     |\n",
      "|    reward             | 0.10937735 |\n",
      "|    std                | 1.76       |\n",
      "|    value_loss         | 0.0143     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 213         |\n",
      "|    iterations         | 5700        |\n",
      "|    time_elapsed       | 133         |\n",
      "|    total_timesteps    | 28500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -3.96       |\n",
      "|    explained_variance | -32.3       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5699        |\n",
      "|    policy_loss        | -0.0914     |\n",
      "|    reward             | -0.07789751 |\n",
      "|    std                | 1.75        |\n",
      "|    value_loss         | 0.0367      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 213        |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 135        |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -3.98      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | -0.982     |\n",
      "|    reward             | -0.1576012 |\n",
      "|    std                | 1.77       |\n",
      "|    value_loss         | 0.0481     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 213        |\n",
      "|    iterations         | 5900       |\n",
      "|    time_elapsed       | 137        |\n",
      "|    total_timesteps    | 29500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.01      |\n",
      "|    explained_variance | -0.143     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5899       |\n",
      "|    policy_loss        | -0.303     |\n",
      "|    reward             | 0.06791816 |\n",
      "|    std                | 1.8        |\n",
      "|    value_loss         | 0.00387    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 214         |\n",
      "|    iterations         | 6000        |\n",
      "|    time_elapsed       | 140         |\n",
      "|    total_timesteps    | 30000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.02       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5999        |\n",
      "|    policy_loss        | 0.00241     |\n",
      "|    reward             | -0.15104492 |\n",
      "|    std                | 1.81        |\n",
      "|    value_loss         | 0.00688     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 214         |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 142         |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.04       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -0.714      |\n",
      "|    reward             | 0.004725879 |\n",
      "|    std                | 1.83        |\n",
      "|    value_loss         | 0.0678      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 214        |\n",
      "|    iterations         | 6200       |\n",
      "|    time_elapsed       | 144        |\n",
      "|    total_timesteps    | 31000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.06      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6199       |\n",
      "|    policy_loss        | -0.326     |\n",
      "|    reward             | -0.1558348 |\n",
      "|    std                | 1.84       |\n",
      "|    value_loss         | 0.019      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 214         |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 146         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.07       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | 0.017344885 |\n",
      "|    std                | 1.85        |\n",
      "|    value_loss         | 0.0608      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 214        |\n",
      "|    iterations         | 6400       |\n",
      "|    time_elapsed       | 149        |\n",
      "|    total_timesteps    | 32000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.08      |\n",
      "|    explained_variance | 0.0102     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6399       |\n",
      "|    policy_loss        | 0.765      |\n",
      "|    reward             | -0.4222178 |\n",
      "|    std                | 1.86       |\n",
      "|    value_loss         | 0.0642     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 214         |\n",
      "|    iterations         | 6500        |\n",
      "|    time_elapsed       | 151         |\n",
      "|    total_timesteps    | 32500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.1        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6499        |\n",
      "|    policy_loss        | -0.492      |\n",
      "|    reward             | 0.022727417 |\n",
      "|    std                | 1.88        |\n",
      "|    value_loss         | 0.0229      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 214         |\n",
      "|    iterations         | 6600        |\n",
      "|    time_elapsed       | 153         |\n",
      "|    total_timesteps    | 33000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6599        |\n",
      "|    policy_loss        | -0.65       |\n",
      "|    reward             | -0.04950188 |\n",
      "|    std                | 1.9         |\n",
      "|    value_loss         | 0.0295      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 214          |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 156          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.16        |\n",
      "|    explained_variance | -0.369       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | -0.147       |\n",
      "|    reward             | -0.031624682 |\n",
      "|    std                | 1.94         |\n",
      "|    value_loss         | 0.00225      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 214         |\n",
      "|    iterations         | 6800        |\n",
      "|    time_elapsed       | 158         |\n",
      "|    total_timesteps    | 34000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.17       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6799        |\n",
      "|    policy_loss        | 0.72        |\n",
      "|    reward             | 0.071675315 |\n",
      "|    std                | 1.95        |\n",
      "|    value_loss         | 0.0326      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 214          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 160          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.2         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | -0.506       |\n",
      "|    reward             | -0.040352736 |\n",
      "|    std                | 1.98         |\n",
      "|    value_loss         | 0.019        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 214          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 162          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.22        |\n",
      "|    explained_variance | -8.13        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | 0.692        |\n",
      "|    reward             | -0.046709105 |\n",
      "|    std                | 2            |\n",
      "|    value_loss         | 0.038        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 165         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.22       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | -0.461      |\n",
      "|    reward             | 0.010570215 |\n",
      "|    std                | 2           |\n",
      "|    value_loss         | 0.0446      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 215          |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 167          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.24        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -0.592       |\n",
      "|    reward             | -0.036558107 |\n",
      "|    std                | 2.01         |\n",
      "|    value_loss         | 0.0193       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 215        |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 169        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.26      |\n",
      "|    explained_variance | -0.0492    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | -0.206     |\n",
      "|    reward             | 0.00871623 |\n",
      "|    std                | 2.04       |\n",
      "|    value_loss         | 0.0058     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 7400        |\n",
      "|    time_elapsed       | 172         |\n",
      "|    total_timesteps    | 37000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.28       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7399        |\n",
      "|    policy_loss        | -0.406      |\n",
      "|    reward             | -0.07781103 |\n",
      "|    std                | 2.06        |\n",
      "|    value_loss         | 0.0105      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 7500        |\n",
      "|    time_elapsed       | 174         |\n",
      "|    total_timesteps    | 37500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.3        |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7499        |\n",
      "|    policy_loss        | -0.21       |\n",
      "|    reward             | -0.07020337 |\n",
      "|    std                | 2.08        |\n",
      "|    value_loss         | 0.00613     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 7600        |\n",
      "|    time_elapsed       | 176         |\n",
      "|    total_timesteps    | 38000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.3        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7599        |\n",
      "|    policy_loss        | 0.565       |\n",
      "|    reward             | -0.18836895 |\n",
      "|    std                | 2.08        |\n",
      "|    value_loss         | 0.0532      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 7700        |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 38500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.33       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7699        |\n",
      "|    policy_loss        | -2.17       |\n",
      "|    reward             | 0.041086182 |\n",
      "|    std                | 2.1         |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 215        |\n",
      "|    iterations         | 7800       |\n",
      "|    time_elapsed       | 181        |\n",
      "|    total_timesteps    | 39000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.33      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7799       |\n",
      "|    policy_loss        | -0.105     |\n",
      "|    reward             | 0.28532857 |\n",
      "|    std                | 2.11       |\n",
      "|    value_loss         | 0.0113     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 215        |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 183        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.35      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | -0.157     |\n",
      "|    reward             | 0.12031699 |\n",
      "|    std                | 2.13       |\n",
      "|    value_loss         | 0.0117     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 8000        |\n",
      "|    time_elapsed       | 185         |\n",
      "|    total_timesteps    | 40000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.35       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7999        |\n",
      "|    policy_loss        | -1.21       |\n",
      "|    reward             | -0.15152188 |\n",
      "|    std                | 2.14        |\n",
      "|    value_loss         | 0.163       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 215        |\n",
      "|    iterations         | 8100       |\n",
      "|    time_elapsed       | 188        |\n",
      "|    total_timesteps    | 40500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.35      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8099       |\n",
      "|    policy_loss        | -0.0999    |\n",
      "|    reward             | 0.22856008 |\n",
      "|    std                | 2.13       |\n",
      "|    value_loss         | 0.0383     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 8200        |\n",
      "|    time_elapsed       | 190         |\n",
      "|    total_timesteps    | 41000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.37       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8199        |\n",
      "|    policy_loss        | 0.0775      |\n",
      "|    reward             | 0.044606395 |\n",
      "|    std                | 2.15        |\n",
      "|    value_loss         | 0.00497     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 215        |\n",
      "|    iterations         | 8300       |\n",
      "|    time_elapsed       | 192        |\n",
      "|    total_timesteps    | 41500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.38      |\n",
      "|    explained_variance | -0.00064   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8299       |\n",
      "|    policy_loss        | -0.0496    |\n",
      "|    reward             | 0.04803584 |\n",
      "|    std                | 2.16       |\n",
      "|    value_loss         | 0.00172    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 215        |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 195        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.4       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | 0.658      |\n",
      "|    reward             | 0.37864876 |\n",
      "|    std                | 2.18       |\n",
      "|    value_loss         | 0.0317     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 215        |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 197        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.42      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | 0.0466     |\n",
      "|    reward             | 0.21325782 |\n",
      "|    std                | 2.21       |\n",
      "|    value_loss         | 0.0046     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 215          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 199          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.44        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 0.509        |\n",
      "|    reward             | -0.022122461 |\n",
      "|    std                | 2.23         |\n",
      "|    value_loss         | 0.012        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 8700        |\n",
      "|    time_elapsed       | 201         |\n",
      "|    total_timesteps    | 43500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.45       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8699        |\n",
      "|    policy_loss        | -1.07       |\n",
      "|    reward             | -0.05591631 |\n",
      "|    std                | 2.24        |\n",
      "|    value_loss         | 0.115       |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 50\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102647.67\n",
      "total_reward: 2647.67\n",
      "total_cost: 936.03\n",
      "total_trades: 1471\n",
      "Sharpe: 0.347\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 215          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 204          |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.47        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | -0.276       |\n",
      "|    reward             | -0.039708983 |\n",
      "|    std                | 2.26         |\n",
      "|    value_loss         | 0.00439      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 206         |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.49       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | -0.633      |\n",
      "|    reward             | 0.038948756 |\n",
      "|    std                | 2.29        |\n",
      "|    value_loss         | 0.0243      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 9000        |\n",
      "|    time_elapsed       | 208         |\n",
      "|    total_timesteps    | 45000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.5        |\n",
      "|    explained_variance | 0.0152      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8999        |\n",
      "|    policy_loss        | -0.259      |\n",
      "|    reward             | 0.004108215 |\n",
      "|    std                | 2.3         |\n",
      "|    value_loss         | 0.00607     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 215          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 211          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.51        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | -0.189       |\n",
      "|    reward             | -0.067017555 |\n",
      "|    std                | 2.31         |\n",
      "|    value_loss         | 0.00332      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 215        |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 213        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.54      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | 0.86       |\n",
      "|    reward             | 0.17037351 |\n",
      "|    std                | 2.34       |\n",
      "|    value_loss         | 0.0468     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 215       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 215       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.55     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | -1.59     |\n",
      "|    reward             | 0.2729998 |\n",
      "|    std                | 2.35      |\n",
      "|    value_loss         | 0.154     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 215          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 217          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.57        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | -0.296       |\n",
      "|    reward             | -0.050335206 |\n",
      "|    std                | 2.38         |\n",
      "|    value_loss         | 0.0218       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 215         |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 220         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.55       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | 0.65        |\n",
      "|    reward             | 0.021597655 |\n",
      "|    std                | 2.36        |\n",
      "|    value_loss         | 0.0348      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 215        |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 222        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.55      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | -0.645     |\n",
      "|    reward             | 0.16712011 |\n",
      "|    std                | 2.36       |\n",
      "|    value_loss         | 0.0741     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 215           |\n",
      "|    iterations         | 9700          |\n",
      "|    time_elapsed       | 224           |\n",
      "|    total_timesteps    | 48500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -4.55         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9699          |\n",
      "|    policy_loss        | -0.855        |\n",
      "|    reward             | -0.0074595856 |\n",
      "|    std                | 2.36          |\n",
      "|    value_loss         | 0.0378        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 215          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 226          |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.56        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | -0.435       |\n",
      "|    reward             | -0.044606395 |\n",
      "|    std                | 2.37         |\n",
      "|    value_loss         | 0.0124       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 229         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.58       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 0.265       |\n",
      "|    reward             | -0.17102225 |\n",
      "|    std                | 2.4         |\n",
      "|    value_loss         | 0.012       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 231         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.62       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | 0.511       |\n",
      "|    reward             | 0.068549655 |\n",
      "|    std                | 2.44        |\n",
      "|    value_loss         | 0.0145      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 10100      |\n",
      "|    time_elapsed       | 233        |\n",
      "|    total_timesteps    | 50500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.62      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10099      |\n",
      "|    policy_loss        | -0.521     |\n",
      "|    reward             | 0.19001503 |\n",
      "|    std                | 2.44       |\n",
      "|    value_loss         | 0.0206     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 10200        |\n",
      "|    time_elapsed       | 235          |\n",
      "|    total_timesteps    | 51000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.62        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10199        |\n",
      "|    policy_loss        | -0.0252      |\n",
      "|    reward             | -0.060703564 |\n",
      "|    std                | 2.44         |\n",
      "|    value_loss         | 0.00139      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 10300       |\n",
      "|    time_elapsed       | 238         |\n",
      "|    total_timesteps    | 51500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.64       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10299       |\n",
      "|    policy_loss        | -2.28       |\n",
      "|    reward             | -0.31871283 |\n",
      "|    std                | 2.47        |\n",
      "|    value_loss         | 0.304       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 10400      |\n",
      "|    time_elapsed       | 240        |\n",
      "|    total_timesteps    | 52000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.65      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10399      |\n",
      "|    policy_loss        | 0.246      |\n",
      "|    reward             | 0.11304443 |\n",
      "|    std                | 2.48       |\n",
      "|    value_loss         | 0.00623    |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 242       |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.67     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | -0.67     |\n",
      "|    reward             | 0.0502635 |\n",
      "|    std                | 2.51      |\n",
      "|    value_loss         | 0.0208    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 245         |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.69       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | -0.175      |\n",
      "|    reward             | 0.054617953 |\n",
      "|    std                | 2.53        |\n",
      "|    value_loss         | 0.00418     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 10700        |\n",
      "|    time_elapsed       | 247          |\n",
      "|    total_timesteps    | 53500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.71        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10699        |\n",
      "|    policy_loss        | -0.0615      |\n",
      "|    reward             | -0.006171094 |\n",
      "|    std                | 2.55         |\n",
      "|    value_loss         | 0.00337      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 10800       |\n",
      "|    time_elapsed       | 249         |\n",
      "|    total_timesteps    | 54000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.72       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10799       |\n",
      "|    policy_loss        | 0.296       |\n",
      "|    reward             | 0.055045277 |\n",
      "|    std                | 2.57        |\n",
      "|    value_loss         | 0.00795     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 10900       |\n",
      "|    time_elapsed       | 251         |\n",
      "|    total_timesteps    | 54500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.74       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10899       |\n",
      "|    policy_loss        | -0.462      |\n",
      "|    reward             | -0.21568555 |\n",
      "|    std                | 2.59        |\n",
      "|    value_loss         | 0.0221      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 11000        |\n",
      "|    time_elapsed       | 254          |\n",
      "|    total_timesteps    | 55000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.75        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10999        |\n",
      "|    policy_loss        | -0.868       |\n",
      "|    reward             | 0.0048745116 |\n",
      "|    std                | 2.6          |\n",
      "|    value_loss         | 0.0376       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 256       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.77     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | 1.12      |\n",
      "|    reward             | 0.1842892 |\n",
      "|    std                | 2.62      |\n",
      "|    value_loss         | 0.0654    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 11200       |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 56000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.77       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11199       |\n",
      "|    policy_loss        | -1.89       |\n",
      "|    reward             | 0.066967875 |\n",
      "|    std                | 2.63        |\n",
      "|    value_loss         | 0.181       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 11300       |\n",
      "|    time_elapsed       | 260         |\n",
      "|    total_timesteps    | 56500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.78       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11299       |\n",
      "|    policy_loss        | -0.662      |\n",
      "|    reward             | -0.03950618 |\n",
      "|    std                | 2.65        |\n",
      "|    value_loss         | 0.0237      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 11400       |\n",
      "|    time_elapsed       | 263         |\n",
      "|    total_timesteps    | 57000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.8        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | 0.0086      |\n",
      "|    reward             | 0.118804574 |\n",
      "|    std                | 2.67        |\n",
      "|    value_loss         | 0.00148     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 11500        |\n",
      "|    time_elapsed       | 265          |\n",
      "|    total_timesteps    | 57500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.83        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11499        |\n",
      "|    policy_loss        | 0.458        |\n",
      "|    reward             | -0.009298196 |\n",
      "|    std                | 2.7          |\n",
      "|    value_loss         | 0.0121       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 11600       |\n",
      "|    time_elapsed       | 267         |\n",
      "|    total_timesteps    | 58000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11599       |\n",
      "|    policy_loss        | 0.0199      |\n",
      "|    reward             | 0.036895532 |\n",
      "|    std                | 2.74        |\n",
      "|    value_loss         | 0.000335    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 11700       |\n",
      "|    time_elapsed       | 270         |\n",
      "|    total_timesteps    | 58500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11699       |\n",
      "|    policy_loss        | 0.497       |\n",
      "|    reward             | 0.023723522 |\n",
      "|    std                | 2.73        |\n",
      "|    value_loss         | 0.0196      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 11800        |\n",
      "|    time_elapsed       | 272          |\n",
      "|    total_timesteps    | 59000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -4.87        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11799        |\n",
      "|    policy_loss        | -0.2         |\n",
      "|    reward             | -0.084808104 |\n",
      "|    std                | 2.76         |\n",
      "|    value_loss         | 0.00337      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 11900      |\n",
      "|    time_elapsed       | 274        |\n",
      "|    total_timesteps    | 59500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -4.9       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 11899      |\n",
      "|    policy_loss        | -0.9       |\n",
      "|    reward             | 0.07494106 |\n",
      "|    std                | 2.82       |\n",
      "|    value_loss         | 0.0451     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 12000       |\n",
      "|    time_elapsed       | 277         |\n",
      "|    total_timesteps    | 60000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.93       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | -0.101      |\n",
      "|    reward             | 0.028889649 |\n",
      "|    std                | 2.85        |\n",
      "|    value_loss         | 0.00377     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 12100       |\n",
      "|    time_elapsed       | 279         |\n",
      "|    total_timesteps    | 60500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.96       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | -0.711      |\n",
      "|    reward             | 0.116657205 |\n",
      "|    std                | 2.9         |\n",
      "|    value_loss         | 0.0211      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 12200       |\n",
      "|    time_elapsed       | 281         |\n",
      "|    total_timesteps    | 61000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.97       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12199       |\n",
      "|    policy_loss        | -0.387      |\n",
      "|    reward             | 0.033585936 |\n",
      "|    std                | 2.9         |\n",
      "|    value_loss         | 0.0107      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 70\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 118347.66\n",
      "total_reward: 18347.66\n",
      "total_cost: 3889.74\n",
      "total_trades: 1727\n",
      "Sharpe: 0.421\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 12300       |\n",
      "|    time_elapsed       | 283         |\n",
      "|    total_timesteps    | 61500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -4.99       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | -0.296      |\n",
      "|    reward             | 0.013603858 |\n",
      "|    std                | 2.93        |\n",
      "|    value_loss         | 0.00603     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 12400      |\n",
      "|    time_elapsed       | 286        |\n",
      "|    total_timesteps    | 62000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.01      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12399      |\n",
      "|    policy_loss        | -0.571     |\n",
      "|    reward             | -0.3235673 |\n",
      "|    std                | 2.97       |\n",
      "|    value_loss         | 0.0198     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 12500      |\n",
      "|    time_elapsed       | 288        |\n",
      "|    total_timesteps    | 62500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.02      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12499      |\n",
      "|    policy_loss        | 0.922      |\n",
      "|    reward             | 0.17979951 |\n",
      "|    std                | 2.99       |\n",
      "|    value_loss         | 0.0343     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 12600      |\n",
      "|    time_elapsed       | 290        |\n",
      "|    total_timesteps    | 63000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12599      |\n",
      "|    policy_loss        | -1.74      |\n",
      "|    reward             | 0.23539986 |\n",
      "|    std                | 3          |\n",
      "|    value_loss         | 0.116      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 12700       |\n",
      "|    time_elapsed       | 292         |\n",
      "|    total_timesteps    | 63500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.04       |\n",
      "|    explained_variance | -4.99       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12699       |\n",
      "|    policy_loss        | 1.36        |\n",
      "|    reward             | 0.031081168 |\n",
      "|    std                | 3.02        |\n",
      "|    value_loss         | 0.0844      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 12800      |\n",
      "|    time_elapsed       | 295        |\n",
      "|    total_timesteps    | 64000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.06      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12799      |\n",
      "|    policy_loss        | -3.79      |\n",
      "|    reward             | -0.9548893 |\n",
      "|    std                | 3.04       |\n",
      "|    value_loss         | 0.669      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 12900      |\n",
      "|    time_elapsed       | 297        |\n",
      "|    total_timesteps    | 64500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.07      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 12899      |\n",
      "|    policy_loss        | 0.194      |\n",
      "|    reward             | 0.14050621 |\n",
      "|    std                | 3.05       |\n",
      "|    value_loss         | 0.0202     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 13000        |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 65000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.07        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12999        |\n",
      "|    policy_loss        | -0.0632      |\n",
      "|    reward             | -0.045006484 |\n",
      "|    std                | 3.05         |\n",
      "|    value_loss         | 0.000694     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 13100      |\n",
      "|    time_elapsed       | 302        |\n",
      "|    total_timesteps    | 65500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.09      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13099      |\n",
      "|    policy_loss        | 0.902      |\n",
      "|    reward             | 0.23642847 |\n",
      "|    std                | 3.09       |\n",
      "|    value_loss         | 0.0533     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 13200        |\n",
      "|    time_elapsed       | 304          |\n",
      "|    total_timesteps    | 66000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.1         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13199        |\n",
      "|    policy_loss        | 0.211        |\n",
      "|    reward             | -0.005617529 |\n",
      "|    std                | 3.1          |\n",
      "|    value_loss         | 0.00188      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 13300      |\n",
      "|    time_elapsed       | 306        |\n",
      "|    total_timesteps    | 66500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13299      |\n",
      "|    policy_loss        | -0.338     |\n",
      "|    reward             | 0.15195069 |\n",
      "|    std                | 3.12       |\n",
      "|    value_loss         | 0.0184     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 13400      |\n",
      "|    time_elapsed       | 308        |\n",
      "|    total_timesteps    | 67000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13399      |\n",
      "|    policy_loss        | -0.547     |\n",
      "|    reward             | 0.02550249 |\n",
      "|    std                | 3.18       |\n",
      "|    value_loss         | 0.0127     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 13500       |\n",
      "|    time_elapsed       | 311         |\n",
      "|    total_timesteps    | 67500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.16       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13499       |\n",
      "|    policy_loss        | -0.501      |\n",
      "|    reward             | -0.19478187 |\n",
      "|    std                | 3.19        |\n",
      "|    value_loss         | 0.0216      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 13600      |\n",
      "|    time_elapsed       | 313        |\n",
      "|    total_timesteps    | 68000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.17      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 13599      |\n",
      "|    policy_loss        | 0.323      |\n",
      "|    reward             | 0.09328891 |\n",
      "|    std                | 3.21       |\n",
      "|    value_loss         | 0.00902    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 13700       |\n",
      "|    time_elapsed       | 315         |\n",
      "|    total_timesteps    | 68500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.17       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13699       |\n",
      "|    policy_loss        | -0.434      |\n",
      "|    reward             | -0.07778467 |\n",
      "|    std                | 3.21        |\n",
      "|    value_loss         | 0.00905     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 13800       |\n",
      "|    time_elapsed       | 318         |\n",
      "|    total_timesteps    | 69000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.18       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13799       |\n",
      "|    policy_loss        | 0.0332      |\n",
      "|    reward             | -0.24583673 |\n",
      "|    std                | 3.24        |\n",
      "|    value_loss         | 0.0039      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 13900       |\n",
      "|    time_elapsed       | 320         |\n",
      "|    total_timesteps    | 69500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.2        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13899       |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | 0.049230102 |\n",
      "|    std                | 3.27        |\n",
      "|    value_loss         | 0.0736      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 14000       |\n",
      "|    time_elapsed       | 322         |\n",
      "|    total_timesteps    | 70000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.22       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13999       |\n",
      "|    policy_loss        | -2.42       |\n",
      "|    reward             | -0.13470617 |\n",
      "|    std                | 3.3         |\n",
      "|    value_loss         | 0.572       |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 80\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 232035.82\n",
      "total_reward: 132035.82\n",
      "total_cost: 8137.30\n",
      "total_trades: 1533\n",
      "Sharpe: 0.781\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 14100      |\n",
      "|    time_elapsed       | 325        |\n",
      "|    total_timesteps    | 70500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14099      |\n",
      "|    policy_loss        | -0.511     |\n",
      "|    reward             | 0.18744983 |\n",
      "|    std                | 3.34       |\n",
      "|    value_loss         | 0.0305     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 14200       |\n",
      "|    time_elapsed       | 327         |\n",
      "|    total_timesteps    | 71000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.26       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14199       |\n",
      "|    policy_loss        | 0.767       |\n",
      "|    reward             | -0.08160947 |\n",
      "|    std                | 3.37        |\n",
      "|    value_loss         | 0.0201      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 14300        |\n",
      "|    time_elapsed       | 329          |\n",
      "|    total_timesteps    | 71500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.28        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14299        |\n",
      "|    policy_loss        | 0.124        |\n",
      "|    reward             | -0.050647266 |\n",
      "|    std                | 3.4          |\n",
      "|    value_loss         | 0.00233      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 217       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.26     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | -1.76     |\n",
      "|    reward             | 0.2676502 |\n",
      "|    std                | 3.36      |\n",
      "|    value_loss         | 0.0887    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 14500      |\n",
      "|    time_elapsed       | 334        |\n",
      "|    total_timesteps    | 72500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.28      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 14499      |\n",
      "|    policy_loss        | 0.248      |\n",
      "|    reward             | 0.14177854 |\n",
      "|    std                | 3.4        |\n",
      "|    value_loss         | 0.0296     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 14600       |\n",
      "|    time_elapsed       | 336         |\n",
      "|    total_timesteps    | 73000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.28       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14599       |\n",
      "|    policy_loss        | 0.0879      |\n",
      "|    reward             | -0.21878748 |\n",
      "|    std                | 3.41        |\n",
      "|    value_loss         | 0.00271     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 14700        |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 73500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.3         |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14699        |\n",
      "|    policy_loss        | 1.37         |\n",
      "|    reward             | -0.032326024 |\n",
      "|    std                | 3.44         |\n",
      "|    value_loss         | 0.0643       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 14800        |\n",
      "|    time_elapsed       | 340          |\n",
      "|    total_timesteps    | 74000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.32        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14799        |\n",
      "|    policy_loss        | 0.186        |\n",
      "|    reward             | 0.0073310547 |\n",
      "|    std                | 3.47         |\n",
      "|    value_loss         | 0.00189      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 14900        |\n",
      "|    time_elapsed       | 343          |\n",
      "|    total_timesteps    | 74500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.33        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14899        |\n",
      "|    policy_loss        | -1.09        |\n",
      "|    reward             | -0.073002666 |\n",
      "|    std                | 3.49         |\n",
      "|    value_loss         | 0.0529       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 15000       |\n",
      "|    time_elapsed       | 345         |\n",
      "|    total_timesteps    | 75000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.35       |\n",
      "|    explained_variance | -2.9        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14999       |\n",
      "|    policy_loss        | -1.53       |\n",
      "|    reward             | 0.046143677 |\n",
      "|    std                | 3.51        |\n",
      "|    value_loss         | 0.0968      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 15100      |\n",
      "|    time_elapsed       | 347        |\n",
      "|    total_timesteps    | 75500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.37      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15099      |\n",
      "|    policy_loss        | 0.514      |\n",
      "|    reward             | 0.47433817 |\n",
      "|    std                | 3.55       |\n",
      "|    value_loss         | 0.0416     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 15200      |\n",
      "|    time_elapsed       | 349        |\n",
      "|    total_timesteps    | 76000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.39      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15199      |\n",
      "|    policy_loss        | 0.102      |\n",
      "|    reward             | -0.1136209 |\n",
      "|    std                | 3.59       |\n",
      "|    value_loss         | 0.00473    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 15300      |\n",
      "|    time_elapsed       | 352        |\n",
      "|    total_timesteps    | 76500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15299      |\n",
      "|    policy_loss        | -0.291     |\n",
      "|    reward             | 0.05172705 |\n",
      "|    std                | 3.56       |\n",
      "|    value_loss         | 0.00329    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 15400       |\n",
      "|    time_elapsed       | 354         |\n",
      "|    total_timesteps    | 77000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.38       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15399       |\n",
      "|    policy_loss        | -0.817      |\n",
      "|    reward             | -0.04930194 |\n",
      "|    std                | 3.58        |\n",
      "|    value_loss         | 0.0249      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 15500        |\n",
      "|    time_elapsed       | 356          |\n",
      "|    total_timesteps    | 77500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.4         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15499        |\n",
      "|    policy_loss        | -0.249       |\n",
      "|    reward             | -0.017629871 |\n",
      "|    std                | 3.62         |\n",
      "|    value_loss         | 0.00302      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 15600       |\n",
      "|    time_elapsed       | 358         |\n",
      "|    total_timesteps    | 78000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.42       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15599       |\n",
      "|    policy_loss        | -1.41       |\n",
      "|    reward             | -0.12198303 |\n",
      "|    std                | 3.64        |\n",
      "|    value_loss         | 0.171       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 15700        |\n",
      "|    time_elapsed       | 361          |\n",
      "|    total_timesteps    | 78500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.45        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15699        |\n",
      "|    policy_loss        | -1.55        |\n",
      "|    reward             | -0.120004274 |\n",
      "|    std                | 3.71         |\n",
      "|    value_loss         | 0.121        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 15800        |\n",
      "|    time_elapsed       | 363          |\n",
      "|    total_timesteps    | 79000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.46        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15799        |\n",
      "|    policy_loss        | -1.34        |\n",
      "|    reward             | -0.011380982 |\n",
      "|    std                | 3.72         |\n",
      "|    value_loss         | 0.0861       |\n",
      "----------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 90\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 184559.14\n",
      "total_reward: 84559.14\n",
      "total_cost: 5729.39\n",
      "total_trades: 1679\n",
      "Sharpe: 0.662\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 15900      |\n",
      "|    time_elapsed       | 366        |\n",
      "|    total_timesteps    | 79500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.47      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 15899      |\n",
      "|    policy_loss        | 0.518      |\n",
      "|    reward             | -0.0888089 |\n",
      "|    std                | 3.74       |\n",
      "|    value_loss         | 0.0083     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 16000        |\n",
      "|    time_elapsed       | 368          |\n",
      "|    total_timesteps    | 80000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.47        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15999        |\n",
      "|    policy_loss        | -0.367       |\n",
      "|    reward             | -0.069553904 |\n",
      "|    std                | 3.75         |\n",
      "|    value_loss         | 0.00859      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 216      |\n",
      "|    iterations         | 16100    |\n",
      "|    time_elapsed       | 371      |\n",
      "|    total_timesteps    | 80500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.48    |\n",
      "|    explained_variance | 0.0415   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 16099    |\n",
      "|    policy_loss        | 2.14     |\n",
      "|    reward             | 0.147458 |\n",
      "|    std                | 3.77     |\n",
      "|    value_loss         | 0.224    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 16200      |\n",
      "|    time_elapsed       | 373        |\n",
      "|    total_timesteps    | 81000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.49      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16199      |\n",
      "|    policy_loss        | 0.309      |\n",
      "|    reward             | 0.09696633 |\n",
      "|    std                | 3.78       |\n",
      "|    value_loss         | 0.00459    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 216           |\n",
      "|    iterations         | 16300         |\n",
      "|    time_elapsed       | 375           |\n",
      "|    total_timesteps    | 81500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -5.5          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16299         |\n",
      "|    policy_loss        | 1.34          |\n",
      "|    reward             | -0.0069828597 |\n",
      "|    std                | 3.79          |\n",
      "|    value_loss         | 0.0986        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 16400      |\n",
      "|    time_elapsed       | 377        |\n",
      "|    total_timesteps    | 82000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.51      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16399      |\n",
      "|    policy_loss        | 0.253      |\n",
      "|    reward             | 0.10089807 |\n",
      "|    std                | 3.8        |\n",
      "|    value_loss         | 0.00283    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 16500      |\n",
      "|    time_elapsed       | 380        |\n",
      "|    total_timesteps    | 82500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.53      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16499      |\n",
      "|    policy_loss        | -0.722     |\n",
      "|    reward             | 0.06237158 |\n",
      "|    std                | 3.86       |\n",
      "|    value_loss         | 0.0358     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 16600      |\n",
      "|    time_elapsed       | 382        |\n",
      "|    total_timesteps    | 83000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.57      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16599      |\n",
      "|    policy_loss        | 0.843      |\n",
      "|    reward             | 0.09913938 |\n",
      "|    std                | 3.94       |\n",
      "|    value_loss         | 0.0285     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 16700       |\n",
      "|    time_elapsed       | 385         |\n",
      "|    total_timesteps    | 83500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.61       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16699       |\n",
      "|    policy_loss        | 1.02        |\n",
      "|    reward             | 0.105912596 |\n",
      "|    std                | 4.01        |\n",
      "|    value_loss         | 0.055       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 16800        |\n",
      "|    time_elapsed       | 387          |\n",
      "|    total_timesteps    | 84000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.64        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16799        |\n",
      "|    policy_loss        | 0.0491       |\n",
      "|    reward             | -0.056889012 |\n",
      "|    std                | 4.07         |\n",
      "|    value_loss         | 0.00427      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 16900       |\n",
      "|    time_elapsed       | 389         |\n",
      "|    total_timesteps    | 84500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.66       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16899       |\n",
      "|    policy_loss        | -0.00109    |\n",
      "|    reward             | -0.03535818 |\n",
      "|    std                | 4.12        |\n",
      "|    value_loss         | 0.000417    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 17000        |\n",
      "|    time_elapsed       | 392          |\n",
      "|    total_timesteps    | 85000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.67        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16999        |\n",
      "|    policy_loss        | -0.623       |\n",
      "|    reward             | -0.033973753 |\n",
      "|    std                | 4.13         |\n",
      "|    value_loss         | 0.0185       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 17100        |\n",
      "|    time_elapsed       | 394          |\n",
      "|    total_timesteps    | 85500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.71        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17099        |\n",
      "|    policy_loss        | -0.162       |\n",
      "|    reward             | -0.039057788 |\n",
      "|    std                | 4.21         |\n",
      "|    value_loss         | 0.00107      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 17200      |\n",
      "|    time_elapsed       | 396        |\n",
      "|    total_timesteps    | 86000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.72      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17199      |\n",
      "|    policy_loss        | -1.29      |\n",
      "|    reward             | 0.19083084 |\n",
      "|    std                | 4.24       |\n",
      "|    value_loss         | 0.108      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 17300       |\n",
      "|    time_elapsed       | 398         |\n",
      "|    total_timesteps    | 86500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.72       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17299       |\n",
      "|    policy_loss        | -1.68       |\n",
      "|    reward             | -0.33969724 |\n",
      "|    std                | 4.24        |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 17400      |\n",
      "|    time_elapsed       | 401        |\n",
      "|    total_timesteps    | 87000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.74      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17399      |\n",
      "|    policy_loss        | -0.421     |\n",
      "|    reward             | 0.05912932 |\n",
      "|    std                | 4.27       |\n",
      "|    value_loss         | 0.0192     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 17500       |\n",
      "|    time_elapsed       | 403         |\n",
      "|    total_timesteps    | 87500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.76       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17499       |\n",
      "|    policy_loss        | -0.083      |\n",
      "|    reward             | -0.01904255 |\n",
      "|    std                | 4.31        |\n",
      "|    value_loss         | 0.00469     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 17600       |\n",
      "|    time_elapsed       | 405         |\n",
      "|    total_timesteps    | 88000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.77       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17599       |\n",
      "|    policy_loss        | -0.435      |\n",
      "|    reward             | 0.025069922 |\n",
      "|    std                | 4.34        |\n",
      "|    value_loss         | 0.0168      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 100\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 111434.85\n",
      "total_reward: 11434.85\n",
      "total_cost: 2070.72\n",
      "total_trades: 1663\n",
      "Sharpe: 0.389\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 17700        |\n",
      "|    time_elapsed       | 408          |\n",
      "|    total_timesteps    | 88500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.78        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17699        |\n",
      "|    policy_loss        | 1.1          |\n",
      "|    reward             | -0.014738379 |\n",
      "|    std                | 4.37         |\n",
      "|    value_loss         | 0.0555       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 17800        |\n",
      "|    time_elapsed       | 410          |\n",
      "|    total_timesteps    | 89000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -5.8         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17799        |\n",
      "|    policy_loss        | 0.0304       |\n",
      "|    reward             | -0.001033728 |\n",
      "|    std                | 4.4          |\n",
      "|    value_loss         | 0.000932     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 17900       |\n",
      "|    time_elapsed       | 412         |\n",
      "|    total_timesteps    | 89500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.79       |\n",
      "|    explained_variance | 0.0244      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 17899       |\n",
      "|    policy_loss        | 1.29        |\n",
      "|    reward             | -0.02369143 |\n",
      "|    std                | 4.39        |\n",
      "|    value_loss         | 0.0951      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 18000      |\n",
      "|    time_elapsed       | 415        |\n",
      "|    total_timesteps    | 90000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.82      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 17999      |\n",
      "|    policy_loss        | 0.275      |\n",
      "|    reward             | 0.12947075 |\n",
      "|    std                | 4.46       |\n",
      "|    value_loss         | 0.00335    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 18100      |\n",
      "|    time_elapsed       | 417        |\n",
      "|    total_timesteps    | 90500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.83      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18099      |\n",
      "|    policy_loss        | -0.0933    |\n",
      "|    reward             | -0.1308729 |\n",
      "|    std                | 4.48       |\n",
      "|    value_loss         | 0.0255     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 18200       |\n",
      "|    time_elapsed       | 419         |\n",
      "|    total_timesteps    | 91000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18199       |\n",
      "|    policy_loss        | 2.54        |\n",
      "|    reward             | 0.093922265 |\n",
      "|    std                | 4.46        |\n",
      "|    value_loss         | 0.216       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 18300       |\n",
      "|    time_elapsed       | 421         |\n",
      "|    total_timesteps    | 91500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18299       |\n",
      "|    policy_loss        | 5.66        |\n",
      "|    reward             | -0.45882636 |\n",
      "|    std                | 4.49        |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 18400      |\n",
      "|    time_elapsed       | 424        |\n",
      "|    total_timesteps    | 92000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.86      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18399      |\n",
      "|    policy_loss        | -0.514     |\n",
      "|    reward             | 0.08424292 |\n",
      "|    std                | 4.53       |\n",
      "|    value_loss         | 0.0129     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 18500       |\n",
      "|    time_elapsed       | 426         |\n",
      "|    total_timesteps    | 92500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | -0.36       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18499       |\n",
      "|    policy_loss        | 0.762       |\n",
      "|    reward             | -0.04082838 |\n",
      "|    std                | 4.55        |\n",
      "|    value_loss         | 0.0191      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 18600      |\n",
      "|    time_elapsed       | 428        |\n",
      "|    total_timesteps    | 93000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.88      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18599      |\n",
      "|    policy_loss        | -0.991     |\n",
      "|    reward             | 0.10123425 |\n",
      "|    std                | 4.58       |\n",
      "|    value_loss         | 0.0568     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 18700       |\n",
      "|    time_elapsed       | 431         |\n",
      "|    total_timesteps    | 93500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.87       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18699       |\n",
      "|    policy_loss        | -0.135      |\n",
      "|    reward             | 0.034671288 |\n",
      "|    std                | 4.57        |\n",
      "|    value_loss         | 0.000773    |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 216      |\n",
      "|    iterations         | 18800    |\n",
      "|    time_elapsed       | 433      |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.9     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 18799    |\n",
      "|    policy_loss        | -2.37    |\n",
      "|    reward             | 0.097855 |\n",
      "|    std                | 4.63     |\n",
      "|    value_loss         | 0.171    |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 18900       |\n",
      "|    time_elapsed       | 435         |\n",
      "|    total_timesteps    | 94500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.9        |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | -2.51       |\n",
      "|    reward             | -0.27330723 |\n",
      "|    std                | 4.63        |\n",
      "|    value_loss         | 0.597       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 19000      |\n",
      "|    time_elapsed       | 438        |\n",
      "|    total_timesteps    | 95000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -5.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 18999      |\n",
      "|    policy_loss        | -2.57      |\n",
      "|    reward             | 0.08586983 |\n",
      "|    std                | 4.7        |\n",
      "|    value_loss         | 0.266      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 440       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.94     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 0.911     |\n",
      "|    reward             | 0.1619953 |\n",
      "|    std                | 4.74      |\n",
      "|    value_loss         | 0.0258    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 442       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.97     |\n",
      "|    explained_variance | -0.0396   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 0.0608    |\n",
      "|    reward             | 0.1268142 |\n",
      "|    std                | 4.8       |\n",
      "|    value_loss         | 0.0272    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 19300       |\n",
      "|    time_elapsed       | 445         |\n",
      "|    total_timesteps    | 96500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.97       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19299       |\n",
      "|    policy_loss        | 0.917       |\n",
      "|    reward             | -0.16892084 |\n",
      "|    std                | 4.81        |\n",
      "|    value_loss         | 0.0679      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 110\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 102698.85\n",
      "total_reward: 2698.85\n",
      "total_cost: 1483.85\n",
      "total_trades: 1512\n",
      "Sharpe: 0.346\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 19400       |\n",
      "|    time_elapsed       | 447         |\n",
      "|    total_timesteps    | 97000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -5.97       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19399       |\n",
      "|    policy_loss        | 0.0609      |\n",
      "|    reward             | -0.08029087 |\n",
      "|    std                | 4.81        |\n",
      "|    value_loss         | 0.00341     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 19500       |\n",
      "|    time_elapsed       | 449         |\n",
      "|    total_timesteps    | 97500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.01       |\n",
      "|    explained_variance | 0.302       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19499       |\n",
      "|    policy_loss        | 1.71        |\n",
      "|    reward             | 0.044964503 |\n",
      "|    std                | 4.89        |\n",
      "|    value_loss         | 0.0977      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 19600        |\n",
      "|    time_elapsed       | 452          |\n",
      "|    total_timesteps    | 98000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.04        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19599        |\n",
      "|    policy_loss        | 0.512        |\n",
      "|    reward             | -0.055383302 |\n",
      "|    std                | 4.96         |\n",
      "|    value_loss         | 0.0217       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 19700      |\n",
      "|    time_elapsed       | 454        |\n",
      "|    total_timesteps    | 98500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.05      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 19699      |\n",
      "|    policy_loss        | -1.03      |\n",
      "|    reward             | 0.22208008 |\n",
      "|    std                | 5          |\n",
      "|    value_loss         | 0.259      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 19800       |\n",
      "|    time_elapsed       | 456         |\n",
      "|    total_timesteps    | 99000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.04       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19799       |\n",
      "|    policy_loss        | 1.52        |\n",
      "|    reward             | 0.014119189 |\n",
      "|    std                | 4.96        |\n",
      "|    value_loss         | 0.0918      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 19900       |\n",
      "|    time_elapsed       | 458         |\n",
      "|    total_timesteps    | 99500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.04       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19899       |\n",
      "|    policy_loss        | 3.33        |\n",
      "|    reward             | -0.56081015 |\n",
      "|    std                | 4.98        |\n",
      "|    value_loss         | 0.404       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 20000       |\n",
      "|    time_elapsed       | 461         |\n",
      "|    total_timesteps    | 100000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.05       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | 1.76        |\n",
      "|    reward             | -0.21419883 |\n",
      "|    std                | 4.99        |\n",
      "|    value_loss         | 0.123       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 20100       |\n",
      "|    time_elapsed       | 463         |\n",
      "|    total_timesteps    | 100500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20099       |\n",
      "|    policy_loss        | 0.24        |\n",
      "|    reward             | -0.11674673 |\n",
      "|    std                | 5.01        |\n",
      "|    value_loss         | 0.0149      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 20200       |\n",
      "|    time_elapsed       | 465         |\n",
      "|    total_timesteps    | 101000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20199       |\n",
      "|    policy_loss        | -1.32       |\n",
      "|    reward             | -0.24111444 |\n",
      "|    std                | 5.03        |\n",
      "|    value_loss         | 0.0614      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 20300      |\n",
      "|    time_elapsed       | 468        |\n",
      "|    total_timesteps    | 101500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.06      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20299      |\n",
      "|    policy_loss        | 0.267      |\n",
      "|    reward             | 0.09933489 |\n",
      "|    std                | 5.02       |\n",
      "|    value_loss         | 0.00637    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 20400       |\n",
      "|    time_elapsed       | 470         |\n",
      "|    total_timesteps    | 102000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20399       |\n",
      "|    policy_loss        | -2.95       |\n",
      "|    reward             | -0.04616708 |\n",
      "|    std                | 5.01        |\n",
      "|    value_loss         | 0.723       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 20500      |\n",
      "|    time_elapsed       | 472        |\n",
      "|    total_timesteps    | 102500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20499      |\n",
      "|    policy_loss        | -4.69      |\n",
      "|    reward             | 0.13384145 |\n",
      "|    std                | 5.05       |\n",
      "|    value_loss         | 0.935      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 20600      |\n",
      "|    time_elapsed       | 475        |\n",
      "|    total_timesteps    | 103000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.08      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20599      |\n",
      "|    policy_loss        | -2.65      |\n",
      "|    reward             | -0.9075655 |\n",
      "|    std                | 5.07       |\n",
      "|    value_loss         | 0.313      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 20700      |\n",
      "|    time_elapsed       | 477        |\n",
      "|    total_timesteps    | 103500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.1       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20699      |\n",
      "|    policy_loss        | 0.617      |\n",
      "|    reward             | 0.09370758 |\n",
      "|    std                | 5.12       |\n",
      "|    value_loss         | 0.0113     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 20800       |\n",
      "|    time_elapsed       | 479         |\n",
      "|    total_timesteps    | 104000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.1        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20799       |\n",
      "|    policy_loss        | -1.37       |\n",
      "|    reward             | -0.27991602 |\n",
      "|    std                | 5.13        |\n",
      "|    value_loss         | 0.0746      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 20900      |\n",
      "|    time_elapsed       | 481        |\n",
      "|    total_timesteps    | 104500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.12      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20899      |\n",
      "|    policy_loss        | -1.24      |\n",
      "|    reward             | 0.06590088 |\n",
      "|    std                | 5.18       |\n",
      "|    value_loss         | 0.0718     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 21000       |\n",
      "|    time_elapsed       | 484         |\n",
      "|    total_timesteps    | 105000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.14       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20999       |\n",
      "|    policy_loss        | -0.168      |\n",
      "|    reward             | 0.010879688 |\n",
      "|    std                | 5.23        |\n",
      "|    value_loss         | 0.0094      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 21100       |\n",
      "|    time_elapsed       | 486         |\n",
      "|    total_timesteps    | 105500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.15       |\n",
      "|    explained_variance | 0.242       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21099       |\n",
      "|    policy_loss        | 1.3         |\n",
      "|    reward             | 0.042250097 |\n",
      "|    std                | 5.27        |\n",
      "|    value_loss         | 0.0543      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 21200      |\n",
      "|    time_elapsed       | 488        |\n",
      "|    total_timesteps    | 106000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.15      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21199      |\n",
      "|    policy_loss        | 0.0622     |\n",
      "|    reward             | 0.09609356 |\n",
      "|    std                | 5.26       |\n",
      "|    value_loss         | 0.0328     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 21300      |\n",
      "|    time_elapsed       | 491        |\n",
      "|    total_timesteps    | 106500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21299      |\n",
      "|    policy_loss        | 1.11       |\n",
      "|    reward             | 0.36088783 |\n",
      "|    std                | 5.25       |\n",
      "|    value_loss         | 0.309      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 21400        |\n",
      "|    time_elapsed       | 493          |\n",
      "|    total_timesteps    | 107000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.17        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21399        |\n",
      "|    policy_loss        | -0.0146      |\n",
      "|    reward             | -0.049602248 |\n",
      "|    std                | 5.29         |\n",
      "|    value_loss         | 0.00374      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 21500       |\n",
      "|    time_elapsed       | 495         |\n",
      "|    total_timesteps    | 107500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.19       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21499       |\n",
      "|    policy_loss        | 1.01        |\n",
      "|    reward             | -0.12086802 |\n",
      "|    std                | 5.36        |\n",
      "|    value_loss         | 0.0462      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 216      |\n",
      "|    iterations         | 21600    |\n",
      "|    time_elapsed       | 497      |\n",
      "|    total_timesteps    | 108000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 21599    |\n",
      "|    policy_loss        | 0.635    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 5.42     |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 21700        |\n",
      "|    time_elapsed       | 500          |\n",
      "|    total_timesteps    | 108500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.23        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21699        |\n",
      "|    policy_loss        | 0.169        |\n",
      "|    reward             | -0.050580777 |\n",
      "|    std                | 5.48         |\n",
      "|    value_loss         | 0.00451      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 21800      |\n",
      "|    time_elapsed       | 502        |\n",
      "|    total_timesteps    | 109000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.25      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21799      |\n",
      "|    policy_loss        | -0.335     |\n",
      "|    reward             | 0.11955481 |\n",
      "|    std                | 5.53       |\n",
      "|    value_loss         | 0.00453    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 21900       |\n",
      "|    time_elapsed       | 504         |\n",
      "|    total_timesteps    | 109500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.27       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21899       |\n",
      "|    policy_loss        | -0.719      |\n",
      "|    reward             | -0.17245962 |\n",
      "|    std                | 5.58        |\n",
      "|    value_loss         | 0.0138      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 22000      |\n",
      "|    time_elapsed       | 507        |\n",
      "|    total_timesteps    | 110000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.28      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 21999      |\n",
      "|    policy_loss        | 5.11       |\n",
      "|    reward             | -0.1919102 |\n",
      "|    std                | 5.63       |\n",
      "|    value_loss         | 1.16       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 22100      |\n",
      "|    time_elapsed       | 509        |\n",
      "|    total_timesteps    | 110500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.29      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22099      |\n",
      "|    policy_loss        | -10        |\n",
      "|    reward             | 0.20864873 |\n",
      "|    std                | 5.64       |\n",
      "|    value_loss         | 2.44       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 216       |\n",
      "|    iterations         | 22200     |\n",
      "|    time_elapsed       | 512       |\n",
      "|    total_timesteps    | 111000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.29     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 22199     |\n",
      "|    policy_loss        | -1.37     |\n",
      "|    reward             | 0.4946472 |\n",
      "|    std                | 5.65      |\n",
      "|    value_loss         | 0.204     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 22300       |\n",
      "|    time_elapsed       | 514         |\n",
      "|    total_timesteps    | 111500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.29       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22299       |\n",
      "|    policy_loss        | 1.62        |\n",
      "|    reward             | -0.10528056 |\n",
      "|    std                | 5.65        |\n",
      "|    value_loss         | 0.0909      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 22400       |\n",
      "|    time_elapsed       | 516         |\n",
      "|    total_timesteps    | 112000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.31       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22399       |\n",
      "|    policy_loss        | -4.35       |\n",
      "|    reward             | -0.57204026 |\n",
      "|    std                | 5.71        |\n",
      "|    value_loss         | 0.585       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 22500       |\n",
      "|    time_elapsed       | 518         |\n",
      "|    total_timesteps    | 112500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.32       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22499       |\n",
      "|    policy_loss        | -2.89       |\n",
      "|    reward             | -0.05637854 |\n",
      "|    std                | 5.74        |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 22600        |\n",
      "|    time_elapsed       | 521          |\n",
      "|    total_timesteps    | 113000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.33        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22599        |\n",
      "|    policy_loss        | -0.938       |\n",
      "|    reward             | -0.054360412 |\n",
      "|    std                | 5.76         |\n",
      "|    value_loss         | 0.0309       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 22700      |\n",
      "|    time_elapsed       | 523        |\n",
      "|    total_timesteps    | 113500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.34      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22699      |\n",
      "|    policy_loss        | 2.2        |\n",
      "|    reward             | 0.05478418 |\n",
      "|    std                | 5.81       |\n",
      "|    value_loss         | 0.118      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 22800      |\n",
      "|    time_elapsed       | 525        |\n",
      "|    total_timesteps    | 114000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.37      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 22799      |\n",
      "|    policy_loss        | -0.555     |\n",
      "|    reward             | 0.00465625 |\n",
      "|    std                | 5.87       |\n",
      "|    value_loss         | 0.015      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 22900       |\n",
      "|    time_elapsed       | 527         |\n",
      "|    total_timesteps    | 114500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.38       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22899       |\n",
      "|    policy_loss        | 3.6         |\n",
      "|    reward             | -0.20872237 |\n",
      "|    std                | 5.9         |\n",
      "|    value_loss         | 0.325       |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 130\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 120693.35\n",
      "total_reward: 20693.35\n",
      "total_cost: 924.00\n",
      "total_trades: 1327\n",
      "Sharpe: 0.453\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 216           |\n",
      "|    iterations         | 23000         |\n",
      "|    time_elapsed       | 530           |\n",
      "|    total_timesteps    | 115000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -6.4          |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 22999         |\n",
      "|    policy_loss        | 0.215         |\n",
      "|    reward             | -0.0002973633 |\n",
      "|    std                | 5.97          |\n",
      "|    value_loss         | 0.00701       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 23100        |\n",
      "|    time_elapsed       | 532          |\n",
      "|    total_timesteps    | 115500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.43        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 23099        |\n",
      "|    policy_loss        | 0.151        |\n",
      "|    reward             | -0.028445264 |\n",
      "|    std                | 6.03         |\n",
      "|    value_loss         | 0.0542       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 216        |\n",
      "|    iterations         | 23200      |\n",
      "|    time_elapsed       | 534        |\n",
      "|    total_timesteps    | 116000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.44      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 23199      |\n",
      "|    policy_loss        | 0.0435     |\n",
      "|    reward             | 0.01910669 |\n",
      "|    std                | 6.08       |\n",
      "|    value_loss         | 0.00362    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 216          |\n",
      "|    iterations         | 23300        |\n",
      "|    time_elapsed       | 537          |\n",
      "|    total_timesteps    | 116500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.45        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 23299        |\n",
      "|    policy_loss        | 0.149        |\n",
      "|    reward             | -0.036549952 |\n",
      "|    std                | 6.12         |\n",
      "|    value_loss         | 0.00571      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 23400       |\n",
      "|    time_elapsed       | 539         |\n",
      "|    total_timesteps    | 117000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.46       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23399       |\n",
      "|    policy_loss        | -0.14       |\n",
      "|    reward             | -0.08551716 |\n",
      "|    std                | 6.13        |\n",
      "|    value_loss         | 0.00456     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 216         |\n",
      "|    iterations         | 23500       |\n",
      "|    time_elapsed       | 541         |\n",
      "|    total_timesteps    | 117500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.47       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23499       |\n",
      "|    policy_loss        | -0.111      |\n",
      "|    reward             | -0.07504902 |\n",
      "|    std                | 6.17        |\n",
      "|    value_loss         | 0.00341     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 23600       |\n",
      "|    time_elapsed       | 543         |\n",
      "|    total_timesteps    | 118000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23599       |\n",
      "|    policy_loss        | 5.53        |\n",
      "|    reward             | -0.23639561 |\n",
      "|    std                | 6.21        |\n",
      "|    value_loss         | 1.05        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 23700       |\n",
      "|    time_elapsed       | 545         |\n",
      "|    total_timesteps    | 118500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23699       |\n",
      "|    policy_loss        | -6.74       |\n",
      "|    reward             | -0.18649796 |\n",
      "|    std                | 6.2         |\n",
      "|    value_loss         | 1.24        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 23800       |\n",
      "|    time_elapsed       | 548         |\n",
      "|    total_timesteps    | 119000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23799       |\n",
      "|    policy_loss        | 2.91        |\n",
      "|    reward             | -0.22268726 |\n",
      "|    std                | 6.21        |\n",
      "|    value_loss         | 0.296       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 23900      |\n",
      "|    time_elapsed       | 550        |\n",
      "|    total_timesteps    | 119500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.49      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 23899      |\n",
      "|    policy_loss        | 1.1        |\n",
      "|    reward             | 0.13392906 |\n",
      "|    std                | 6.24       |\n",
      "|    value_loss         | 0.0272     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 24000        |\n",
      "|    time_elapsed       | 552          |\n",
      "|    total_timesteps    | 120000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.5         |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 23999        |\n",
      "|    policy_loss        | -0.149       |\n",
      "|    reward             | -0.015742676 |\n",
      "|    std                | 6.28         |\n",
      "|    value_loss         | 0.0161       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 24100        |\n",
      "|    time_elapsed       | 554          |\n",
      "|    total_timesteps    | 120500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.52        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24099        |\n",
      "|    policy_loss        | -0.56        |\n",
      "|    reward             | -0.059210792 |\n",
      "|    std                | 6.35         |\n",
      "|    value_loss         | 0.0121       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 24200       |\n",
      "|    time_elapsed       | 557         |\n",
      "|    total_timesteps    | 121000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.55       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24199       |\n",
      "|    policy_loss        | -0.695      |\n",
      "|    reward             | 0.060553566 |\n",
      "|    std                | 6.44        |\n",
      "|    value_loss         | 0.0204      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 24300      |\n",
      "|    time_elapsed       | 559        |\n",
      "|    total_timesteps    | 121500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.56      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24299      |\n",
      "|    policy_loss        | 0.44       |\n",
      "|    reward             | 0.12719238 |\n",
      "|    std                | 6.47       |\n",
      "|    value_loss         | 0.0356     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 24400      |\n",
      "|    time_elapsed       | 561        |\n",
      "|    total_timesteps    | 122000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.57      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24399      |\n",
      "|    policy_loss        | -0.66      |\n",
      "|    reward             | 0.02927141 |\n",
      "|    std                | 6.49       |\n",
      "|    value_loss         | 0.0154     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 24500        |\n",
      "|    time_elapsed       | 563          |\n",
      "|    total_timesteps    | 122500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.57        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24499        |\n",
      "|    policy_loss        | 0.837        |\n",
      "|    reward             | -0.086847536 |\n",
      "|    std                | 6.51         |\n",
      "|    value_loss         | 0.0302       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 24600        |\n",
      "|    time_elapsed       | 566          |\n",
      "|    total_timesteps    | 123000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.59        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24599        |\n",
      "|    policy_loss        | 1.23         |\n",
      "|    reward             | -0.028334668 |\n",
      "|    std                | 6.58         |\n",
      "|    value_loss         | 0.0781       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 24700       |\n",
      "|    time_elapsed       | 568         |\n",
      "|    total_timesteps    | 123500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.61       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24699       |\n",
      "|    policy_loss        | -2.07       |\n",
      "|    reward             | -0.20147969 |\n",
      "|    std                | 6.62        |\n",
      "|    value_loss         | 0.441       |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 140\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 241470.03\n",
      "total_reward: 141470.03\n",
      "total_cost: 1473.93\n",
      "total_trades: 1396\n",
      "Sharpe: 0.797\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 217       |\n",
      "|    iterations         | 24800     |\n",
      "|    time_elapsed       | 570       |\n",
      "|    total_timesteps    | 124000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.61     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 24799     |\n",
      "|    policy_loss        | 1.81      |\n",
      "|    reward             | 0.3022787 |\n",
      "|    std                | 6.62      |\n",
      "|    value_loss         | 0.099     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 24900       |\n",
      "|    time_elapsed       | 572         |\n",
      "|    total_timesteps    | 124500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.61       |\n",
      "|    explained_variance | 0.00365     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24899       |\n",
      "|    policy_loss        | -0.177      |\n",
      "|    reward             | -0.02601261 |\n",
      "|    std                | 6.64        |\n",
      "|    value_loss         | 0.00947     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 25000        |\n",
      "|    time_elapsed       | 575          |\n",
      "|    total_timesteps    | 125000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.63        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24999        |\n",
      "|    policy_loss        | 0.256        |\n",
      "|    reward             | -0.029575195 |\n",
      "|    std                | 6.71         |\n",
      "|    value_loss         | 0.00566      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 25100       |\n",
      "|    time_elapsed       | 577         |\n",
      "|    total_timesteps    | 125500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.65       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25099       |\n",
      "|    policy_loss        | 0.0499      |\n",
      "|    reward             | -0.01622046 |\n",
      "|    std                | 6.77        |\n",
      "|    value_loss         | 0.00358     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 25200      |\n",
      "|    time_elapsed       | 579        |\n",
      "|    total_timesteps    | 126000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.66      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25199      |\n",
      "|    policy_loss        | 1.61       |\n",
      "|    reward             | 0.20671216 |\n",
      "|    std                | 6.81       |\n",
      "|    value_loss         | 0.0852     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 25300       |\n",
      "|    time_elapsed       | 581         |\n",
      "|    total_timesteps    | 126500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.68       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25299       |\n",
      "|    policy_loss        | -1.53       |\n",
      "|    reward             | -0.22063965 |\n",
      "|    std                | 6.87        |\n",
      "|    value_loss         | 0.056       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 25400       |\n",
      "|    time_elapsed       | 584         |\n",
      "|    total_timesteps    | 127000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.69       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25399       |\n",
      "|    policy_loss        | 0.892       |\n",
      "|    reward             | 0.018502442 |\n",
      "|    std                | 6.93        |\n",
      "|    value_loss         | 0.0576      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 25500       |\n",
      "|    time_elapsed       | 586         |\n",
      "|    total_timesteps    | 127500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.71       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25499       |\n",
      "|    policy_loss        | 1.29        |\n",
      "|    reward             | -0.20330156 |\n",
      "|    std                | 7.01        |\n",
      "|    value_loss         | 0.0441      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 25600      |\n",
      "|    time_elapsed       | 588        |\n",
      "|    total_timesteps    | 128000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25599      |\n",
      "|    policy_loss        | -0.543     |\n",
      "|    reward             | -0.3227532 |\n",
      "|    std                | 7.08       |\n",
      "|    value_loss         | 0.213      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 25700      |\n",
      "|    time_elapsed       | 590        |\n",
      "|    total_timesteps    | 128500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.75      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 25699      |\n",
      "|    policy_loss        | -0.545     |\n",
      "|    reward             | 0.06295706 |\n",
      "|    std                | 7.13       |\n",
      "|    value_loss         | 0.0228     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 25800        |\n",
      "|    time_elapsed       | 593          |\n",
      "|    total_timesteps    | 129000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.76        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25799        |\n",
      "|    policy_loss        | -1.26        |\n",
      "|    reward             | 0.0044160155 |\n",
      "|    std                | 7.17         |\n",
      "|    value_loss         | 0.0438       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 25900       |\n",
      "|    time_elapsed       | 595         |\n",
      "|    total_timesteps    | 129500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.79       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25899       |\n",
      "|    policy_loss        | 1.04        |\n",
      "|    reward             | -0.02152793 |\n",
      "|    std                | 7.29        |\n",
      "|    value_loss         | 0.0483      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 26000        |\n",
      "|    time_elapsed       | 597          |\n",
      "|    total_timesteps    | 130000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.8         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25999        |\n",
      "|    policy_loss        | -0.869       |\n",
      "|    reward             | 0.0051776855 |\n",
      "|    std                | 7.34         |\n",
      "|    value_loss         | 0.0236       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 26100      |\n",
      "|    time_elapsed       | 599        |\n",
      "|    total_timesteps    | 130500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26099      |\n",
      "|    policy_loss        | -0.662     |\n",
      "|    reward             | 0.08467431 |\n",
      "|    std                | 7.48       |\n",
      "|    value_loss         | 0.0302     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 26200      |\n",
      "|    time_elapsed       | 602        |\n",
      "|    total_timesteps    | 131000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26199      |\n",
      "|    policy_loss        | 1.64       |\n",
      "|    reward             | 0.35255724 |\n",
      "|    std                | 7.53       |\n",
      "|    value_loss         | 0.101      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 26300      |\n",
      "|    time_elapsed       | 604        |\n",
      "|    total_timesteps    | 131500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.86      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26299      |\n",
      "|    policy_loss        | -5.66      |\n",
      "|    reward             | 0.75781614 |\n",
      "|    std                | 7.55       |\n",
      "|    value_loss         | 1.1        |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 26400       |\n",
      "|    time_elapsed       | 606         |\n",
      "|    total_timesteps    | 132000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26399       |\n",
      "|    policy_loss        | -0.88       |\n",
      "|    reward             | -0.40287814 |\n",
      "|    std                | 7.54        |\n",
      "|    value_loss         | 0.0467      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 150\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 241336.75\n",
      "total_reward: 141336.75\n",
      "total_cost: 924.77\n",
      "total_trades: 1447\n",
      "Sharpe: 0.796\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 26500      |\n",
      "|    time_elapsed       | 608        |\n",
      "|    total_timesteps    | 132500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.85      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26499      |\n",
      "|    policy_loss        | 0.565      |\n",
      "|    reward             | 0.14022163 |\n",
      "|    std                | 7.51       |\n",
      "|    value_loss         | 0.0816     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 26600       |\n",
      "|    time_elapsed       | 611         |\n",
      "|    total_timesteps    | 133000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.86       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26599       |\n",
      "|    policy_loss        | -2.02       |\n",
      "|    reward             | 0.014725097 |\n",
      "|    std                | 7.54        |\n",
      "|    value_loss         | 0.122       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 26700        |\n",
      "|    time_elapsed       | 613          |\n",
      "|    total_timesteps    | 133500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.85        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26699        |\n",
      "|    policy_loss        | 0.901        |\n",
      "|    reward             | -0.043396376 |\n",
      "|    std                | 7.52         |\n",
      "|    value_loss         | 0.0556       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 26800      |\n",
      "|    time_elapsed       | 615        |\n",
      "|    total_timesteps    | 134000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.87      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 26799      |\n",
      "|    policy_loss        | -3.57      |\n",
      "|    reward             | -0.3996331 |\n",
      "|    std                | 7.55       |\n",
      "|    value_loss         | 0.646      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 26900       |\n",
      "|    time_elapsed       | 617         |\n",
      "|    total_timesteps    | 134500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.88       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26899       |\n",
      "|    policy_loss        | -0.839      |\n",
      "|    reward             | 0.030778052 |\n",
      "|    std                | 7.61        |\n",
      "|    value_loss         | 0.0183      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 27000        |\n",
      "|    time_elapsed       | 619          |\n",
      "|    total_timesteps    | 135000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.9         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26999        |\n",
      "|    policy_loss        | 2.88         |\n",
      "|    reward             | -0.016159741 |\n",
      "|    std                | 7.67         |\n",
      "|    value_loss         | 0.196        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 27100      |\n",
      "|    time_elapsed       | 622        |\n",
      "|    total_timesteps    | 135500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27099      |\n",
      "|    policy_loss        | 0.26       |\n",
      "|    reward             | 0.11945962 |\n",
      "|    std                | 7.63       |\n",
      "|    value_loss         | 0.00306    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 27200      |\n",
      "|    time_elapsed       | 624        |\n",
      "|    total_timesteps    | 136000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27199      |\n",
      "|    policy_loss        | 3.66       |\n",
      "|    reward             | 0.41296554 |\n",
      "|    std                | 7.65       |\n",
      "|    value_loss         | 0.432      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 217       |\n",
      "|    iterations         | 27300     |\n",
      "|    time_elapsed       | 626       |\n",
      "|    total_timesteps    | 136500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.89     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27299     |\n",
      "|    policy_loss        | -0.0762   |\n",
      "|    reward             | 0.7884979 |\n",
      "|    std                | 7.63      |\n",
      "|    value_loss         | 0.121     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 27400       |\n",
      "|    time_elapsed       | 628         |\n",
      "|    total_timesteps    | 137000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27399       |\n",
      "|    policy_loss        | -1          |\n",
      "|    reward             | 0.008362366 |\n",
      "|    std                | 7.7         |\n",
      "|    value_loss         | 0.023       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 27500      |\n",
      "|    time_elapsed       | 631        |\n",
      "|    total_timesteps    | 137500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.91      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27499      |\n",
      "|    policy_loss        | 1.64       |\n",
      "|    reward             | 0.26051244 |\n",
      "|    std                | 7.71       |\n",
      "|    value_loss         | 0.0852     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 27600      |\n",
      "|    time_elapsed       | 633        |\n",
      "|    total_timesteps    | 138000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27599      |\n",
      "|    policy_loss        | 0.134      |\n",
      "|    reward             | 0.05399116 |\n",
      "|    std                | 7.73       |\n",
      "|    value_loss         | 0.0702     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 27700       |\n",
      "|    time_elapsed       | 635         |\n",
      "|    total_timesteps    | 138500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27699       |\n",
      "|    policy_loss        | -4.08       |\n",
      "|    reward             | -0.21191572 |\n",
      "|    std                | 7.72        |\n",
      "|    value_loss         | 0.473       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 27800      |\n",
      "|    time_elapsed       | 637        |\n",
      "|    total_timesteps    | 139000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.92      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27799      |\n",
      "|    policy_loss        | -1.8       |\n",
      "|    reward             | 0.30350652 |\n",
      "|    std                | 7.75       |\n",
      "|    value_loss         | 0.159      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 27900       |\n",
      "|    time_elapsed       | 640         |\n",
      "|    total_timesteps    | 139500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -6.94       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27899       |\n",
      "|    policy_loss        | -4.14       |\n",
      "|    reward             | -0.01897959 |\n",
      "|    std                | 7.81        |\n",
      "|    value_loss         | 0.811       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 28000      |\n",
      "|    time_elapsed       | 642        |\n",
      "|    total_timesteps    | 140000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -6.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 27999      |\n",
      "|    policy_loss        | -1.09      |\n",
      "|    reward             | 0.07368022 |\n",
      "|    std                | 7.89       |\n",
      "|    value_loss         | 0.0293     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 28100        |\n",
      "|    time_elapsed       | 644          |\n",
      "|    total_timesteps    | 140500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.96        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 28099        |\n",
      "|    policy_loss        | -1.14        |\n",
      "|    reward             | 0.0074309437 |\n",
      "|    std                | 7.91         |\n",
      "|    value_loss         | 0.0434       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 28200        |\n",
      "|    time_elapsed       | 646          |\n",
      "|    total_timesteps    | 141000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -6.99        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 28199        |\n",
      "|    policy_loss        | -0.436       |\n",
      "|    reward             | -0.036110204 |\n",
      "|    std                | 8.02         |\n",
      "|    value_loss         | 0.00925      |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 217       |\n",
      "|    iterations         | 28300     |\n",
      "|    time_elapsed       | 649       |\n",
      "|    total_timesteps    | 141500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.01     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28299     |\n",
      "|    policy_loss        | 2.54      |\n",
      "|    reward             | 0.1517552 |\n",
      "|    std                | 8.12      |\n",
      "|    value_loss         | 0.186     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 28400      |\n",
      "|    time_elapsed       | 651        |\n",
      "|    total_timesteps    | 142000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.01      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28399      |\n",
      "|    policy_loss        | -8.45      |\n",
      "|    reward             | -1.2334486 |\n",
      "|    std                | 8.15       |\n",
      "|    value_loss         | 1.69       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 28500      |\n",
      "|    time_elapsed       | 653        |\n",
      "|    total_timesteps    | 142500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.03      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28499      |\n",
      "|    policy_loss        | -1.72      |\n",
      "|    reward             | 0.19783233 |\n",
      "|    std                | 8.23       |\n",
      "|    value_loss         | 0.16       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 28600        |\n",
      "|    time_elapsed       | 655          |\n",
      "|    total_timesteps    | 143000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.06        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 28599        |\n",
      "|    policy_loss        | 2.09         |\n",
      "|    reward             | -0.024311524 |\n",
      "|    std                | 8.32         |\n",
      "|    value_loss         | 0.407        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 28700       |\n",
      "|    time_elapsed       | 658         |\n",
      "|    total_timesteps    | 143500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 28699       |\n",
      "|    policy_loss        | -0.285      |\n",
      "|    reward             | 0.070574366 |\n",
      "|    std                | 8.35        |\n",
      "|    value_loss         | 0.00244     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 28800       |\n",
      "|    time_elapsed       | 660         |\n",
      "|    total_timesteps    | 144000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.06       |\n",
      "|    explained_variance | -4.23       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 28799       |\n",
      "|    policy_loss        | 1.51        |\n",
      "|    reward             | 0.026373144 |\n",
      "|    std                | 8.34        |\n",
      "|    value_loss         | 0.065       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 28900     |\n",
      "|    time_elapsed       | 662       |\n",
      "|    total_timesteps    | 144500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.07     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 28899     |\n",
      "|    policy_loss        | 0.229     |\n",
      "|    reward             | 0.1315542 |\n",
      "|    std                | 8.37      |\n",
      "|    value_loss         | 0.0241    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 29000      |\n",
      "|    time_elapsed       | 665        |\n",
      "|    total_timesteps    | 145000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.07      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28999      |\n",
      "|    policy_loss        | -0.756     |\n",
      "|    reward             | 0.08964785 |\n",
      "|    std                | 8.38       |\n",
      "|    value_loss         | 0.0135     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 29100       |\n",
      "|    time_elapsed       | 667         |\n",
      "|    total_timesteps    | 145500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.08       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29099       |\n",
      "|    policy_loss        | 3.49        |\n",
      "|    reward             | 0.023072103 |\n",
      "|    std                | 8.42        |\n",
      "|    value_loss         | 0.269       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 29200      |\n",
      "|    time_elapsed       | 669        |\n",
      "|    total_timesteps    | 146000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29199      |\n",
      "|    policy_loss        | 2.28       |\n",
      "|    reward             | 0.11722546 |\n",
      "|    std                | 8.49       |\n",
      "|    value_loss         | 0.171      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 29300      |\n",
      "|    time_elapsed       | 671        |\n",
      "|    total_timesteps    | 146500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29299      |\n",
      "|    policy_loss        | -4.4       |\n",
      "|    reward             | -0.8896172 |\n",
      "|    std                | 8.56       |\n",
      "|    value_loss         | 0.491      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 29400        |\n",
      "|    time_elapsed       | 674          |\n",
      "|    total_timesteps    | 147000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.11        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 29399        |\n",
      "|    policy_loss        | -3.86        |\n",
      "|    reward             | -0.058015235 |\n",
      "|    std                | 8.56         |\n",
      "|    value_loss         | 0.312        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 29500      |\n",
      "|    time_elapsed       | 676        |\n",
      "|    total_timesteps    | 147500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29499      |\n",
      "|    policy_loss        | 6          |\n",
      "|    reward             | 0.10313789 |\n",
      "|    std                | 8.57       |\n",
      "|    value_loss         | 1.62       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 29600       |\n",
      "|    time_elapsed       | 678         |\n",
      "|    total_timesteps    | 148000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.12       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29599       |\n",
      "|    policy_loss        | 0.0481      |\n",
      "|    reward             | 0.082732566 |\n",
      "|    std                | 8.59        |\n",
      "|    value_loss         | 0.00328     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 29700       |\n",
      "|    time_elapsed       | 680         |\n",
      "|    total_timesteps    | 148500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.14       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29699       |\n",
      "|    policy_loss        | -4.58       |\n",
      "|    reward             | 0.031629737 |\n",
      "|    std                | 8.66        |\n",
      "|    value_loss         | 0.433       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 29800       |\n",
      "|    time_elapsed       | 683         |\n",
      "|    total_timesteps    | 149000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.15       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29799       |\n",
      "|    policy_loss        | -0.57       |\n",
      "|    reward             | -0.15578203 |\n",
      "|    std                | 8.69        |\n",
      "|    value_loss         | 0.0869      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 29900      |\n",
      "|    time_elapsed       | 685        |\n",
      "|    total_timesteps    | 149500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.15      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29899      |\n",
      "|    policy_loss        | 3.47       |\n",
      "|    reward             | 0.05094015 |\n",
      "|    std                | 8.73       |\n",
      "|    value_loss         | 0.333      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 30000      |\n",
      "|    time_elapsed       | 687        |\n",
      "|    total_timesteps    | 150000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.16      |\n",
      "|    explained_variance | -0.0796    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29999      |\n",
      "|    policy_loss        | -3.07      |\n",
      "|    reward             | 0.12922119 |\n",
      "|    std                | 8.76       |\n",
      "|    value_loss         | 0.535      |\n",
      "--------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 170\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 255875.31\n",
      "total_reward: 155875.31\n",
      "total_cost: 2802.04\n",
      "total_trades: 1535\n",
      "Sharpe: 0.846\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 30100       |\n",
      "|    time_elapsed       | 689         |\n",
      "|    total_timesteps    | 150500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.16       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30099       |\n",
      "|    policy_loss        | 0.0907      |\n",
      "|    reward             | -0.24675512 |\n",
      "|    std                | 8.76        |\n",
      "|    value_loss         | 0.0182      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 30200       |\n",
      "|    time_elapsed       | 692         |\n",
      "|    total_timesteps    | 151000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.18       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30199       |\n",
      "|    policy_loss        | 0.973       |\n",
      "|    reward             | -0.29904184 |\n",
      "|    std                | 8.85        |\n",
      "|    value_loss         | 0.077       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 30300       |\n",
      "|    time_elapsed       | 694         |\n",
      "|    total_timesteps    | 151500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.21       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30299       |\n",
      "|    policy_loss        | -0.39       |\n",
      "|    reward             | -0.16434336 |\n",
      "|    std                | 9.02        |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 30400       |\n",
      "|    time_elapsed       | 696         |\n",
      "|    total_timesteps    | 152000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.21       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30399       |\n",
      "|    policy_loss        | -0.751      |\n",
      "|    reward             | -0.50693154 |\n",
      "|    std                | 9.01        |\n",
      "|    value_loss         | 0.242       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 30500      |\n",
      "|    time_elapsed       | 698        |\n",
      "|    total_timesteps    | 152500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.22      |\n",
      "|    explained_variance | 0.00183    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 30499      |\n",
      "|    policy_loss        | -2.58      |\n",
      "|    reward             | -0.7165879 |\n",
      "|    std                | 9.06       |\n",
      "|    value_loss         | 0.281      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 30600       |\n",
      "|    time_elapsed       | 701         |\n",
      "|    total_timesteps    | 153000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.23       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30599       |\n",
      "|    policy_loss        | -1.25       |\n",
      "|    reward             | -0.21229956 |\n",
      "|    std                | 9.11        |\n",
      "|    value_loss         | 0.0476      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 30700      |\n",
      "|    time_elapsed       | 703        |\n",
      "|    total_timesteps    | 153500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.25      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 30699      |\n",
      "|    policy_loss        | 1.63       |\n",
      "|    reward             | 0.71393764 |\n",
      "|    std                | 9.19       |\n",
      "|    value_loss         | 0.0586     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 30800       |\n",
      "|    time_elapsed       | 705         |\n",
      "|    total_timesteps    | 154000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.25       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30799       |\n",
      "|    policy_loss        | 3.92        |\n",
      "|    reward             | 0.016774707 |\n",
      "|    std                | 9.21        |\n",
      "|    value_loss         | 0.34        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 30900     |\n",
      "|    time_elapsed       | 707       |\n",
      "|    total_timesteps    | 154500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.25     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 30899     |\n",
      "|    policy_loss        | -1.54     |\n",
      "|    reward             | 0.8367964 |\n",
      "|    std                | 9.22      |\n",
      "|    value_loss         | 0.33      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 31000        |\n",
      "|    time_elapsed       | 710          |\n",
      "|    total_timesteps    | 155000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.26        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 30999        |\n",
      "|    policy_loss        | -1.04        |\n",
      "|    reward             | -0.014439136 |\n",
      "|    std                | 9.26         |\n",
      "|    value_loss         | 0.0698       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 31100      |\n",
      "|    time_elapsed       | 712        |\n",
      "|    total_timesteps    | 155500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.27      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31099      |\n",
      "|    policy_loss        | 12.1       |\n",
      "|    reward             | 0.49658477 |\n",
      "|    std                | 9.27       |\n",
      "|    value_loss         | 3.06       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 31200      |\n",
      "|    time_elapsed       | 714        |\n",
      "|    total_timesteps    | 156000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.27      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31199      |\n",
      "|    policy_loss        | 2.19       |\n",
      "|    reward             | -0.0735167 |\n",
      "|    std                | 9.31       |\n",
      "|    value_loss         | 0.152      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 31300        |\n",
      "|    time_elapsed       | 716          |\n",
      "|    total_timesteps    | 156500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.26        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 31299        |\n",
      "|    policy_loss        | -1           |\n",
      "|    reward             | -0.006595984 |\n",
      "|    std                | 9.27         |\n",
      "|    value_loss         | 0.0199       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 31400        |\n",
      "|    time_elapsed       | 719          |\n",
      "|    total_timesteps    | 157000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.29        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 31399        |\n",
      "|    policy_loss        | 1.07         |\n",
      "|    reward             | -0.045554686 |\n",
      "|    std                | 9.42         |\n",
      "|    value_loss         | 0.0385       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 31500       |\n",
      "|    time_elapsed       | 721         |\n",
      "|    total_timesteps    | 157500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.3        |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31499       |\n",
      "|    policy_loss        | 3.6         |\n",
      "|    reward             | 0.022777941 |\n",
      "|    std                | 9.43        |\n",
      "|    value_loss         | 0.256       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 31600      |\n",
      "|    time_elapsed       | 723        |\n",
      "|    total_timesteps    | 158000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.29      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31599      |\n",
      "|    policy_loss        | -2.94      |\n",
      "|    reward             | 0.33316052 |\n",
      "|    std                | 9.41       |\n",
      "|    value_loss         | 0.301      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 31700      |\n",
      "|    time_elapsed       | 725        |\n",
      "|    total_timesteps    | 158500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.31      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31699      |\n",
      "|    policy_loss        | -3.1       |\n",
      "|    reward             | -0.6190006 |\n",
      "|    std                | 9.49       |\n",
      "|    value_loss         | 0.267      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 31800     |\n",
      "|    time_elapsed       | 727       |\n",
      "|    total_timesteps    | 159000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.29     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 31799     |\n",
      "|    policy_loss        | 4.03      |\n",
      "|    reward             | 0.4182395 |\n",
      "|    std                | 9.44      |\n",
      "|    value_loss         | 0.568     |\n",
      "-------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 180\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 214184.60\n",
      "total_reward: 114184.60\n",
      "total_cost: 3884.46\n",
      "total_trades: 1466\n",
      "Sharpe: 0.719\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 31900      |\n",
      "|    time_elapsed       | 730        |\n",
      "|    total_timesteps    | 159500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.31      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31899      |\n",
      "|    policy_loss        | 1.03       |\n",
      "|    reward             | 0.35443848 |\n",
      "|    std                | 9.5        |\n",
      "|    value_loss         | 0.0452     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 32000      |\n",
      "|    time_elapsed       | 732        |\n",
      "|    total_timesteps    | 160000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.3       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31999      |\n",
      "|    policy_loss        | -3.16      |\n",
      "|    reward             | 0.33561328 |\n",
      "|    std                | 9.46       |\n",
      "|    value_loss         | 0.385      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 32100       |\n",
      "|    time_elapsed       | 734         |\n",
      "|    total_timesteps    | 160500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.31       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32099       |\n",
      "|    policy_loss        | -1.22       |\n",
      "|    reward             | -0.06805005 |\n",
      "|    std                | 9.52        |\n",
      "|    value_loss         | 0.0574      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 32200      |\n",
      "|    time_elapsed       | 736        |\n",
      "|    total_timesteps    | 161000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.32      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32199      |\n",
      "|    policy_loss        | 0.433      |\n",
      "|    reward             | 0.06986103 |\n",
      "|    std                | 9.55       |\n",
      "|    value_loss         | 0.053      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 218      |\n",
      "|    iterations         | 32300    |\n",
      "|    time_elapsed       | 739      |\n",
      "|    total_timesteps    | 161500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.32    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 32299    |\n",
      "|    policy_loss        | 0.335    |\n",
      "|    reward             | -0.04095 |\n",
      "|    std                | 9.56     |\n",
      "|    value_loss         | 0.021    |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 32400       |\n",
      "|    time_elapsed       | 741         |\n",
      "|    total_timesteps    | 162000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.32       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32399       |\n",
      "|    policy_loss        | 0.876       |\n",
      "|    reward             | 0.044966456 |\n",
      "|    std                | 9.57        |\n",
      "|    value_loss         | 0.0158      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 32500      |\n",
      "|    time_elapsed       | 743        |\n",
      "|    total_timesteps    | 162500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.34      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32499      |\n",
      "|    policy_loss        | 1.83       |\n",
      "|    reward             | 0.20158872 |\n",
      "|    std                | 9.67       |\n",
      "|    value_loss         | 0.158      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 32600       |\n",
      "|    time_elapsed       | 745         |\n",
      "|    total_timesteps    | 163000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.36       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32599       |\n",
      "|    policy_loss        | -3.19       |\n",
      "|    reward             | -0.02402588 |\n",
      "|    std                | 9.73        |\n",
      "|    value_loss         | 0.194       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 32700      |\n",
      "|    time_elapsed       | 747        |\n",
      "|    total_timesteps    | 163500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.36      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32699      |\n",
      "|    policy_loss        | 7.41       |\n",
      "|    reward             | 0.30809596 |\n",
      "|    std                | 9.73       |\n",
      "|    value_loss         | 1.06       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 32800      |\n",
      "|    time_elapsed       | 750        |\n",
      "|    total_timesteps    | 164000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.36      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32799      |\n",
      "|    policy_loss        | 0.952      |\n",
      "|    reward             | 0.38016888 |\n",
      "|    std                | 9.73       |\n",
      "|    value_loss         | 0.443      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 32900       |\n",
      "|    time_elapsed       | 752         |\n",
      "|    total_timesteps    | 164500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.38       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32899       |\n",
      "|    policy_loss        | -1.62       |\n",
      "|    reward             | -0.08008183 |\n",
      "|    std                | 9.84        |\n",
      "|    value_loss         | 0.0484      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 33000      |\n",
      "|    time_elapsed       | 754        |\n",
      "|    total_timesteps    | 165000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 32999      |\n",
      "|    policy_loss        | 4.38       |\n",
      "|    reward             | 0.45197695 |\n",
      "|    std                | 9.84       |\n",
      "|    value_loss         | 0.659      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 218           |\n",
      "|    iterations         | 33100         |\n",
      "|    time_elapsed       | 757           |\n",
      "|    total_timesteps    | 165500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -7.38         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 33099         |\n",
      "|    policy_loss        | 1.81          |\n",
      "|    reward             | -0.0073392577 |\n",
      "|    std                | 9.87          |\n",
      "|    value_loss         | 0.0893        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 33200      |\n",
      "|    time_elapsed       | 759        |\n",
      "|    total_timesteps    | 166000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.41      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 33199      |\n",
      "|    policy_loss        | -6.32      |\n",
      "|    reward             | 0.91543275 |\n",
      "|    std                | 10         |\n",
      "|    value_loss         | 0.784      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 33300       |\n",
      "|    time_elapsed       | 761         |\n",
      "|    total_timesteps    | 166500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.41       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33299       |\n",
      "|    policy_loss        | -1.75       |\n",
      "|    reward             | -0.13336924 |\n",
      "|    std                | 9.99        |\n",
      "|    value_loss         | 0.0656      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 33400       |\n",
      "|    time_elapsed       | 763         |\n",
      "|    total_timesteps    | 167000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.43       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33399       |\n",
      "|    policy_loss        | -2.51       |\n",
      "|    reward             | -0.11917285 |\n",
      "|    std                | 10.1        |\n",
      "|    value_loss         | 0.184       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 33500       |\n",
      "|    time_elapsed       | 766         |\n",
      "|    total_timesteps    | 167500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.44       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33499       |\n",
      "|    policy_loss        | 0.635       |\n",
      "|    reward             | 0.068163574 |\n",
      "|    std                | 10.1        |\n",
      "|    value_loss         | 0.0145      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 33600       |\n",
      "|    time_elapsed       | 768         |\n",
      "|    total_timesteps    | 168000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.46       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33599       |\n",
      "|    policy_loss        | 0.698       |\n",
      "|    reward             | -0.17676334 |\n",
      "|    std                | 10.2        |\n",
      "|    value_loss         | 0.0374      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 33700       |\n",
      "|    time_elapsed       | 770         |\n",
      "|    total_timesteps    | 168500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.48       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33699       |\n",
      "|    policy_loss        | 5.66        |\n",
      "|    reward             | -0.18195337 |\n",
      "|    std                | 10.3        |\n",
      "|    value_loss         | 0.644       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 33800       |\n",
      "|    time_elapsed       | 772         |\n",
      "|    total_timesteps    | 169000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33799       |\n",
      "|    policy_loss        | 1.73        |\n",
      "|    reward             | -0.27131572 |\n",
      "|    std                | 10.4        |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 33900        |\n",
      "|    time_elapsed       | 775          |\n",
      "|    total_timesteps    | 169500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.49        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33899        |\n",
      "|    policy_loss        | 0.739        |\n",
      "|    reward             | 0.0014395195 |\n",
      "|    std                | 10.4         |\n",
      "|    value_loss         | 0.0498       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 34000       |\n",
      "|    time_elapsed       | 777         |\n",
      "|    total_timesteps    | 170000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.49       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33999       |\n",
      "|    policy_loss        | -0.408      |\n",
      "|    reward             | -0.12026758 |\n",
      "|    std                | 10.4        |\n",
      "|    value_loss         | 0.00378     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 34100      |\n",
      "|    time_elapsed       | 779        |\n",
      "|    total_timesteps    | 170500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.51      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34099      |\n",
      "|    policy_loss        | 2.89       |\n",
      "|    reward             | 0.11051855 |\n",
      "|    std                | 10.5       |\n",
      "|    value_loss         | 0.236      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 34200      |\n",
      "|    time_elapsed       | 781        |\n",
      "|    total_timesteps    | 171000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.52      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34199      |\n",
      "|    policy_loss        | -0.161     |\n",
      "|    reward             | 0.10652539 |\n",
      "|    std                | 10.6       |\n",
      "|    value_loss         | 0.00554    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 34300       |\n",
      "|    time_elapsed       | 784         |\n",
      "|    total_timesteps    | 171500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.55       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34299       |\n",
      "|    policy_loss        | 2.08        |\n",
      "|    reward             | -0.03331958 |\n",
      "|    std                | 10.7        |\n",
      "|    value_loss         | 0.087       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 34400       |\n",
      "|    time_elapsed       | 786         |\n",
      "|    total_timesteps    | 172000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.56       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34399       |\n",
      "|    policy_loss        | 3.53        |\n",
      "|    reward             | 0.002003723 |\n",
      "|    std                | 10.8        |\n",
      "|    value_loss         | 0.264       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 34500      |\n",
      "|    time_elapsed       | 788        |\n",
      "|    total_timesteps    | 172500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.58      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34499      |\n",
      "|    policy_loss        | -2.42      |\n",
      "|    reward             | 0.37158418 |\n",
      "|    std                | 10.9       |\n",
      "|    value_loss         | 0.14       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 34600       |\n",
      "|    time_elapsed       | 791         |\n",
      "|    total_timesteps    | 173000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.59       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34599       |\n",
      "|    policy_loss        | 6.42        |\n",
      "|    reward             | -0.13130596 |\n",
      "|    std                | 10.9        |\n",
      "|    value_loss         | 0.849       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 34700        |\n",
      "|    time_elapsed       | 793          |\n",
      "|    total_timesteps    | 173500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.59        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 34699        |\n",
      "|    policy_loss        | 0.959        |\n",
      "|    reward             | -0.031772353 |\n",
      "|    std                | 10.9         |\n",
      "|    value_loss         | 0.0168       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 34800      |\n",
      "|    time_elapsed       | 795        |\n",
      "|    total_timesteps    | 174000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.59      |\n",
      "|    explained_variance | -2.38e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 34799      |\n",
      "|    policy_loss        | -0.116     |\n",
      "|    reward             | 0.12814564 |\n",
      "|    std                | 11         |\n",
      "|    value_loss         | 0.0591     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 34900       |\n",
      "|    time_elapsed       | 797         |\n",
      "|    total_timesteps    | 174500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.6        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34899       |\n",
      "|    policy_loss        | -4.91       |\n",
      "|    reward             | -0.19991435 |\n",
      "|    std                | 11          |\n",
      "|    value_loss         | 0.43        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 35000     |\n",
      "|    time_elapsed       | 799       |\n",
      "|    total_timesteps    | 175000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.58     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 34999     |\n",
      "|    policy_loss        | -14.4     |\n",
      "|    reward             | 0.9473739 |\n",
      "|    std                | 10.9      |\n",
      "|    value_loss         | 4.06      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 35100       |\n",
      "|    time_elapsed       | 802         |\n",
      "|    total_timesteps    | 175500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.58       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35099       |\n",
      "|    policy_loss        | 1.71        |\n",
      "|    reward             | 0.055641513 |\n",
      "|    std                | 10.9        |\n",
      "|    value_loss         | 0.0764      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 35200       |\n",
      "|    time_elapsed       | 804         |\n",
      "|    total_timesteps    | 176000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.59       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35199       |\n",
      "|    policy_loss        | 2.78        |\n",
      "|    reward             | 0.053480275 |\n",
      "|    std                | 10.9        |\n",
      "|    value_loss         | 0.419       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 35300       |\n",
      "|    time_elapsed       | 806         |\n",
      "|    total_timesteps    | 176500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.59       |\n",
      "|    explained_variance | 0.0829      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35299       |\n",
      "|    policy_loss        | 2.12        |\n",
      "|    reward             | -0.05085254 |\n",
      "|    std                | 10.9        |\n",
      "|    value_loss         | 0.0879      |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 200\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 375900.64\n",
      "total_reward: 275900.64\n",
      "total_cost: 9770.17\n",
      "total_trades: 1517\n",
      "Sharpe: 1.106\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 35400       |\n",
      "|    time_elapsed       | 808         |\n",
      "|    total_timesteps    | 177000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.62       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35399       |\n",
      "|    policy_loss        | 3.2         |\n",
      "|    reward             | -0.17379987 |\n",
      "|    std                | 11.1        |\n",
      "|    value_loss         | 0.211       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 35500       |\n",
      "|    time_elapsed       | 811         |\n",
      "|    total_timesteps    | 177500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.63       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35499       |\n",
      "|    policy_loss        | -3.21       |\n",
      "|    reward             | -0.35287574 |\n",
      "|    std                | 11.2        |\n",
      "|    value_loss         | 0.23        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 35600        |\n",
      "|    time_elapsed       | 813          |\n",
      "|    total_timesteps    | 178000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.63        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 35599        |\n",
      "|    policy_loss        | -0.116       |\n",
      "|    reward             | -0.056146838 |\n",
      "|    std                | 11.2         |\n",
      "|    value_loss         | 0.00116      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 35700       |\n",
      "|    time_elapsed       | 815         |\n",
      "|    total_timesteps    | 178500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.67       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35699       |\n",
      "|    policy_loss        | 1.97        |\n",
      "|    reward             | -0.08296289 |\n",
      "|    std                | 11.4        |\n",
      "|    value_loss         | 0.153       |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 218      |\n",
      "|    iterations         | 35800    |\n",
      "|    time_elapsed       | 817      |\n",
      "|    total_timesteps    | 179000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 35799    |\n",
      "|    policy_loss        | 2.48     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 11.5     |\n",
      "|    value_loss         | 0.15     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 35900      |\n",
      "|    time_elapsed       | 819        |\n",
      "|    total_timesteps    | 179500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.7       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 35899      |\n",
      "|    policy_loss        | 0.417      |\n",
      "|    reward             | -1.1148745 |\n",
      "|    std                | 11.6       |\n",
      "|    value_loss         | 0.0256     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 36000      |\n",
      "|    time_elapsed       | 822        |\n",
      "|    total_timesteps    | 180000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.72      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 35999      |\n",
      "|    policy_loss        | 10.2       |\n",
      "|    reward             | 0.14032122 |\n",
      "|    std                | 11.7       |\n",
      "|    value_loss         | 2.38       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 36100       |\n",
      "|    time_elapsed       | 824         |\n",
      "|    total_timesteps    | 180500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.73       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36099       |\n",
      "|    policy_loss        | -1.12       |\n",
      "|    reward             | 0.037371546 |\n",
      "|    std                | 11.7        |\n",
      "|    value_loss         | 0.0217      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 36200       |\n",
      "|    time_elapsed       | 826         |\n",
      "|    total_timesteps    | 181000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.74       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36199       |\n",
      "|    policy_loss        | -0.716      |\n",
      "|    reward             | 0.017973177 |\n",
      "|    std                | 11.8        |\n",
      "|    value_loss         | 0.0554      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 828         |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.73       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36299       |\n",
      "|    policy_loss        | 2.91        |\n",
      "|    reward             | 0.032886352 |\n",
      "|    std                | 11.7        |\n",
      "|    value_loss         | 0.187       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 36400      |\n",
      "|    time_elapsed       | 830        |\n",
      "|    total_timesteps    | 182000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.75      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36399      |\n",
      "|    policy_loss        | -0.697     |\n",
      "|    reward             | -0.7026227 |\n",
      "|    std                | 11.8       |\n",
      "|    value_loss         | 0.233      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 36500       |\n",
      "|    time_elapsed       | 833         |\n",
      "|    total_timesteps    | 182500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.76       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36499       |\n",
      "|    policy_loss        | 0.781       |\n",
      "|    reward             | -0.36084878 |\n",
      "|    std                | 11.9        |\n",
      "|    value_loss         | 0.0305      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 36600       |\n",
      "|    time_elapsed       | 835         |\n",
      "|    total_timesteps    | 183000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.76       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36599       |\n",
      "|    policy_loss        | -7.11       |\n",
      "|    reward             | -0.06586826 |\n",
      "|    std                | 11.9        |\n",
      "|    value_loss         | 0.737       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 36700       |\n",
      "|    time_elapsed       | 837         |\n",
      "|    total_timesteps    | 183500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.77       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36699       |\n",
      "|    policy_loss        | 0.683       |\n",
      "|    reward             | 0.011790015 |\n",
      "|    std                | 11.9        |\n",
      "|    value_loss         | 0.0115      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 36800      |\n",
      "|    time_elapsed       | 839        |\n",
      "|    total_timesteps    | 184000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.78      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 36799      |\n",
      "|    policy_loss        | 1.47       |\n",
      "|    reward             | 0.17782517 |\n",
      "|    std                | 12         |\n",
      "|    value_loss         | 0.0818     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 36900     |\n",
      "|    time_elapsed       | 841       |\n",
      "|    total_timesteps    | 184500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.79     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 36899     |\n",
      "|    policy_loss        | 1.52      |\n",
      "|    reward             | 0.2954371 |\n",
      "|    std                | 12        |\n",
      "|    value_loss         | 0.0996    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 37000       |\n",
      "|    time_elapsed       | 844         |\n",
      "|    total_timesteps    | 185000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.76       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36999       |\n",
      "|    policy_loss        | 2.85        |\n",
      "|    reward             | -0.00963636 |\n",
      "|    std                | 11.9        |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 37100     |\n",
      "|    time_elapsed       | 846       |\n",
      "|    total_timesteps    | 185500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.79     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 37099     |\n",
      "|    policy_loss        | -2.4      |\n",
      "|    reward             | 1.1653745 |\n",
      "|    std                | 12        |\n",
      "|    value_loss         | 0.138     |\n",
      "-------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 210\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 222695.55\n",
      "total_reward: 122695.55\n",
      "total_cost: 12479.94\n",
      "total_trades: 1515\n",
      "Sharpe: 0.749\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 37200        |\n",
      "|    time_elapsed       | 848          |\n",
      "|    total_timesteps    | 186000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.79        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 37199        |\n",
      "|    policy_loss        | 0.147        |\n",
      "|    reward             | -0.050589796 |\n",
      "|    std                | 12.1         |\n",
      "|    value_loss         | 0.00195      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 37300       |\n",
      "|    time_elapsed       | 850         |\n",
      "|    total_timesteps    | 186500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.78       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37299       |\n",
      "|    policy_loss        | 5.26        |\n",
      "|    reward             | -0.07815938 |\n",
      "|    std                | 12          |\n",
      "|    value_loss         | 0.47        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 37400       |\n",
      "|    time_elapsed       | 853         |\n",
      "|    total_timesteps    | 187000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.8        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37399       |\n",
      "|    policy_loss        | 0.459       |\n",
      "|    reward             | -0.16192837 |\n",
      "|    std                | 12.1        |\n",
      "|    value_loss         | 0.0122      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 37500        |\n",
      "|    time_elapsed       | 855          |\n",
      "|    total_timesteps    | 187500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.81        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 37499        |\n",
      "|    policy_loss        | -0.0114      |\n",
      "|    reward             | -0.054434374 |\n",
      "|    std                | 12.2         |\n",
      "|    value_loss         | 0.0035       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 37600       |\n",
      "|    time_elapsed       | 857         |\n",
      "|    total_timesteps    | 188000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.83       |\n",
      "|    explained_variance | 0.227       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37599       |\n",
      "|    policy_loss        | -0.412      |\n",
      "|    reward             | 0.019977905 |\n",
      "|    std                | 12.3        |\n",
      "|    value_loss         | 0.00734     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 37700      |\n",
      "|    time_elapsed       | 859        |\n",
      "|    total_timesteps    | 188500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 37699      |\n",
      "|    policy_loss        | -2.2       |\n",
      "|    reward             | -0.5035446 |\n",
      "|    std                | 12.4       |\n",
      "|    value_loss         | 0.112      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 37800       |\n",
      "|    time_elapsed       | 861         |\n",
      "|    total_timesteps    | 189000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.84       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37799       |\n",
      "|    policy_loss        | 2.8         |\n",
      "|    reward             | -0.40879825 |\n",
      "|    std                | 12.4        |\n",
      "|    value_loss         | 0.154       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 37900      |\n",
      "|    time_elapsed       | 864        |\n",
      "|    total_timesteps    | 189500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.83      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 37899      |\n",
      "|    policy_loss        | 1.63       |\n",
      "|    reward             | 0.11097107 |\n",
      "|    std                | 12.3       |\n",
      "|    value_loss         | 0.0704     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 38000       |\n",
      "|    time_elapsed       | 866         |\n",
      "|    total_timesteps    | 190000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.84       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37999       |\n",
      "|    policy_loss        | -3.8        |\n",
      "|    reward             | 0.110736914 |\n",
      "|    std                | 12.4        |\n",
      "|    value_loss         | 0.565       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 38100      |\n",
      "|    time_elapsed       | 868        |\n",
      "|    total_timesteps    | 190500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.85      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38099      |\n",
      "|    policy_loss        | -3.74      |\n",
      "|    reward             | 0.35639217 |\n",
      "|    std                | 12.5       |\n",
      "|    value_loss         | 0.427      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 38200       |\n",
      "|    time_elapsed       | 870         |\n",
      "|    total_timesteps    | 191000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.85       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38199       |\n",
      "|    policy_loss        | -4.36       |\n",
      "|    reward             | -0.12458428 |\n",
      "|    std                | 12.4        |\n",
      "|    value_loss         | 0.322       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 38300        |\n",
      "|    time_elapsed       | 872          |\n",
      "|    total_timesteps    | 191500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.84        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 38299        |\n",
      "|    policy_loss        | -4.51        |\n",
      "|    reward             | -0.056174412 |\n",
      "|    std                | 12.4         |\n",
      "|    value_loss         | 0.316        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 38400      |\n",
      "|    time_elapsed       | 875        |\n",
      "|    total_timesteps    | 192000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38399      |\n",
      "|    policy_loss        | -2.48      |\n",
      "|    reward             | 0.29541886 |\n",
      "|    std                | 12.5       |\n",
      "|    value_loss         | 0.252      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 38500      |\n",
      "|    time_elapsed       | 877        |\n",
      "|    total_timesteps    | 192500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.86      |\n",
      "|    explained_variance | 0.37       |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38499      |\n",
      "|    policy_loss        | 2.05       |\n",
      "|    reward             | 0.37895802 |\n",
      "|    std                | 12.5       |\n",
      "|    value_loss         | 0.0982     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 38600        |\n",
      "|    time_elapsed       | 879          |\n",
      "|    total_timesteps    | 193000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.86        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 38599        |\n",
      "|    policy_loss        | 0.0164       |\n",
      "|    reward             | -0.041060362 |\n",
      "|    std                | 12.6         |\n",
      "|    value_loss         | 0.00208      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 38700      |\n",
      "|    time_elapsed       | 881        |\n",
      "|    total_timesteps    | 193500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.87      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38699      |\n",
      "|    policy_loss        | -1.23      |\n",
      "|    reward             | 0.10139678 |\n",
      "|    std                | 12.6       |\n",
      "|    value_loss         | 0.0294     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 38800      |\n",
      "|    time_elapsed       | 883        |\n",
      "|    total_timesteps    | 194000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.88      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38799      |\n",
      "|    policy_loss        | -0.53      |\n",
      "|    reward             | 0.24278577 |\n",
      "|    std                | 12.6       |\n",
      "|    value_loss         | 0.0106     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 38900       |\n",
      "|    time_elapsed       | 886         |\n",
      "|    total_timesteps    | 194500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -7.88       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38899       |\n",
      "|    policy_loss        | 7.03        |\n",
      "|    reward             | -0.37983984 |\n",
      "|    std                | 12.7        |\n",
      "|    value_loss         | 0.903       |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 220\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 241857.14\n",
      "total_reward: 141857.14\n",
      "total_cost: 14815.70\n",
      "total_trades: 1438\n",
      "Sharpe: 0.805\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 39000      |\n",
      "|    time_elapsed       | 888        |\n",
      "|    total_timesteps    | 195000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.89      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 38999      |\n",
      "|    policy_loss        | 4.37       |\n",
      "|    reward             | 0.28863502 |\n",
      "|    std                | 12.7       |\n",
      "|    value_loss         | 0.353      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 39100      |\n",
      "|    time_elapsed       | 890        |\n",
      "|    total_timesteps    | 195500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39099      |\n",
      "|    policy_loss        | 1.64       |\n",
      "|    reward             | 0.76651686 |\n",
      "|    std                | 12.8       |\n",
      "|    value_loss         | 0.172      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 39200      |\n",
      "|    time_elapsed       | 892        |\n",
      "|    total_timesteps    | 196000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.9       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39199      |\n",
      "|    policy_loss        | 13.2       |\n",
      "|    reward             | 0.44657838 |\n",
      "|    std                | 12.8       |\n",
      "|    value_loss         | 2.53       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 39300        |\n",
      "|    time_elapsed       | 895          |\n",
      "|    total_timesteps    | 196500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.91        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 39299        |\n",
      "|    policy_loss        | -1.48        |\n",
      "|    reward             | -0.019801458 |\n",
      "|    std                | 12.8         |\n",
      "|    value_loss         | 0.0349       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 39400      |\n",
      "|    time_elapsed       | 897        |\n",
      "|    total_timesteps    | 197000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39399      |\n",
      "|    policy_loss        | -0.0322    |\n",
      "|    reward             | 0.08605908 |\n",
      "|    std                | 12.9       |\n",
      "|    value_loss         | 0.00423    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 39500      |\n",
      "|    time_elapsed       | 899        |\n",
      "|    total_timesteps    | 197500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.94      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39499      |\n",
      "|    policy_loss        | 3.3        |\n",
      "|    reward             | 0.36222813 |\n",
      "|    std                | 13         |\n",
      "|    value_loss         | 0.173      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 39600      |\n",
      "|    time_elapsed       | 901        |\n",
      "|    total_timesteps    | 198000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.93      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39599      |\n",
      "|    policy_loss        | -6.07      |\n",
      "|    reward             | 0.22840093 |\n",
      "|    std                | 12.9       |\n",
      "|    value_loss         | 1.15       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 39700        |\n",
      "|    time_elapsed       | 903          |\n",
      "|    total_timesteps    | 198500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.95        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 39699        |\n",
      "|    policy_loss        | -1.63        |\n",
      "|    reward             | -0.010434343 |\n",
      "|    std                | 13           |\n",
      "|    value_loss         | 0.0698       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 39800        |\n",
      "|    time_elapsed       | 905          |\n",
      "|    total_timesteps    | 199000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -7.97        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 39799        |\n",
      "|    policy_loss        | -1.71        |\n",
      "|    reward             | 0.0077919923 |\n",
      "|    std                | 13.2         |\n",
      "|    value_loss         | 0.0513       |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 39900    |\n",
      "|    time_elapsed       | 908      |\n",
      "|    total_timesteps    | 199500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.98    |\n",
      "|    explained_variance | 0.239    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 39899    |\n",
      "|    policy_loss        | -0.697   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 13.3     |\n",
      "|    value_loss         | 0.0106   |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 40000      |\n",
      "|    time_elapsed       | 910        |\n",
      "|    total_timesteps    | 200000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -7.98      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39999      |\n",
      "|    policy_loss        | -3.2       |\n",
      "|    reward             | -0.3089978 |\n",
      "|    std                | 13.3       |\n",
      "|    value_loss         | 0.242      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 40100      |\n",
      "|    time_elapsed       | 913        |\n",
      "|    total_timesteps    | 200500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8         |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40099      |\n",
      "|    policy_loss        | -1.26      |\n",
      "|    reward             | -0.3534526 |\n",
      "|    std                | 13.4       |\n",
      "|    value_loss         | 0.0268     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 40200      |\n",
      "|    time_elapsed       | 915        |\n",
      "|    total_timesteps    | 201000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40199      |\n",
      "|    policy_loss        | -1.28      |\n",
      "|    reward             | 0.33070016 |\n",
      "|    std                | 13.5       |\n",
      "|    value_loss         | 0.0374     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 40300       |\n",
      "|    time_elapsed       | 918         |\n",
      "|    total_timesteps    | 201500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.02       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 40299       |\n",
      "|    policy_loss        | -2.05       |\n",
      "|    reward             | -0.15098041 |\n",
      "|    std                | 13.5        |\n",
      "|    value_loss         | 0.0877      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 40400      |\n",
      "|    time_elapsed       | 920        |\n",
      "|    total_timesteps    | 202000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.01      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40399      |\n",
      "|    policy_loss        | 1.97       |\n",
      "|    reward             | 0.41201937 |\n",
      "|    std                | 13.5       |\n",
      "|    value_loss         | 0.0757     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 40500        |\n",
      "|    time_elapsed       | 922          |\n",
      "|    total_timesteps    | 202500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.01        |\n",
      "|    explained_variance | 0.469        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 40499        |\n",
      "|    policy_loss        | -1.02        |\n",
      "|    reward             | -0.055184815 |\n",
      "|    std                | 13.5         |\n",
      "|    value_loss         | 0.0202       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 40600      |\n",
      "|    time_elapsed       | 924        |\n",
      "|    total_timesteps    | 203000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.03      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40599      |\n",
      "|    policy_loss        | 1.54       |\n",
      "|    reward             | -0.1222583 |\n",
      "|    std                | 13.6       |\n",
      "|    value_loss         | 0.0349     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 40700      |\n",
      "|    time_elapsed       | 927        |\n",
      "|    total_timesteps    | 203500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 40699      |\n",
      "|    policy_loss        | 0.0281     |\n",
      "|    reward             | 0.03596118 |\n",
      "|    std                | 13.6       |\n",
      "|    value_loss         | 0.00225    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 40800       |\n",
      "|    time_elapsed       | 929         |\n",
      "|    total_timesteps    | 204000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.05       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 40799       |\n",
      "|    policy_loss        | 2.01        |\n",
      "|    reward             | -0.10593107 |\n",
      "|    std                | 13.7        |\n",
      "|    value_loss         | 0.0562      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 40900        |\n",
      "|    time_elapsed       | 931          |\n",
      "|    total_timesteps    | 204500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.05        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 40899        |\n",
      "|    policy_loss        | 0.349        |\n",
      "|    reward             | -0.064892285 |\n",
      "|    std                | 13.7         |\n",
      "|    value_loss         | 0.00583      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 41000       |\n",
      "|    time_elapsed       | 933         |\n",
      "|    total_timesteps    | 205000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.06       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 40999       |\n",
      "|    policy_loss        | -0.946      |\n",
      "|    reward             | -0.18251222 |\n",
      "|    std                | 13.8        |\n",
      "|    value_loss         | 0.0321      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 41100       |\n",
      "|    time_elapsed       | 936         |\n",
      "|    total_timesteps    | 205500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.08       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 41099       |\n",
      "|    policy_loss        | 0.839       |\n",
      "|    reward             | 0.029973242 |\n",
      "|    std                | 14          |\n",
      "|    value_loss         | 0.0121      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 41200      |\n",
      "|    time_elapsed       | 938        |\n",
      "|    total_timesteps    | 206000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.11      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 41199      |\n",
      "|    policy_loss        | -0.401     |\n",
      "|    reward             | -0.3318535 |\n",
      "|    std                | 14.2       |\n",
      "|    value_loss         | 0.0415     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 41300         |\n",
      "|    time_elapsed       | 940           |\n",
      "|    total_timesteps    | 206500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.12         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 41299         |\n",
      "|    policy_loss        | -2.26         |\n",
      "|    reward             | -0.0054420386 |\n",
      "|    std                | 14.3          |\n",
      "|    value_loss         | 0.129         |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 41400      |\n",
      "|    time_elapsed       | 942        |\n",
      "|    total_timesteps    | 207000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.13      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 41399      |\n",
      "|    policy_loss        | -0.561     |\n",
      "|    reward             | 0.24084254 |\n",
      "|    std                | 14.4       |\n",
      "|    value_loss         | 0.0115     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 41500      |\n",
      "|    time_elapsed       | 945        |\n",
      "|    total_timesteps    | 207500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.14      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 41499      |\n",
      "|    policy_loss        | -3.95      |\n",
      "|    reward             | 0.10313672 |\n",
      "|    std                | 14.4       |\n",
      "|    value_loss         | 0.331      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 41600       |\n",
      "|    time_elapsed       | 947         |\n",
      "|    total_timesteps    | 208000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.16       |\n",
      "|    explained_variance | -0.11       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 41599       |\n",
      "|    policy_loss        | -13.3       |\n",
      "|    reward             | -0.16752364 |\n",
      "|    std                | 14.6        |\n",
      "|    value_loss         | 2.43        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 41700     |\n",
      "|    time_elapsed       | 949       |\n",
      "|    total_timesteps    | 208500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.18     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 41699     |\n",
      "|    policy_loss        | -0.313    |\n",
      "|    reward             | 0.1338625 |\n",
      "|    std                | 14.7      |\n",
      "|    value_loss         | 0.0022    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 41800       |\n",
      "|    time_elapsed       | 951         |\n",
      "|    total_timesteps    | 209000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.19       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 41799       |\n",
      "|    policy_loss        | -1.57       |\n",
      "|    reward             | -0.08776343 |\n",
      "|    std                | 14.8        |\n",
      "|    value_loss         | 0.0527      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 41900      |\n",
      "|    time_elapsed       | 953        |\n",
      "|    total_timesteps    | 209500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 41899      |\n",
      "|    policy_loss        | 1.1        |\n",
      "|    reward             | 0.27955472 |\n",
      "|    std                | 14.8       |\n",
      "|    value_loss         | 0.0291     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 42000        |\n",
      "|    time_elapsed       | 956          |\n",
      "|    total_timesteps    | 210000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.19        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 41999        |\n",
      "|    policy_loss        | 0.753        |\n",
      "|    reward             | -0.058351245 |\n",
      "|    std                | 14.8         |\n",
      "|    value_loss         | 0.0419       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 42100      |\n",
      "|    time_elapsed       | 958        |\n",
      "|    total_timesteps    | 210500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.18      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42099      |\n",
      "|    policy_loss        | 1.41       |\n",
      "|    reward             | 0.57016414 |\n",
      "|    std                | 14.7       |\n",
      "|    value_loss         | 0.134      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 42200       |\n",
      "|    time_elapsed       | 960         |\n",
      "|    total_timesteps    | 211000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.19       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 42199       |\n",
      "|    policy_loss        | -0.101      |\n",
      "|    reward             | -0.09308562 |\n",
      "|    std                | 14.8        |\n",
      "|    value_loss         | 0.00185     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 42300      |\n",
      "|    time_elapsed       | 963        |\n",
      "|    total_timesteps    | 211500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.2       |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42299      |\n",
      "|    policy_loss        | -0.981     |\n",
      "|    reward             | 0.35628515 |\n",
      "|    std                | 14.9       |\n",
      "|    value_loss         | 0.0157     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 42400      |\n",
      "|    time_elapsed       | 965        |\n",
      "|    total_timesteps    | 212000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.21      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42399      |\n",
      "|    policy_loss        | 3.1        |\n",
      "|    reward             | 0.04297603 |\n",
      "|    std                | 15         |\n",
      "|    value_loss         | 0.188      |\n",
      "--------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 240\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 245374.81\n",
      "total_reward: 145374.81\n",
      "total_cost: 14478.35\n",
      "total_trades: 1369\n",
      "Sharpe: 0.814\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 42500       |\n",
      "|    time_elapsed       | 967         |\n",
      "|    total_timesteps    | 212500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.21       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 42499       |\n",
      "|    policy_loss        | 1.14        |\n",
      "|    reward             | -0.11846716 |\n",
      "|    std                | 15          |\n",
      "|    value_loss         | 0.0434      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 42600      |\n",
      "|    time_elapsed       | 969        |\n",
      "|    total_timesteps    | 213000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.22      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42599      |\n",
      "|    policy_loss        | -4.28      |\n",
      "|    reward             | 0.39951825 |\n",
      "|    std                | 15         |\n",
      "|    value_loss         | 0.287      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 42700       |\n",
      "|    time_elapsed       | 972         |\n",
      "|    total_timesteps    | 213500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.21       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 42699       |\n",
      "|    policy_loss        | 0.108       |\n",
      "|    reward             | 0.080487646 |\n",
      "|    std                | 14.9        |\n",
      "|    value_loss         | 0.0177      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 42800         |\n",
      "|    time_elapsed       | 974           |\n",
      "|    total_timesteps    | 214000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.22         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 42799         |\n",
      "|    policy_loss        | 12.7          |\n",
      "|    reward             | 0.00057631836 |\n",
      "|    std                | 15            |\n",
      "|    value_loss         | 2.88          |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 42900      |\n",
      "|    time_elapsed       | 976        |\n",
      "|    total_timesteps    | 214500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42899      |\n",
      "|    policy_loss        | -9.24      |\n",
      "|    reward             | -0.6495403 |\n",
      "|    std                | 15.1       |\n",
      "|    value_loss         | 1.19       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 43000      |\n",
      "|    time_elapsed       | 978        |\n",
      "|    total_timesteps    | 215000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.24      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 42999      |\n",
      "|    policy_loss        | -1.18      |\n",
      "|    reward             | -0.8127752 |\n",
      "|    std                | 15.1       |\n",
      "|    value_loss         | 0.0427     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 43100       |\n",
      "|    time_elapsed       | 981         |\n",
      "|    total_timesteps    | 215500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.23       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43099       |\n",
      "|    policy_loss        | -3.88       |\n",
      "|    reward             | -0.07083862 |\n",
      "|    std                | 15.1        |\n",
      "|    value_loss         | 0.287       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 43200       |\n",
      "|    time_elapsed       | 983         |\n",
      "|    total_timesteps    | 216000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.23       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43199       |\n",
      "|    policy_loss        | 1.62        |\n",
      "|    reward             | -0.15458545 |\n",
      "|    std                | 15.1        |\n",
      "|    value_loss         | 0.268       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 43300      |\n",
      "|    time_elapsed       | 985        |\n",
      "|    total_timesteps    | 216500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.23      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 43299      |\n",
      "|    policy_loss        | -0.733     |\n",
      "|    reward             | 0.36242503 |\n",
      "|    std                | 15         |\n",
      "|    value_loss         | 0.179      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 43400      |\n",
      "|    time_elapsed       | 987        |\n",
      "|    total_timesteps    | 217000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.23      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 43399      |\n",
      "|    policy_loss        | -2.12      |\n",
      "|    reward             | 0.11936887 |\n",
      "|    std                | 15         |\n",
      "|    value_loss         | 0.075      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 43500       |\n",
      "|    time_elapsed       | 989         |\n",
      "|    total_timesteps    | 217500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.25       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 43499       |\n",
      "|    policy_loss        | 1.81        |\n",
      "|    reward             | -0.08626734 |\n",
      "|    std                | 15.1        |\n",
      "|    value_loss         | 0.0716      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 43600        |\n",
      "|    time_elapsed       | 992          |\n",
      "|    total_timesteps    | 218000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.25        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 43599        |\n",
      "|    policy_loss        | 0.676        |\n",
      "|    reward             | -0.012460694 |\n",
      "|    std                | 15.2         |\n",
      "|    value_loss         | 0.0341       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 43700      |\n",
      "|    time_elapsed       | 994        |\n",
      "|    total_timesteps    | 218500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.27      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 43699      |\n",
      "|    policy_loss        | 1.25       |\n",
      "|    reward             | -0.6155309 |\n",
      "|    std                | 15.3       |\n",
      "|    value_loss         | 0.102      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 43800      |\n",
      "|    time_elapsed       | 996        |\n",
      "|    total_timesteps    | 219000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.27      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 43799      |\n",
      "|    policy_loss        | 1.33       |\n",
      "|    reward             | 0.16232836 |\n",
      "|    std                | 15.3       |\n",
      "|    value_loss         | 0.0401     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 43900     |\n",
      "|    time_elapsed       | 998       |\n",
      "|    total_timesteps    | 219500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.26     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43899     |\n",
      "|    policy_loss        | -1.81     |\n",
      "|    reward             | 0.2671122 |\n",
      "|    std                | 15.2      |\n",
      "|    value_loss         | 0.071     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 44000     |\n",
      "|    time_elapsed       | 1001      |\n",
      "|    total_timesteps    | 220000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.26     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 43999     |\n",
      "|    policy_loss        | -2.59     |\n",
      "|    reward             | 0.1352147 |\n",
      "|    std                | 15.2      |\n",
      "|    value_loss         | 0.11      |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 44100        |\n",
      "|    time_elapsed       | 1003         |\n",
      "|    total_timesteps    | 220500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.28        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 44099        |\n",
      "|    policy_loss        | -0.0792      |\n",
      "|    reward             | 0.0026308228 |\n",
      "|    std                | 15.3         |\n",
      "|    value_loss         | 0.00307      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 44200      |\n",
      "|    time_elapsed       | 1005       |\n",
      "|    total_timesteps    | 221000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.3       |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44199      |\n",
      "|    policy_loss        | -1.38      |\n",
      "|    reward             | 0.08993393 |\n",
      "|    std                | 15.5       |\n",
      "|    value_loss         | 0.0397     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 44300       |\n",
      "|    time_elapsed       | 1007        |\n",
      "|    total_timesteps    | 221500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.31       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44299       |\n",
      "|    policy_loss        | -0.255      |\n",
      "|    reward             | 0.100981936 |\n",
      "|    std                | 15.6        |\n",
      "|    value_loss         | 0.00135     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 44400      |\n",
      "|    time_elapsed       | 1009       |\n",
      "|    total_timesteps    | 222000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.34      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44399      |\n",
      "|    policy_loss        | 1.23       |\n",
      "|    reward             | 0.15780704 |\n",
      "|    std                | 15.9       |\n",
      "|    value_loss         | 0.0252     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 44500      |\n",
      "|    time_elapsed       | 1012       |\n",
      "|    total_timesteps    | 222500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.36      |\n",
      "|    explained_variance | -8.84      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44499      |\n",
      "|    policy_loss        | -0.588     |\n",
      "|    reward             | 0.11294103 |\n",
      "|    std                | 16         |\n",
      "|    value_loss         | 0.00736    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 44600       |\n",
      "|    time_elapsed       | 1014        |\n",
      "|    total_timesteps    | 223000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.37       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 44599       |\n",
      "|    policy_loss        | 0.379       |\n",
      "|    reward             | -0.12356418 |\n",
      "|    std                | 16.1        |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 44700      |\n",
      "|    time_elapsed       | 1016       |\n",
      "|    total_timesteps    | 223500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.38      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44699      |\n",
      "|    policy_loss        | -1.08      |\n",
      "|    reward             | 0.07292317 |\n",
      "|    std                | 16.2       |\n",
      "|    value_loss         | 0.023      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 44800      |\n",
      "|    time_elapsed       | 1018       |\n",
      "|    total_timesteps    | 224000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.4       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44799      |\n",
      "|    policy_loss        | 0.479      |\n",
      "|    reward             | 0.27049688 |\n",
      "|    std                | 16.4       |\n",
      "|    value_loss         | 0.0264     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 44900        |\n",
      "|    time_elapsed       | 1020         |\n",
      "|    total_timesteps    | 224500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.41        |\n",
      "|    explained_variance | -0.0295      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 44899        |\n",
      "|    policy_loss        | 3.63         |\n",
      "|    reward             | -0.036489185 |\n",
      "|    std                | 16.5         |\n",
      "|    value_loss         | 0.626        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 45000      |\n",
      "|    time_elapsed       | 1022       |\n",
      "|    total_timesteps    | 225000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.41      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 44999      |\n",
      "|    policy_loss        | -0.352     |\n",
      "|    reward             | 0.11369106 |\n",
      "|    std                | 16.5       |\n",
      "|    value_loss         | 0.00233    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 45100      |\n",
      "|    time_elapsed       | 1025       |\n",
      "|    total_timesteps    | 225500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.42      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 45099      |\n",
      "|    policy_loss        | 0.792      |\n",
      "|    reward             | 0.09979229 |\n",
      "|    std                | 16.6       |\n",
      "|    value_loss         | 0.0137     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 45200      |\n",
      "|    time_elapsed       | 1027       |\n",
      "|    total_timesteps    | 226000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.45      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 45199      |\n",
      "|    policy_loss        | 1.29       |\n",
      "|    reward             | 0.05158435 |\n",
      "|    std                | 16.8       |\n",
      "|    value_loss         | 0.0332     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 45300      |\n",
      "|    time_elapsed       | 1029       |\n",
      "|    total_timesteps    | 226500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.48      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 45299      |\n",
      "|    policy_loss        | -1.97      |\n",
      "|    reward             | 0.45956668 |\n",
      "|    std                | 17         |\n",
      "|    value_loss         | 0.0694     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 45400       |\n",
      "|    time_elapsed       | 1031        |\n",
      "|    total_timesteps    | 227000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.49       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 45399       |\n",
      "|    policy_loss        | -0.167      |\n",
      "|    reward             | -0.14966123 |\n",
      "|    std                | 17.1        |\n",
      "|    value_loss         | 0.0151      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 45500      |\n",
      "|    time_elapsed       | 1034       |\n",
      "|    total_timesteps    | 227500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.47      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 45499      |\n",
      "|    policy_loss        | 0.323      |\n",
      "|    reward             | 0.23421094 |\n",
      "|    std                | 17         |\n",
      "|    value_loss         | 0.0254     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 45600    |\n",
      "|    time_elapsed       | 1036     |\n",
      "|    total_timesteps    | 228000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 45599    |\n",
      "|    policy_loss        | -1.16    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 17.1     |\n",
      "|    value_loss         | 0.029    |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 45700        |\n",
      "|    time_elapsed       | 1038         |\n",
      "|    total_timesteps    | 228500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.49        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 45699        |\n",
      "|    policy_loss        | 0.761        |\n",
      "|    reward             | -0.041777443 |\n",
      "|    std                | 17.1         |\n",
      "|    value_loss         | 0.012        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 45800      |\n",
      "|    time_elapsed       | 1040       |\n",
      "|    total_timesteps    | 229000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.49      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 45799      |\n",
      "|    policy_loss        | -1.41      |\n",
      "|    reward             | 0.07535006 |\n",
      "|    std                | 17.1       |\n",
      "|    value_loss         | 0.0366     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 220           |\n",
      "|    iterations         | 45900         |\n",
      "|    time_elapsed       | 1042          |\n",
      "|    total_timesteps    | 229500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.51         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 45899         |\n",
      "|    policy_loss        | 0.257         |\n",
      "|    reward             | -0.0101775145 |\n",
      "|    std                | 17.3          |\n",
      "|    value_loss         | 0.00693       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 46000       |\n",
      "|    time_elapsed       | 1045        |\n",
      "|    total_timesteps    | 230000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.52       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 45999       |\n",
      "|    policy_loss        | -0.458      |\n",
      "|    reward             | 0.063332416 |\n",
      "|    std                | 17.4        |\n",
      "|    value_loss         | 0.0527      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 46100       |\n",
      "|    time_elapsed       | 1047        |\n",
      "|    total_timesteps    | 230500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.54       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 46099       |\n",
      "|    policy_loss        | -0.691      |\n",
      "|    reward             | -0.16898096 |\n",
      "|    std                | 17.5        |\n",
      "|    value_loss         | 0.0276      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 46200        |\n",
      "|    time_elapsed       | 1049         |\n",
      "|    total_timesteps    | 231000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.54        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 46199        |\n",
      "|    policy_loss        | 0.653        |\n",
      "|    reward             | -0.102629684 |\n",
      "|    std                | 17.6         |\n",
      "|    value_loss         | 0.0364       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 46300      |\n",
      "|    time_elapsed       | 1051       |\n",
      "|    total_timesteps    | 231500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.57      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46299      |\n",
      "|    policy_loss        | -1.46      |\n",
      "|    reward             | 0.09184229 |\n",
      "|    std                | 17.8       |\n",
      "|    value_loss         | 0.0303     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 46400       |\n",
      "|    time_elapsed       | 1053        |\n",
      "|    total_timesteps    | 232000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.57       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 46399       |\n",
      "|    policy_loss        | -2.71       |\n",
      "|    reward             | 0.073861085 |\n",
      "|    std                | 17.8        |\n",
      "|    value_loss         | 0.152       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 46500      |\n",
      "|    time_elapsed       | 1056       |\n",
      "|    total_timesteps    | 232500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.58      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46499      |\n",
      "|    policy_loss        | 2.34       |\n",
      "|    reward             | 0.76814955 |\n",
      "|    std                | 17.9       |\n",
      "|    value_loss         | 0.443      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 46600      |\n",
      "|    time_elapsed       | 1058       |\n",
      "|    total_timesteps    | 233000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.59      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46599      |\n",
      "|    policy_loss        | -0.54      |\n",
      "|    reward             | 0.07272417 |\n",
      "|    std                | 18         |\n",
      "|    value_loss         | 0.00444    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 46700        |\n",
      "|    time_elapsed       | 1060         |\n",
      "|    total_timesteps    | 233500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.6         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 46699        |\n",
      "|    policy_loss        | 1.2          |\n",
      "|    reward             | -0.023762645 |\n",
      "|    std                | 18.1         |\n",
      "|    value_loss         | 0.0262       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 46800        |\n",
      "|    time_elapsed       | 1062         |\n",
      "|    total_timesteps    | 234000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.62        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 46799        |\n",
      "|    policy_loss        | 4.87         |\n",
      "|    reward             | -0.069545604 |\n",
      "|    std                | 18.3         |\n",
      "|    value_loss         | 0.366        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 46900     |\n",
      "|    time_elapsed       | 1065      |\n",
      "|    total_timesteps    | 234500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.63     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 46899     |\n",
      "|    policy_loss        | -3.59     |\n",
      "|    reward             | 0.9347694 |\n",
      "|    std                | 18.4      |\n",
      "|    value_loss         | 0.332     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 47000      |\n",
      "|    time_elapsed       | 1067       |\n",
      "|    total_timesteps    | 235000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.65      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 46999      |\n",
      "|    policy_loss        | -0.263     |\n",
      "|    reward             | 0.07727783 |\n",
      "|    std                | 18.5       |\n",
      "|    value_loss         | 0.00568    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 47100        |\n",
      "|    time_elapsed       | 1069         |\n",
      "|    total_timesteps    | 235500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.65        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 47099        |\n",
      "|    policy_loss        | 0.562        |\n",
      "|    reward             | -0.103092775 |\n",
      "|    std                | 18.6         |\n",
      "|    value_loss         | 0.0246       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 47200     |\n",
      "|    time_elapsed       | 1071      |\n",
      "|    total_timesteps    | 236000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.67     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 47199     |\n",
      "|    policy_loss        | -4.37     |\n",
      "|    reward             | 0.9842676 |\n",
      "|    std                | 18.8      |\n",
      "|    value_loss         | 0.369     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 47300      |\n",
      "|    time_elapsed       | 1073       |\n",
      "|    total_timesteps    | 236500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.68      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 47299      |\n",
      "|    policy_loss        | 2.54       |\n",
      "|    reward             | -0.3300952 |\n",
      "|    std                | 18.9       |\n",
      "|    value_loss         | 0.0954     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 47400      |\n",
      "|    time_elapsed       | 1076       |\n",
      "|    total_timesteps    | 237000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.67      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 47399      |\n",
      "|    policy_loss        | -2.08      |\n",
      "|    reward             | 0.17267026 |\n",
      "|    std                | 18.9       |\n",
      "|    value_loss         | 0.116      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 47500      |\n",
      "|    time_elapsed       | 1078       |\n",
      "|    total_timesteps    | 237500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.68      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 47499      |\n",
      "|    policy_loss        | -1.64      |\n",
      "|    reward             | 0.16476592 |\n",
      "|    std                | 18.9       |\n",
      "|    value_loss         | 0.0703     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 47600       |\n",
      "|    time_elapsed       | 1080        |\n",
      "|    total_timesteps    | 238000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.69       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47599       |\n",
      "|    policy_loss        | -7.3        |\n",
      "|    reward             | -0.43806532 |\n",
      "|    std                | 19.1        |\n",
      "|    value_loss         | 1.66        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 47700      |\n",
      "|    time_elapsed       | 1082       |\n",
      "|    total_timesteps    | 238500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 47699      |\n",
      "|    policy_loss        | 2.75       |\n",
      "|    reward             | -0.1514665 |\n",
      "|    std                | 19         |\n",
      "|    value_loss         | 0.13       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 47800      |\n",
      "|    time_elapsed       | 1085       |\n",
      "|    total_timesteps    | 239000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.69      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 47799      |\n",
      "|    policy_loss        | -2.72      |\n",
      "|    reward             | -0.7770212 |\n",
      "|    std                | 19.1       |\n",
      "|    value_loss         | 0.141      |\n",
      "--------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 270\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 254404.59\n",
      "total_reward: 154404.59\n",
      "total_cost: 8710.94\n",
      "total_trades: 1405\n",
      "Sharpe: 0.836\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 47900       |\n",
      "|    time_elapsed       | 1087        |\n",
      "|    total_timesteps    | 239500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47899       |\n",
      "|    policy_loss        | -0.564      |\n",
      "|    reward             | 0.049222264 |\n",
      "|    std                | 19.2        |\n",
      "|    value_loss         | 0.0584      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 48000       |\n",
      "|    time_elapsed       | 1089        |\n",
      "|    total_timesteps    | 240000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.72       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 47999       |\n",
      "|    policy_loss        | -16         |\n",
      "|    reward             | 0.013609684 |\n",
      "|    std                | 19.4        |\n",
      "|    value_loss         | 3.28        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 48100       |\n",
      "|    time_elapsed       | 1091        |\n",
      "|    total_timesteps    | 240500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.73       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48099       |\n",
      "|    policy_loss        | 1.42        |\n",
      "|    reward             | -0.37859678 |\n",
      "|    std                | 19.5        |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 48200        |\n",
      "|    time_elapsed       | 1093         |\n",
      "|    total_timesteps    | 241000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.73        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 48199        |\n",
      "|    policy_loss        | -0.408       |\n",
      "|    reward             | -0.020344628 |\n",
      "|    std                | 19.5         |\n",
      "|    value_loss         | 0.00274      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 48300       |\n",
      "|    time_elapsed       | 1096        |\n",
      "|    total_timesteps    | 241500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.73       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48299       |\n",
      "|    policy_loss        | 1.7         |\n",
      "|    reward             | -0.20106609 |\n",
      "|    std                | 19.5        |\n",
      "|    value_loss         | 0.0529      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 48400      |\n",
      "|    time_elapsed       | 1098       |\n",
      "|    total_timesteps    | 242000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.73      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48399      |\n",
      "|    policy_loss        | 1.19       |\n",
      "|    reward             | 0.07981543 |\n",
      "|    std                | 19.5       |\n",
      "|    value_loss         | 0.0203     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 48500        |\n",
      "|    time_elapsed       | 1100         |\n",
      "|    total_timesteps    | 242500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.74        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 48499        |\n",
      "|    policy_loss        | -0.245       |\n",
      "|    reward             | -0.062109023 |\n",
      "|    std                | 19.6         |\n",
      "|    value_loss         | 0.000835     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 48600      |\n",
      "|    time_elapsed       | 1102       |\n",
      "|    total_timesteps    | 243000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.75      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48599      |\n",
      "|    policy_loss        | 1.18       |\n",
      "|    reward             | 0.17685308 |\n",
      "|    std                | 19.8       |\n",
      "|    value_loss         | 0.0212     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 48700      |\n",
      "|    time_elapsed       | 1105       |\n",
      "|    total_timesteps    | 243500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.77      |\n",
      "|    explained_variance | 0.0195     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48699      |\n",
      "|    policy_loss        | -0.0325    |\n",
      "|    reward             | 0.09828232 |\n",
      "|    std                | 19.9       |\n",
      "|    value_loss         | 0.0175     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 48800      |\n",
      "|    time_elapsed       | 1107       |\n",
      "|    total_timesteps    | 244000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.79      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 48799      |\n",
      "|    policy_loss        | -1.59      |\n",
      "|    reward             | 0.22324549 |\n",
      "|    std                | 20.1       |\n",
      "|    value_loss         | 0.061      |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 220           |\n",
      "|    iterations         | 48900         |\n",
      "|    time_elapsed       | 1109          |\n",
      "|    total_timesteps    | 244500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -8.81         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 48899         |\n",
      "|    policy_loss        | 2.8           |\n",
      "|    reward             | -0.0005240479 |\n",
      "|    std                | 20.4          |\n",
      "|    value_loss         | 0.109         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 49000       |\n",
      "|    time_elapsed       | 1111        |\n",
      "|    total_timesteps    | 245000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 48999       |\n",
      "|    policy_loss        | -0.111      |\n",
      "|    reward             | -0.24127275 |\n",
      "|    std                | 20.5        |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 49100      |\n",
      "|    time_elapsed       | 1114       |\n",
      "|    total_timesteps    | 245500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.82      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49099      |\n",
      "|    policy_loss        | -1.34      |\n",
      "|    reward             | 0.11693478 |\n",
      "|    std                | 20.5       |\n",
      "|    value_loss         | 0.0269     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 49200      |\n",
      "|    time_elapsed       | 1116       |\n",
      "|    total_timesteps    | 246000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49199      |\n",
      "|    policy_loss        | -5.48      |\n",
      "|    reward             | -0.5526466 |\n",
      "|    std                | 20.6       |\n",
      "|    value_loss         | 0.537      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 49300      |\n",
      "|    time_elapsed       | 1118       |\n",
      "|    total_timesteps    | 246500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.84      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49299      |\n",
      "|    policy_loss        | 0.507      |\n",
      "|    reward             | 0.04849668 |\n",
      "|    std                | 20.7       |\n",
      "|    value_loss         | 0.00884    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 49400        |\n",
      "|    time_elapsed       | 1120         |\n",
      "|    total_timesteps    | 247000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.85        |\n",
      "|    explained_variance | 0.00865      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 49399        |\n",
      "|    policy_loss        | 0.444        |\n",
      "|    reward             | 0.0043100095 |\n",
      "|    std                | 20.8         |\n",
      "|    value_loss         | 0.0148       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 49500        |\n",
      "|    time_elapsed       | 1123         |\n",
      "|    total_timesteps    | 247500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.86        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 49499        |\n",
      "|    policy_loss        | 3.36         |\n",
      "|    reward             | -0.062329393 |\n",
      "|    std                | 21           |\n",
      "|    value_loss         | 0.158        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 49600      |\n",
      "|    time_elapsed       | 1125       |\n",
      "|    total_timesteps    | 248000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.87      |\n",
      "|    explained_variance | -0.0855    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 49599      |\n",
      "|    policy_loss        | -12.9      |\n",
      "|    reward             | -1.3285058 |\n",
      "|    std                | 21         |\n",
      "|    value_loss         | 2.34       |\n",
      "--------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 280\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 235945.46\n",
      "total_reward: 135945.46\n",
      "total_cost: 6366.83\n",
      "total_trades: 1413\n",
      "Sharpe: 0.782\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 49700       |\n",
      "|    time_elapsed       | 1127        |\n",
      "|    total_timesteps    | 248500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.89       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49699       |\n",
      "|    policy_loss        | 0.618       |\n",
      "|    reward             | 0.031361815 |\n",
      "|    std                | 21.2        |\n",
      "|    value_loss         | 0.0474      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 49800        |\n",
      "|    time_elapsed       | 1129         |\n",
      "|    total_timesteps    | 249000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.9         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 49799        |\n",
      "|    policy_loss        | 0.26         |\n",
      "|    reward             | -0.001879126 |\n",
      "|    std                | 21.4         |\n",
      "|    value_loss         | 0.00129      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 49900       |\n",
      "|    time_elapsed       | 1132        |\n",
      "|    total_timesteps    | 249500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.91       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49899       |\n",
      "|    policy_loss        | 0.661       |\n",
      "|    reward             | 0.017120361 |\n",
      "|    std                | 21.5        |\n",
      "|    value_loss         | 0.0199      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 50000       |\n",
      "|    time_elapsed       | 1134        |\n",
      "|    total_timesteps    | 250000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.93       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 49999       |\n",
      "|    policy_loss        | 2.39        |\n",
      "|    reward             | 0.051885545 |\n",
      "|    std                | 21.8        |\n",
      "|    value_loss         | 0.0941      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 50100       |\n",
      "|    time_elapsed       | 1136        |\n",
      "|    total_timesteps    | 250500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 50099       |\n",
      "|    policy_loss        | 8.12        |\n",
      "|    reward             | 0.049421486 |\n",
      "|    std                | 21.9        |\n",
      "|    value_loss         | 1.55        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 50200       |\n",
      "|    time_elapsed       | 1138        |\n",
      "|    total_timesteps    | 251000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.95       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 50199       |\n",
      "|    policy_loss        | 1.7         |\n",
      "|    reward             | -0.10890234 |\n",
      "|    std                | 22          |\n",
      "|    value_loss         | 0.0799      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 50300      |\n",
      "|    time_elapsed       | 1141       |\n",
      "|    total_timesteps    | 251500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.95      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50299      |\n",
      "|    policy_loss        | 2.07       |\n",
      "|    reward             | -0.1818144 |\n",
      "|    std                | 22.1       |\n",
      "|    value_loss         | 0.163      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 50400     |\n",
      "|    time_elapsed       | 1143      |\n",
      "|    total_timesteps    | 252000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.95     |\n",
      "|    explained_variance | 0.0801    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50399     |\n",
      "|    policy_loss        | -7.77     |\n",
      "|    reward             | 0.6108831 |\n",
      "|    std                | 22.1      |\n",
      "|    value_loss         | 0.753     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 50500      |\n",
      "|    time_elapsed       | 1145       |\n",
      "|    total_timesteps    | 252500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.93      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50499      |\n",
      "|    policy_loss        | 0.866      |\n",
      "|    reward             | 0.15516216 |\n",
      "|    std                | 21.9       |\n",
      "|    value_loss         | 0.0211     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 50600      |\n",
      "|    time_elapsed       | 1147       |\n",
      "|    total_timesteps    | 253000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.93      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 50599      |\n",
      "|    policy_loss        | 0.905      |\n",
      "|    reward             | 0.34596452 |\n",
      "|    std                | 21.9       |\n",
      "|    value_loss         | 0.292      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 50700        |\n",
      "|    time_elapsed       | 1150         |\n",
      "|    total_timesteps    | 253500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.94        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 50699        |\n",
      "|    policy_loss        | -0.397       |\n",
      "|    reward             | -0.055009864 |\n",
      "|    std                | 22           |\n",
      "|    value_loss         | 0.017        |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 50800     |\n",
      "|    time_elapsed       | 1152      |\n",
      "|    total_timesteps    | 254000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.93     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 50799     |\n",
      "|    policy_loss        | -16       |\n",
      "|    reward             | 1.2197036 |\n",
      "|    std                | 22        |\n",
      "|    value_loss         | 3.99      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 50900       |\n",
      "|    time_elapsed       | 1154        |\n",
      "|    total_timesteps    | 254500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 50899       |\n",
      "|    policy_loss        | 0.861       |\n",
      "|    reward             | -0.24970739 |\n",
      "|    std                | 22.1        |\n",
      "|    value_loss         | 0.0114      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 51000        |\n",
      "|    time_elapsed       | 1156         |\n",
      "|    total_timesteps    | 255000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.94        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 50999        |\n",
      "|    policy_loss        | -3.27        |\n",
      "|    reward             | -0.112534694 |\n",
      "|    std                | 22.1         |\n",
      "|    value_loss         | 0.145        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 51100       |\n",
      "|    time_elapsed       | 1159        |\n",
      "|    total_timesteps    | 255500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -8.94       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51099       |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | -0.09054502 |\n",
      "|    std                | 22.1        |\n",
      "|    value_loss         | 0.0227      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 51200        |\n",
      "|    time_elapsed       | 1161         |\n",
      "|    total_timesteps    | 256000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.96        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 51199        |\n",
      "|    policy_loss        | -1.83        |\n",
      "|    reward             | -0.055721484 |\n",
      "|    std                | 22.4         |\n",
      "|    value_loss         | 0.0665       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 51300      |\n",
      "|    time_elapsed       | 1163       |\n",
      "|    total_timesteps    | 256500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -8.97      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 51299      |\n",
      "|    policy_loss        | -12.1      |\n",
      "|    reward             | -0.1605142 |\n",
      "|    std                | 22.5       |\n",
      "|    value_loss         | 2.09       |\n",
      "--------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 290\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 175296.49\n",
      "total_reward: 75296.49\n",
      "total_cost: 7675.01\n",
      "total_trades: 1456\n",
      "Sharpe: 0.590\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 51400        |\n",
      "|    time_elapsed       | 1165         |\n",
      "|    total_timesteps    | 257000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -8.98        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 51399        |\n",
      "|    policy_loss        | 0.346        |\n",
      "|    reward             | -0.055401392 |\n",
      "|    std                | 22.6         |\n",
      "|    value_loss         | 0.00198      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 51500       |\n",
      "|    time_elapsed       | 1167        |\n",
      "|    total_timesteps    | 257500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9          |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51499       |\n",
      "|    policy_loss        | 0.0848      |\n",
      "|    reward             | 0.015482812 |\n",
      "|    std                | 22.8        |\n",
      "|    value_loss         | 0.0167      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 51600       |\n",
      "|    time_elapsed       | 1170        |\n",
      "|    total_timesteps    | 258000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.01       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51599       |\n",
      "|    policy_loss        | 2.44        |\n",
      "|    reward             | -0.14337304 |\n",
      "|    std                | 23          |\n",
      "|    value_loss         | 0.0965      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 51700     |\n",
      "|    time_elapsed       | 1172      |\n",
      "|    total_timesteps    | 258500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.03     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 51699     |\n",
      "|    policy_loss        | 9.3       |\n",
      "|    reward             | 0.5746048 |\n",
      "|    std                | 23.2      |\n",
      "|    value_loss         | 2.17      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 51800      |\n",
      "|    time_elapsed       | 1174       |\n",
      "|    total_timesteps    | 259000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.04      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 51799      |\n",
      "|    policy_loss        | 1.61       |\n",
      "|    reward             | 0.21033847 |\n",
      "|    std                | 23.4       |\n",
      "|    value_loss         | 0.0794     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 51900       |\n",
      "|    time_elapsed       | 1176        |\n",
      "|    total_timesteps    | 259500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.04       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51899       |\n",
      "|    policy_loss        | 4.33        |\n",
      "|    reward             | -0.22373237 |\n",
      "|    std                | 23.4        |\n",
      "|    value_loss         | 0.204       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 52000       |\n",
      "|    time_elapsed       | 1178        |\n",
      "|    total_timesteps    | 260000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.04       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 51999       |\n",
      "|    policy_loss        | -4.77       |\n",
      "|    reward             | -0.30081254 |\n",
      "|    std                | 23.4        |\n",
      "|    value_loss         | 0.288       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 52100        |\n",
      "|    time_elapsed       | 1181         |\n",
      "|    total_timesteps    | 260500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.04        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 52099        |\n",
      "|    policy_loss        | -0.0182      |\n",
      "|    reward             | -0.051207922 |\n",
      "|    std                | 23.5         |\n",
      "|    value_loss         | 0.000826     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 52200        |\n",
      "|    time_elapsed       | 1183         |\n",
      "|    total_timesteps    | 261000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.06        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 52199        |\n",
      "|    policy_loss        | 2.33         |\n",
      "|    reward             | -0.015805103 |\n",
      "|    std                | 23.6         |\n",
      "|    value_loss         | 0.0895       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 52300       |\n",
      "|    time_elapsed       | 1185        |\n",
      "|    total_timesteps    | 261500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.08       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52299       |\n",
      "|    policy_loss        | 0.898       |\n",
      "|    reward             | -0.01593391 |\n",
      "|    std                | 23.8        |\n",
      "|    value_loss         | 0.0108      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 52400      |\n",
      "|    time_elapsed       | 1187       |\n",
      "|    total_timesteps    | 262000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.1       |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52399      |\n",
      "|    policy_loss        | -0.986     |\n",
      "|    reward             | 0.11869959 |\n",
      "|    std                | 24         |\n",
      "|    value_loss         | 0.0637     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 52500      |\n",
      "|    time_elapsed       | 1190       |\n",
      "|    total_timesteps    | 262500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52499      |\n",
      "|    policy_loss        | 2.19       |\n",
      "|    reward             | -0.3824458 |\n",
      "|    std                | 24         |\n",
      "|    value_loss         | 0.0748     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 52600      |\n",
      "|    time_elapsed       | 1192       |\n",
      "|    total_timesteps    | 263000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.09      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52599      |\n",
      "|    policy_loss        | -1.57      |\n",
      "|    reward             | 0.05003727 |\n",
      "|    std                | 24         |\n",
      "|    value_loss         | 0.0852     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 52700        |\n",
      "|    time_elapsed       | 1194         |\n",
      "|    total_timesteps    | 263500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.12        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 52699        |\n",
      "|    policy_loss        | 1.76         |\n",
      "|    reward             | -0.026214624 |\n",
      "|    std                | 24.3         |\n",
      "|    value_loss         | 0.0417       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 52800      |\n",
      "|    time_elapsed       | 1196       |\n",
      "|    total_timesteps    | 264000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.14      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 52799      |\n",
      "|    policy_loss        | 1.4        |\n",
      "|    reward             | 0.42782813 |\n",
      "|    std                | 24.5       |\n",
      "|    value_loss         | 0.0952     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 52900       |\n",
      "|    time_elapsed       | 1199        |\n",
      "|    total_timesteps    | 264500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.14       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52899       |\n",
      "|    policy_loss        | -8.32       |\n",
      "|    reward             | 0.010629565 |\n",
      "|    std                | 24.5        |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 53000       |\n",
      "|    time_elapsed       | 1201        |\n",
      "|    total_timesteps    | 265000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.15       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 52999       |\n",
      "|    policy_loss        | 0.168       |\n",
      "|    reward             | 0.011524451 |\n",
      "|    std                | 24.7        |\n",
      "|    value_loss         | 0.0223      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 53100      |\n",
      "|    time_elapsed       | 1203       |\n",
      "|    total_timesteps    | 265500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.16      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53099      |\n",
      "|    policy_loss        | -3.67      |\n",
      "|    reward             | 0.06788203 |\n",
      "|    std                | 24.8       |\n",
      "|    value_loss         | 0.477      |\n",
      "--------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 300\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 323467.22\n",
      "total_reward: 223467.22\n",
      "total_cost: 12495.13\n",
      "total_trades: 1471\n",
      "Sharpe: 1.002\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 53200      |\n",
      "|    time_elapsed       | 1205       |\n",
      "|    total_timesteps    | 266000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.16      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53199      |\n",
      "|    policy_loss        | 0.269      |\n",
      "|    reward             | 0.05306858 |\n",
      "|    std                | 24.9       |\n",
      "|    value_loss         | 0.013      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 53300        |\n",
      "|    time_elapsed       | 1207         |\n",
      "|    total_timesteps    | 266500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.17        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 53299        |\n",
      "|    policy_loss        | 18.4         |\n",
      "|    reward             | -0.123320654 |\n",
      "|    std                | 24.9         |\n",
      "|    value_loss         | 4.72         |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 53400       |\n",
      "|    time_elapsed       | 1210        |\n",
      "|    total_timesteps    | 267000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.17       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53399       |\n",
      "|    policy_loss        | 4.11        |\n",
      "|    reward             | 0.079171926 |\n",
      "|    std                | 24.8        |\n",
      "|    value_loss         | 0.263       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 53500      |\n",
      "|    time_elapsed       | 1212       |\n",
      "|    total_timesteps    | 267500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.18      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53499      |\n",
      "|    policy_loss        | 5.38       |\n",
      "|    reward             | 0.04636455 |\n",
      "|    std                | 24.9       |\n",
      "|    value_loss         | 0.636      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 53600      |\n",
      "|    time_elapsed       | 1214       |\n",
      "|    total_timesteps    | 268000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.19      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53599      |\n",
      "|    policy_loss        | -2.06      |\n",
      "|    reward             | 0.02050852 |\n",
      "|    std                | 25.1       |\n",
      "|    value_loss         | 0.0411     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 53700      |\n",
      "|    time_elapsed       | 1216       |\n",
      "|    total_timesteps    | 268500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.2       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53699      |\n",
      "|    policy_loss        | 0.38       |\n",
      "|    reward             | 0.01774033 |\n",
      "|    std                | 25.2       |\n",
      "|    value_loss         | 0.00254    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 53800       |\n",
      "|    time_elapsed       | 1218        |\n",
      "|    total_timesteps    | 269000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.21       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 53799       |\n",
      "|    policy_loss        | 3.26        |\n",
      "|    reward             | -0.09265781 |\n",
      "|    std                | 25.3        |\n",
      "|    value_loss         | 0.144       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 53900     |\n",
      "|    time_elapsed       | 1221      |\n",
      "|    total_timesteps    | 269500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.23     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 53899     |\n",
      "|    policy_loss        | 1.02      |\n",
      "|    reward             | 0.1028116 |\n",
      "|    std                | 25.6      |\n",
      "|    value_loss         | 0.0152    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 54000      |\n",
      "|    time_elapsed       | 1223       |\n",
      "|    total_timesteps    | 270000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.25      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 53999      |\n",
      "|    policy_loss        | -1.44      |\n",
      "|    reward             | 0.30487126 |\n",
      "|    std                | 25.9       |\n",
      "|    value_loss         | 0.234      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 54100       |\n",
      "|    time_elapsed       | 1225        |\n",
      "|    total_timesteps    | 270500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.28       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54099       |\n",
      "|    policy_loss        | 0.633       |\n",
      "|    reward             | -0.12223323 |\n",
      "|    std                | 26.3        |\n",
      "|    value_loss         | 0.00484     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 54200      |\n",
      "|    time_elapsed       | 1227       |\n",
      "|    total_timesteps    | 271000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.28      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 54199      |\n",
      "|    policy_loss        | -2.19      |\n",
      "|    reward             | 0.14463916 |\n",
      "|    std                | 26.4       |\n",
      "|    value_loss         | 0.0692     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 54300       |\n",
      "|    time_elapsed       | 1229        |\n",
      "|    total_timesteps    | 271500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.29       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54299       |\n",
      "|    policy_loss        | 0.184       |\n",
      "|    reward             | -0.07365176 |\n",
      "|    std                | 26.5        |\n",
      "|    value_loss         | 0.00509     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 54400        |\n",
      "|    time_elapsed       | 1231         |\n",
      "|    total_timesteps    | 272000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.3         |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 54399        |\n",
      "|    policy_loss        | 3.49         |\n",
      "|    reward             | -0.008088073 |\n",
      "|    std                | 26.6         |\n",
      "|    value_loss         | 0.187        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 54500        |\n",
      "|    time_elapsed       | 1233         |\n",
      "|    total_timesteps    | 272500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.32        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 54499        |\n",
      "|    policy_loss        | -5.16        |\n",
      "|    reward             | -0.008237048 |\n",
      "|    std                | 26.7         |\n",
      "|    value_loss         | 0.496        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 54600        |\n",
      "|    time_elapsed       | 1235         |\n",
      "|    total_timesteps    | 273000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.33        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 54599        |\n",
      "|    policy_loss        | 0.663        |\n",
      "|    reward             | -0.028128296 |\n",
      "|    std                | 26.9         |\n",
      "|    value_loss         | 0.00818      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 54700       |\n",
      "|    time_elapsed       | 1237        |\n",
      "|    total_timesteps    | 273500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.34       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54699       |\n",
      "|    policy_loss        | -2.65       |\n",
      "|    reward             | 0.047876183 |\n",
      "|    std                | 27          |\n",
      "|    value_loss         | 0.121       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 54800       |\n",
      "|    time_elapsed       | 1239        |\n",
      "|    total_timesteps    | 274000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.34       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54799       |\n",
      "|    policy_loss        | -1.47       |\n",
      "|    reward             | 0.015161682 |\n",
      "|    std                | 27.1        |\n",
      "|    value_loss         | 0.0335      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 54900       |\n",
      "|    time_elapsed       | 1241        |\n",
      "|    total_timesteps    | 274500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.34       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54899       |\n",
      "|    policy_loss        | 8.77        |\n",
      "|    reward             | -0.21458948 |\n",
      "|    std                | 27          |\n",
      "|    value_loss         | 1.21        |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 310\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 223365.69\n",
      "total_reward: 123365.69\n",
      "total_cost: 12110.87\n",
      "total_trades: 1429\n",
      "Sharpe: 0.753\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 55000       |\n",
      "|    time_elapsed       | 1243        |\n",
      "|    total_timesteps    | 275000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.34       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 54999       |\n",
      "|    policy_loss        | 0.877       |\n",
      "|    reward             | -0.26727906 |\n",
      "|    std                | 27          |\n",
      "|    value_loss         | 0.0604      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 55100      |\n",
      "|    time_elapsed       | 1245       |\n",
      "|    total_timesteps    | 275500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.36      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55099      |\n",
      "|    policy_loss        | -1.16      |\n",
      "|    reward             | 0.21661133 |\n",
      "|    std                | 27.3       |\n",
      "|    value_loss         | 0.265      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 55200       |\n",
      "|    time_elapsed       | 1247        |\n",
      "|    total_timesteps    | 276000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.38       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55199       |\n",
      "|    policy_loss        | -0.0982     |\n",
      "|    reward             | -0.08168716 |\n",
      "|    std                | 27.6        |\n",
      "|    value_loss         | 0.000495    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 55300      |\n",
      "|    time_elapsed       | 1250       |\n",
      "|    total_timesteps    | 276500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.41      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55299      |\n",
      "|    policy_loss        | 0.351      |\n",
      "|    reward             | 0.09126089 |\n",
      "|    std                | 27.9       |\n",
      "|    value_loss         | 0.0176     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 55400        |\n",
      "|    time_elapsed       | 1252         |\n",
      "|    total_timesteps    | 277000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.41        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 55399        |\n",
      "|    policy_loss        | 7.16         |\n",
      "|    reward             | -0.066597536 |\n",
      "|    std                | 27.9         |\n",
      "|    value_loss         | 0.528        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 55500      |\n",
      "|    time_elapsed       | 1254       |\n",
      "|    total_timesteps    | 277500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.42      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55499      |\n",
      "|    policy_loss        | 0.496      |\n",
      "|    reward             | 0.04279136 |\n",
      "|    std                | 28.1       |\n",
      "|    value_loss         | 0.0032     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 55600       |\n",
      "|    time_elapsed       | 1256        |\n",
      "|    total_timesteps    | 278000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.44       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55599       |\n",
      "|    policy_loss        | 3.69        |\n",
      "|    reward             | -0.02475498 |\n",
      "|    std                | 28.4        |\n",
      "|    value_loss         | 0.386       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 55700      |\n",
      "|    time_elapsed       | 1258       |\n",
      "|    total_timesteps    | 278500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.46      |\n",
      "|    explained_variance | 2.38e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 55699      |\n",
      "|    policy_loss        | 2.29       |\n",
      "|    reward             | 0.29349688 |\n",
      "|    std                | 28.7       |\n",
      "|    value_loss         | 0.0763     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 55800       |\n",
      "|    time_elapsed       | 1260        |\n",
      "|    total_timesteps    | 279000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.47       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55799       |\n",
      "|    policy_loss        | -7.22       |\n",
      "|    reward             | -0.73241633 |\n",
      "|    std                | 28.7        |\n",
      "|    value_loss         | 0.689       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 55900       |\n",
      "|    time_elapsed       | 1263        |\n",
      "|    total_timesteps    | 279500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.48       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55899       |\n",
      "|    policy_loss        | 0.341       |\n",
      "|    reward             | -0.08412925 |\n",
      "|    std                | 28.8        |\n",
      "|    value_loss         | 0.0105      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 56000       |\n",
      "|    time_elapsed       | 1265        |\n",
      "|    total_timesteps    | 280000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.51       |\n",
      "|    explained_variance | -0.043      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 55999       |\n",
      "|    policy_loss        | 2.42        |\n",
      "|    reward             | -0.16865283 |\n",
      "|    std                | 29.3        |\n",
      "|    value_loss         | 0.0555      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 56100       |\n",
      "|    time_elapsed       | 1267        |\n",
      "|    total_timesteps    | 280500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.53       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 56099       |\n",
      "|    policy_loss        | -8.45       |\n",
      "|    reward             | -0.06088823 |\n",
      "|    std                | 29.6        |\n",
      "|    value_loss         | 0.96        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 56200        |\n",
      "|    time_elapsed       | 1269         |\n",
      "|    total_timesteps    | 281000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.52        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 56199        |\n",
      "|    policy_loss        | 0.366        |\n",
      "|    reward             | -0.034858923 |\n",
      "|    std                | 29.5         |\n",
      "|    value_loss         | 0.00343      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 56300       |\n",
      "|    time_elapsed       | 1271        |\n",
      "|    total_timesteps    | 281500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.55       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 56299       |\n",
      "|    policy_loss        | -3.56       |\n",
      "|    reward             | 0.015595051 |\n",
      "|    std                | 29.9        |\n",
      "|    value_loss         | 0.124       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 56400       |\n",
      "|    time_elapsed       | 1274        |\n",
      "|    total_timesteps    | 282000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.56       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 56399       |\n",
      "|    policy_loss        | -0.525      |\n",
      "|    reward             | 0.034418944 |\n",
      "|    std                | 30.1        |\n",
      "|    value_loss         | 0.00421     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 56500       |\n",
      "|    time_elapsed       | 1276        |\n",
      "|    total_timesteps    | 282500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.58       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 56499       |\n",
      "|    policy_loss        | 4.34        |\n",
      "|    reward             | -0.17223872 |\n",
      "|    std                | 30.3        |\n",
      "|    value_loss         | 0.217       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 56600      |\n",
      "|    time_elapsed       | 1278       |\n",
      "|    total_timesteps    | 283000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.6       |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56599      |\n",
      "|    policy_loss        | -0.577     |\n",
      "|    reward             | 0.11995898 |\n",
      "|    std                | 30.6       |\n",
      "|    value_loss         | 0.0118     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 56700        |\n",
      "|    time_elapsed       | 1281         |\n",
      "|    total_timesteps    | 283500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.61        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 56699        |\n",
      "|    policy_loss        | 3.37         |\n",
      "|    reward             | -0.085112356 |\n",
      "|    std                | 30.8         |\n",
      "|    value_loss         | 0.204        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 320\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 122563.42\n",
      "total_reward: 22563.42\n",
      "total_cost: 8650.12\n",
      "total_trades: 1438\n",
      "Sharpe: 0.466\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 56800      |\n",
      "|    time_elapsed       | 1283       |\n",
      "|    total_timesteps    | 284000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.63      |\n",
      "|    explained_variance | -0.717     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 56799      |\n",
      "|    policy_loss        | 0.129      |\n",
      "|    reward             | 0.09917383 |\n",
      "|    std                | 31.2       |\n",
      "|    value_loss         | 0.0122     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 56900    |\n",
      "|    time_elapsed       | 1285     |\n",
      "|    total_timesteps    | 284500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.63    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 56899    |\n",
      "|    policy_loss        | -0.504   |\n",
      "|    reward             | 0.295989 |\n",
      "|    std                | 31.1     |\n",
      "|    value_loss         | 0.0572   |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 57000       |\n",
      "|    time_elapsed       | 1287        |\n",
      "|    total_timesteps    | 285000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.63       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 56999       |\n",
      "|    policy_loss        | -3.79       |\n",
      "|    reward             | 0.021480339 |\n",
      "|    std                | 31.1        |\n",
      "|    value_loss         | 0.22        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 57100        |\n",
      "|    time_elapsed       | 1290         |\n",
      "|    total_timesteps    | 285500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.64        |\n",
      "|    explained_variance | -0.327       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 57099        |\n",
      "|    policy_loss        | -0.155       |\n",
      "|    reward             | -0.121959545 |\n",
      "|    std                | 31.5         |\n",
      "|    value_loss         | 0.00131      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 57200        |\n",
      "|    time_elapsed       | 1292         |\n",
      "|    total_timesteps    | 286000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.66        |\n",
      "|    explained_variance | -0.000323    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 57199        |\n",
      "|    policy_loss        | -0.911       |\n",
      "|    reward             | 0.0074161375 |\n",
      "|    std                | 31.7         |\n",
      "|    value_loss         | 0.144        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 57300       |\n",
      "|    time_elapsed       | 1294        |\n",
      "|    total_timesteps    | 286500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.66       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 57299       |\n",
      "|    policy_loss        | 0.291       |\n",
      "|    reward             | -0.08461726 |\n",
      "|    std                | 31.9        |\n",
      "|    value_loss         | 0.0174      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 57400      |\n",
      "|    time_elapsed       | 1297       |\n",
      "|    total_timesteps    | 287000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.68      |\n",
      "|    explained_variance | 0.0341     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57399      |\n",
      "|    policy_loss        | 1.57       |\n",
      "|    reward             | 0.20911919 |\n",
      "|    std                | 32         |\n",
      "|    value_loss         | 0.0397     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 57500       |\n",
      "|    time_elapsed       | 1299        |\n",
      "|    total_timesteps    | 287500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.7        |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 57499       |\n",
      "|    policy_loss        | 0.564       |\n",
      "|    reward             | 0.018813867 |\n",
      "|    std                | 32.3        |\n",
      "|    value_loss         | 0.0132      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 57600       |\n",
      "|    time_elapsed       | 1302        |\n",
      "|    total_timesteps    | 288000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.7        |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 57599       |\n",
      "|    policy_loss        | 0.963       |\n",
      "|    reward             | -0.09646421 |\n",
      "|    std                | 32.4        |\n",
      "|    value_loss         | 0.0189      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 57700        |\n",
      "|    time_elapsed       | 1304         |\n",
      "|    total_timesteps    | 288500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.73        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 57699        |\n",
      "|    policy_loss        | -6.11        |\n",
      "|    reward             | -0.017234527 |\n",
      "|    std                | 32.8         |\n",
      "|    value_loss         | 0.448        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 57800       |\n",
      "|    time_elapsed       | 1306        |\n",
      "|    total_timesteps    | 289000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.73       |\n",
      "|    explained_variance | 0.0719      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 57799       |\n",
      "|    policy_loss        | -1.22       |\n",
      "|    reward             | 0.014642579 |\n",
      "|    std                | 32.9        |\n",
      "|    value_loss         | 0.0204      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 57900      |\n",
      "|    time_elapsed       | 1308       |\n",
      "|    total_timesteps    | 289500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.76      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57899      |\n",
      "|    policy_loss        | 1.13       |\n",
      "|    reward             | 0.03689033 |\n",
      "|    std                | 33.3       |\n",
      "|    value_loss         | 0.013      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 58000      |\n",
      "|    time_elapsed       | 1310       |\n",
      "|    total_timesteps    | 290000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.78      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 57999      |\n",
      "|    policy_loss        | -0.58      |\n",
      "|    reward             | 0.05396089 |\n",
      "|    std                | 33.7       |\n",
      "|    value_loss         | 0.0318     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 58100      |\n",
      "|    time_elapsed       | 1313       |\n",
      "|    total_timesteps    | 290500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.78      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58099      |\n",
      "|    policy_loss        | 8.22       |\n",
      "|    reward             | 0.43022722 |\n",
      "|    std                | 33.7       |\n",
      "|    value_loss         | 0.764      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 58200      |\n",
      "|    time_elapsed       | 1315       |\n",
      "|    total_timesteps    | 291000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.79      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58199      |\n",
      "|    policy_loss        | -1.3       |\n",
      "|    reward             | 0.03984309 |\n",
      "|    std                | 33.9       |\n",
      "|    value_loss         | 0.0215     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 58300       |\n",
      "|    time_elapsed       | 1317        |\n",
      "|    total_timesteps    | 291500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.8        |\n",
      "|    explained_variance | -0.122      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58299       |\n",
      "|    policy_loss        | 5.87        |\n",
      "|    reward             | -0.10004007 |\n",
      "|    std                | 34.2        |\n",
      "|    value_loss         | 0.366       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 58400       |\n",
      "|    time_elapsed       | 1319        |\n",
      "|    total_timesteps    | 292000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.82       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58399       |\n",
      "|    policy_loss        | 0.51        |\n",
      "|    reward             | -0.17075522 |\n",
      "|    std                | 34.6        |\n",
      "|    value_loss         | 0.00724     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 58500        |\n",
      "|    time_elapsed       | 1322         |\n",
      "|    total_timesteps    | 292500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.83        |\n",
      "|    explained_variance | 0.37         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 58499        |\n",
      "|    policy_loss        | -0.218       |\n",
      "|    reward             | 0.0070219724 |\n",
      "|    std                | 34.7         |\n",
      "|    value_loss         | 0.00123      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 58600       |\n",
      "|    time_elapsed       | 1324        |\n",
      "|    total_timesteps    | 293000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.85       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58599       |\n",
      "|    policy_loss        | -1.25       |\n",
      "|    reward             | -0.16435508 |\n",
      "|    std                | 35          |\n",
      "|    value_loss         | 0.0199      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 58700      |\n",
      "|    time_elapsed       | 1326       |\n",
      "|    total_timesteps    | 293500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.87      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58699      |\n",
      "|    policy_loss        | 0.587      |\n",
      "|    reward             | -0.1706847 |\n",
      "|    std                | 35.4       |\n",
      "|    value_loss         | 0.0085     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 58800       |\n",
      "|    time_elapsed       | 1328        |\n",
      "|    total_timesteps    | 294000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.87       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 58799       |\n",
      "|    policy_loss        | -15.5       |\n",
      "|    reward             | -0.11772949 |\n",
      "|    std                | 35.5        |\n",
      "|    value_loss         | 4.04        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 58900      |\n",
      "|    time_elapsed       | 1330       |\n",
      "|    total_timesteps    | 294500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.87      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58899      |\n",
      "|    policy_loss        | 1.27       |\n",
      "|    reward             | 0.16917236 |\n",
      "|    std                | 35.4       |\n",
      "|    value_loss         | 0.0446     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 59000      |\n",
      "|    time_elapsed       | 1333       |\n",
      "|    total_timesteps    | 295000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.87      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 58999      |\n",
      "|    policy_loss        | -0.276     |\n",
      "|    reward             | 0.30181152 |\n",
      "|    std                | 35.5       |\n",
      "|    value_loss         | 0.0743     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 59100        |\n",
      "|    time_elapsed       | 1335         |\n",
      "|    total_timesteps    | 295500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.87        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 59099        |\n",
      "|    policy_loss        | 0.4          |\n",
      "|    reward             | -0.060960498 |\n",
      "|    std                | 35.6         |\n",
      "|    value_loss         | 0.076        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 59200       |\n",
      "|    time_elapsed       | 1337        |\n",
      "|    total_timesteps    | 296000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.88       |\n",
      "|    explained_variance | -0.254      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59199       |\n",
      "|    policy_loss        | -5.8        |\n",
      "|    reward             | -0.78992265 |\n",
      "|    std                | 35.8        |\n",
      "|    value_loss         | 0.477       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 59300       |\n",
      "|    time_elapsed       | 1339        |\n",
      "|    total_timesteps    | 296500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.9        |\n",
      "|    explained_variance | -0.000466   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59299       |\n",
      "|    policy_loss        | -1.44       |\n",
      "|    reward             | -0.25218993 |\n",
      "|    std                | 36.2        |\n",
      "|    value_loss         | 0.0244      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 59400       |\n",
      "|    time_elapsed       | 1342        |\n",
      "|    total_timesteps    | 297000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.91       |\n",
      "|    explained_variance | -0.629      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59399       |\n",
      "|    policy_loss        | -0.222      |\n",
      "|    reward             | 0.071448706 |\n",
      "|    std                | 36.4        |\n",
      "|    value_loss         | 0.00369     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 59500      |\n",
      "|    time_elapsed       | 1344       |\n",
      "|    total_timesteps    | 297500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.94      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59499      |\n",
      "|    policy_loss        | 0.0248     |\n",
      "|    reward             | 0.13264585 |\n",
      "|    std                | 36.8       |\n",
      "|    value_loss         | 0.00136    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 59600       |\n",
      "|    time_elapsed       | 1346        |\n",
      "|    total_timesteps    | 298000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.97       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59599       |\n",
      "|    policy_loss        | 1.31        |\n",
      "|    reward             | 0.017529486 |\n",
      "|    std                | 37.4        |\n",
      "|    value_loss         | 0.0218      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 59700      |\n",
      "|    time_elapsed       | 1348       |\n",
      "|    total_timesteps    | 298500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -9.96      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 59699      |\n",
      "|    policy_loss        | 0.294      |\n",
      "|    reward             | -0.3713513 |\n",
      "|    std                | 37.4       |\n",
      "|    value_loss         | 0.0299     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 59800       |\n",
      "|    time_elapsed       | 1351        |\n",
      "|    total_timesteps    | 299000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.98       |\n",
      "|    explained_variance | 0.542       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59799       |\n",
      "|    policy_loss        | -3.42       |\n",
      "|    reward             | -0.13861558 |\n",
      "|    std                | 37.6        |\n",
      "|    value_loss         | 0.111       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 59900       |\n",
      "|    time_elapsed       | 1353        |\n",
      "|    total_timesteps    | 299500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -9.98       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 59899       |\n",
      "|    policy_loss        | 4.95        |\n",
      "|    reward             | -0.19521289 |\n",
      "|    std                | 37.6        |\n",
      "|    value_loss         | 0.312       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 60000        |\n",
      "|    time_elapsed       | 1355         |\n",
      "|    total_timesteps    | 300000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -9.99        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 59999        |\n",
      "|    policy_loss        | 0.722        |\n",
      "|    reward             | -0.032672606 |\n",
      "|    std                | 37.9         |\n",
      "|    value_loss         | 0.00576      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 60100        |\n",
      "|    time_elapsed       | 1357         |\n",
      "|    total_timesteps    | 300500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10          |\n",
      "|    explained_variance | 0.0484       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 60099        |\n",
      "|    policy_loss        | -0.763       |\n",
      "|    reward             | -0.011205713 |\n",
      "|    std                | 38           |\n",
      "|    value_loss         | 0.0126       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 60200       |\n",
      "|    time_elapsed       | 1360        |\n",
      "|    total_timesteps    | 301000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 60199       |\n",
      "|    policy_loss        | -0.904      |\n",
      "|    reward             | 0.055112693 |\n",
      "|    std                | 38.4        |\n",
      "|    value_loss         | 0.0148      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 60300      |\n",
      "|    time_elapsed       | 1362       |\n",
      "|    total_timesteps    | 301500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10        |\n",
      "|    explained_variance | -0.157     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60299      |\n",
      "|    policy_loss        | -0.874     |\n",
      "|    reward             | 0.07826841 |\n",
      "|    std                | 38.7       |\n",
      "|    value_loss         | 0.0163     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 60400      |\n",
      "|    time_elapsed       | 1364       |\n",
      "|    total_timesteps    | 302000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 60399      |\n",
      "|    policy_loss        | -13.3      |\n",
      "|    reward             | -1.9112234 |\n",
      "|    std                | 38.6       |\n",
      "|    value_loss         | 4.35       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 60500       |\n",
      "|    time_elapsed       | 1366        |\n",
      "|    total_timesteps    | 302500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | -6.33       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 60499       |\n",
      "|    policy_loss        | -1.03       |\n",
      "|    reward             | 0.045078125 |\n",
      "|    std                | 39          |\n",
      "|    value_loss         | 0.0162      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 60600       |\n",
      "|    time_elapsed       | 1368        |\n",
      "|    total_timesteps    | 303000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 60599       |\n",
      "|    policy_loss        | 0.426       |\n",
      "|    reward             | -0.09209502 |\n",
      "|    std                | 39.1        |\n",
      "|    value_loss         | 0.00746     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 60700     |\n",
      "|    time_elapsed       | 1371      |\n",
      "|    total_timesteps    | 303500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10       |\n",
      "|    explained_variance | 0.0213    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 60699     |\n",
      "|    policy_loss        | -1.72     |\n",
      "|    reward             | 0.6505882 |\n",
      "|    std                | 39.1      |\n",
      "|    value_loss         | 0.301     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 60800       |\n",
      "|    time_elapsed       | 1373        |\n",
      "|    total_timesteps    | 304000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 60799       |\n",
      "|    policy_loss        | 1.67        |\n",
      "|    reward             | -0.27984348 |\n",
      "|    std                | 39.1        |\n",
      "|    value_loss         | 0.31        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 60900       |\n",
      "|    time_elapsed       | 1375        |\n",
      "|    total_timesteps    | 304500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 60899       |\n",
      "|    policy_loss        | 0.479       |\n",
      "|    reward             | -0.18463184 |\n",
      "|    std                | 39          |\n",
      "|    value_loss         | 0.00487     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 61000       |\n",
      "|    time_elapsed       | 1378        |\n",
      "|    total_timesteps    | 305000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 60999       |\n",
      "|    policy_loss        | -2.42       |\n",
      "|    reward             | -0.11273664 |\n",
      "|    std                | 39.3        |\n",
      "|    value_loss         | 0.0625      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 61100      |\n",
      "|    time_elapsed       | 1380       |\n",
      "|    total_timesteps    | 305500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10        |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61099      |\n",
      "|    policy_loss        | 0.549      |\n",
      "|    reward             | 0.28085795 |\n",
      "|    std                | 39.2       |\n",
      "|    value_loss         | 0.0222     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 61200       |\n",
      "|    time_elapsed       | 1382        |\n",
      "|    total_timesteps    | 306000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61199       |\n",
      "|    policy_loss        | -0.614      |\n",
      "|    reward             | 0.070939444 |\n",
      "|    std                | 39.4        |\n",
      "|    value_loss         | 0.00598     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 61300      |\n",
      "|    time_elapsed       | 1385       |\n",
      "|    total_timesteps    | 306500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | -0.0143    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61299      |\n",
      "|    policy_loss        | -0.79      |\n",
      "|    reward             | 0.31319138 |\n",
      "|    std                | 39.8       |\n",
      "|    value_loss         | 0.0134     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 61400      |\n",
      "|    time_elapsed       | 1387       |\n",
      "|    total_timesteps    | 307000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | -0.677     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61399      |\n",
      "|    policy_loss        | 0.273      |\n",
      "|    reward             | 0.15059388 |\n",
      "|    std                | 40.2       |\n",
      "|    value_loss         | 0.00728    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 61500      |\n",
      "|    time_elapsed       | 1390       |\n",
      "|    total_timesteps    | 307500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | 0.00358    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61499      |\n",
      "|    policy_loss        | 0.184      |\n",
      "|    reward             | 0.23546074 |\n",
      "|    std                | 40.8       |\n",
      "|    value_loss         | 0.0155     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 61600      |\n",
      "|    time_elapsed       | 1392       |\n",
      "|    total_timesteps    | 308000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 61599      |\n",
      "|    policy_loss        | 2.38       |\n",
      "|    reward             | 0.17892994 |\n",
      "|    std                | 41.3       |\n",
      "|    value_loss         | 0.0779     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 61700       |\n",
      "|    time_elapsed       | 1394        |\n",
      "|    total_timesteps    | 308500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61699       |\n",
      "|    policy_loss        | -0.424      |\n",
      "|    reward             | 0.017463082 |\n",
      "|    std                | 41.1        |\n",
      "|    value_loss         | 0.00222     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 61800       |\n",
      "|    time_elapsed       | 1396        |\n",
      "|    total_timesteps    | 309000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61799       |\n",
      "|    policy_loss        | -0.412      |\n",
      "|    reward             | 0.112522505 |\n",
      "|    std                | 41.3        |\n",
      "|    value_loss         | 0.0188      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 61900       |\n",
      "|    time_elapsed       | 1399        |\n",
      "|    total_timesteps    | 309500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.1       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61899       |\n",
      "|    policy_loss        | -0.502      |\n",
      "|    reward             | 0.041082777 |\n",
      "|    std                | 41.4        |\n",
      "|    value_loss         | 0.00311     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 62000       |\n",
      "|    time_elapsed       | 1401        |\n",
      "|    total_timesteps    | 310000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.2       |\n",
      "|    explained_variance | 0.00877     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 61999       |\n",
      "|    policy_loss        | -1.49       |\n",
      "|    reward             | -0.27184063 |\n",
      "|    std                | 41.8        |\n",
      "|    value_loss         | 0.146       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 62100      |\n",
      "|    time_elapsed       | 1403       |\n",
      "|    total_timesteps    | 310500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62099      |\n",
      "|    policy_loss        | 0.483      |\n",
      "|    reward             | 0.03713894 |\n",
      "|    std                | 42.5       |\n",
      "|    value_loss         | 0.00526    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 221           |\n",
      "|    iterations         | 62200         |\n",
      "|    time_elapsed       | 1406          |\n",
      "|    total_timesteps    | 311000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 62199         |\n",
      "|    policy_loss        | -2.07         |\n",
      "|    reward             | -0.0040874025 |\n",
      "|    std                | 42.8          |\n",
      "|    value_loss         | 0.0498        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 62300      |\n",
      "|    time_elapsed       | 1408       |\n",
      "|    total_timesteps    | 311500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62299      |\n",
      "|    policy_loss        | -1.75      |\n",
      "|    reward             | 0.02085105 |\n",
      "|    std                | 43.1       |\n",
      "|    value_loss         | 0.0617     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 62400        |\n",
      "|    time_elapsed       | 1410         |\n",
      "|    total_timesteps    | 312000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 62399        |\n",
      "|    policy_loss        | 0.0194       |\n",
      "|    reward             | -0.035095606 |\n",
      "|    std                | 43.7         |\n",
      "|    value_loss         | 0.0704       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 62500      |\n",
      "|    time_elapsed       | 1412       |\n",
      "|    total_timesteps    | 312500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62499      |\n",
      "|    policy_loss        | -0.216     |\n",
      "|    reward             | 0.04210117 |\n",
      "|    std                | 43.7       |\n",
      "|    value_loss         | 0.0128     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 62600      |\n",
      "|    time_elapsed       | 1415       |\n",
      "|    total_timesteps    | 313000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 62599      |\n",
      "|    policy_loss        | -1.09      |\n",
      "|    reward             | 0.06505967 |\n",
      "|    std                | 44.5       |\n",
      "|    value_loss         | 0.0164     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 62700       |\n",
      "|    time_elapsed       | 1417        |\n",
      "|    total_timesteps    | 313500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62699       |\n",
      "|    policy_loss        | 1.34        |\n",
      "|    reward             | 0.012088197 |\n",
      "|    std                | 44.5        |\n",
      "|    value_loss         | 0.0487      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 62800       |\n",
      "|    time_elapsed       | 1419        |\n",
      "|    total_timesteps    | 314000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | 0.0175      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 62799       |\n",
      "|    policy_loss        | -3.93       |\n",
      "|    reward             | -0.08346492 |\n",
      "|    std                | 44.4        |\n",
      "|    value_loss         | 0.165       |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 62900     |\n",
      "|    time_elapsed       | 1421      |\n",
      "|    total_timesteps    | 314500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.3     |\n",
      "|    explained_variance | 0.139     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62899     |\n",
      "|    policy_loss        | -1.44     |\n",
      "|    reward             | 0.6183993 |\n",
      "|    std                | 44.3      |\n",
      "|    value_loss         | 0.0548    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 63000     |\n",
      "|    time_elapsed       | 1424      |\n",
      "|    total_timesteps    | 315000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 62999     |\n",
      "|    policy_loss        | -3.2      |\n",
      "|    reward             | 0.2544431 |\n",
      "|    std                | 44.3      |\n",
      "|    value_loss         | 0.127     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 63100       |\n",
      "|    time_elapsed       | 1426        |\n",
      "|    total_timesteps    | 315500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 63099       |\n",
      "|    policy_loss        | 10.9        |\n",
      "|    reward             | -0.46904165 |\n",
      "|    std                | 44.7        |\n",
      "|    value_loss         | 1.11        |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 221      |\n",
      "|    iterations         | 63200    |\n",
      "|    time_elapsed       | 1429     |\n",
      "|    total_timesteps    | 316000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 63199    |\n",
      "|    policy_loss        | 3.07     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 44.9     |\n",
      "|    value_loss         | 0.0968   |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 221          |\n",
      "|    iterations         | 63300        |\n",
      "|    time_elapsed       | 1431         |\n",
      "|    total_timesteps    | 316500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 63299        |\n",
      "|    policy_loss        | -1.36        |\n",
      "|    reward             | -0.012406808 |\n",
      "|    std                | 45           |\n",
      "|    value_loss         | 0.0172       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 221        |\n",
      "|    iterations         | 63400      |\n",
      "|    time_elapsed       | 1433       |\n",
      "|    total_timesteps    | 317000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.3      |\n",
      "|    explained_variance | -0.00328   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 63399      |\n",
      "|    policy_loss        | -1.87      |\n",
      "|    reward             | 0.23772666 |\n",
      "|    std                | 45.4       |\n",
      "|    value_loss         | 0.0319     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 63500       |\n",
      "|    time_elapsed       | 1436        |\n",
      "|    total_timesteps    | 317500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | -0.732      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 63499       |\n",
      "|    policy_loss        | -2.72       |\n",
      "|    reward             | 0.085572265 |\n",
      "|    std                | 45.8        |\n",
      "|    value_loss         | 0.0572      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 63600     |\n",
      "|    time_elapsed       | 1438      |\n",
      "|    total_timesteps    | 318000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63599     |\n",
      "|    policy_loss        | -44       |\n",
      "|    reward             | 0.9082683 |\n",
      "|    std                | 45.6      |\n",
      "|    value_loss         | 19.7      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 63700       |\n",
      "|    time_elapsed       | 1440        |\n",
      "|    total_timesteps    | 318500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.3       |\n",
      "|    explained_variance | -0.0815     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 63699       |\n",
      "|    policy_loss        | -1.61       |\n",
      "|    reward             | 0.061045155 |\n",
      "|    std                | 45.8        |\n",
      "|    value_loss         | 0.0249      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 63800       |\n",
      "|    time_elapsed       | 1442        |\n",
      "|    total_timesteps    | 319000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 63799       |\n",
      "|    policy_loss        | -2.52       |\n",
      "|    reward             | -0.13675562 |\n",
      "|    std                | 46.2        |\n",
      "|    value_loss         | 0.0511      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 63900       |\n",
      "|    time_elapsed       | 1445        |\n",
      "|    total_timesteps    | 319500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 63899       |\n",
      "|    policy_loss        | -3.32       |\n",
      "|    reward             | -0.06390884 |\n",
      "|    std                | 46.6        |\n",
      "|    value_loss         | 0.0974      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 221       |\n",
      "|    iterations         | 64000     |\n",
      "|    time_elapsed       | 1447      |\n",
      "|    total_timesteps    | 320000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 63999     |\n",
      "|    policy_loss        | 2.29      |\n",
      "|    reward             | 0.2416084 |\n",
      "|    std                | 46.8      |\n",
      "|    value_loss         | 0.108     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 221         |\n",
      "|    iterations         | 64100       |\n",
      "|    time_elapsed       | 1450        |\n",
      "|    total_timesteps    | 320500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 64099       |\n",
      "|    policy_loss        | -0.695      |\n",
      "|    reward             | -0.10629507 |\n",
      "|    std                | 47.1        |\n",
      "|    value_loss         | 0.0172      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 220           |\n",
      "|    iterations         | 64200         |\n",
      "|    time_elapsed       | 1452          |\n",
      "|    total_timesteps    | 321000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 64199         |\n",
      "|    policy_loss        | 0.0409        |\n",
      "|    reward             | -0.0039964975 |\n",
      "|    std                | 47.5          |\n",
      "|    value_loss         | 0.00128       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 64300       |\n",
      "|    time_elapsed       | 1454        |\n",
      "|    total_timesteps    | 321500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 64299       |\n",
      "|    policy_loss        | 1.18        |\n",
      "|    reward             | -0.41007113 |\n",
      "|    std                | 48.3        |\n",
      "|    value_loss         | 0.0193      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 64400      |\n",
      "|    time_elapsed       | 1457       |\n",
      "|    total_timesteps    | 322000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.4      |\n",
      "|    explained_variance | 0.101      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64399      |\n",
      "|    policy_loss        | -2.7       |\n",
      "|    reward             | -0.1542914 |\n",
      "|    std                | 48.2       |\n",
      "|    value_loss         | 0.0816     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 64500    |\n",
      "|    time_elapsed       | 1459     |\n",
      "|    total_timesteps    | 322500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.5    |\n",
      "|    explained_variance | 0.0038   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 64499    |\n",
      "|    policy_loss        | 0.287    |\n",
      "|    reward             | 0.515239 |\n",
      "|    std                | 48.5     |\n",
      "|    value_loss         | 0.0132   |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 64600       |\n",
      "|    time_elapsed       | 1461        |\n",
      "|    total_timesteps    | 323000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 64599       |\n",
      "|    policy_loss        | 0.706       |\n",
      "|    reward             | 0.011527344 |\n",
      "|    std                | 49          |\n",
      "|    value_loss         | 0.00542     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 220           |\n",
      "|    iterations         | 64700         |\n",
      "|    time_elapsed       | 1464          |\n",
      "|    total_timesteps    | 323500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -10.5         |\n",
      "|    explained_variance | -0.242        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 64699         |\n",
      "|    policy_loss        | 2.37          |\n",
      "|    reward             | -0.0011938476 |\n",
      "|    std                | 49.3          |\n",
      "|    value_loss         | 0.0542        |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 64800     |\n",
      "|    time_elapsed       | 1466      |\n",
      "|    total_timesteps    | 324000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 64799     |\n",
      "|    policy_loss        | -1.05     |\n",
      "|    reward             | 0.0709375 |\n",
      "|    std                | 49.6      |\n",
      "|    value_loss         | 0.00958   |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 64900      |\n",
      "|    time_elapsed       | 1468       |\n",
      "|    total_timesteps    | 324500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 64899      |\n",
      "|    policy_loss        | 0.115      |\n",
      "|    reward             | 0.06687795 |\n",
      "|    std                | 49.9       |\n",
      "|    value_loss         | 0.000209   |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 65000    |\n",
      "|    time_elapsed       | 1471     |\n",
      "|    total_timesteps    | 325000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 64999    |\n",
      "|    policy_loss        | -1.87    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 50.4     |\n",
      "|    value_loss         | 0.047    |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 65100       |\n",
      "|    time_elapsed       | 1473        |\n",
      "|    total_timesteps    | 325500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 65099       |\n",
      "|    policy_loss        | -0.978      |\n",
      "|    reward             | 0.055738293 |\n",
      "|    std                | 50.6        |\n",
      "|    value_loss         | 0.0144      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 65200      |\n",
      "|    time_elapsed       | 1475       |\n",
      "|    total_timesteps    | 326000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.6      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65199      |\n",
      "|    policy_loss        | -29.6      |\n",
      "|    reward             | 0.46543095 |\n",
      "|    std                | 50.9       |\n",
      "|    value_loss         | 8.92       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 65300        |\n",
      "|    time_elapsed       | 1478         |\n",
      "|    total_timesteps    | 326500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 65299        |\n",
      "|    policy_loss        | 0.733        |\n",
      "|    reward             | -0.004519708 |\n",
      "|    std                | 51.2         |\n",
      "|    value_loss         | 0.0132       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 65400        |\n",
      "|    time_elapsed       | 1480         |\n",
      "|    total_timesteps    | 327000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 65399        |\n",
      "|    policy_loss        | 1.56         |\n",
      "|    reward             | -0.024059325 |\n",
      "|    std                | 51.4         |\n",
      "|    value_loss         | 0.0296       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 65500      |\n",
      "|    time_elapsed       | 1482       |\n",
      "|    total_timesteps    | 327500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.6      |\n",
      "|    explained_variance | -0.213     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65499      |\n",
      "|    policy_loss        | -0.748     |\n",
      "|    reward             | 0.32893756 |\n",
      "|    std                | 51.5       |\n",
      "|    value_loss         | 0.0353     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 65600       |\n",
      "|    time_elapsed       | 1484        |\n",
      "|    total_timesteps    | 328000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 65599       |\n",
      "|    policy_loss        | 18.2        |\n",
      "|    reward             | 0.056131918 |\n",
      "|    std                | 51.6        |\n",
      "|    value_loss         | 5.02        |\n",
      "---------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 370\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 249215.43\n",
      "total_reward: 149215.43\n",
      "total_cost: 35325.95\n",
      "total_trades: 1431\n",
      "Sharpe: 0.842\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 65700       |\n",
      "|    time_elapsed       | 1487        |\n",
      "|    total_timesteps    | 328500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | -0.0317     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 65699       |\n",
      "|    policy_loss        | -1.44       |\n",
      "|    reward             | -0.25576568 |\n",
      "|    std                | 51.9        |\n",
      "|    value_loss         | 0.0483      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 65800      |\n",
      "|    time_elapsed       | 1489       |\n",
      "|    total_timesteps    | 329000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 65799      |\n",
      "|    policy_loss        | 0.478      |\n",
      "|    reward             | 0.05390332 |\n",
      "|    std                | 52.1       |\n",
      "|    value_loss         | 0.00252    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 65900       |\n",
      "|    time_elapsed       | 1491        |\n",
      "|    total_timesteps    | 329500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 65899       |\n",
      "|    policy_loss        | 1.28        |\n",
      "|    reward             | -0.07893492 |\n",
      "|    std                | 52.8        |\n",
      "|    value_loss         | 0.0157      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 66000        |\n",
      "|    time_elapsed       | 1494         |\n",
      "|    total_timesteps    | 330000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 65999        |\n",
      "|    policy_loss        | -0.369       |\n",
      "|    reward             | -0.015577734 |\n",
      "|    std                | 53.2         |\n",
      "|    value_loss         | 0.00532      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 66100      |\n",
      "|    time_elapsed       | 1496       |\n",
      "|    total_timesteps    | 330500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66099      |\n",
      "|    policy_loss        | 1.25       |\n",
      "|    reward             | 0.24561258 |\n",
      "|    std                | 53.5       |\n",
      "|    value_loss         | 0.0294     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 66200       |\n",
      "|    time_elapsed       | 1498        |\n",
      "|    total_timesteps    | 331000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66199       |\n",
      "|    policy_loss        | -1.48       |\n",
      "|    reward             | 0.038857177 |\n",
      "|    std                | 53.2        |\n",
      "|    value_loss         | 0.0304      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 66300    |\n",
      "|    time_elapsed       | 1500     |\n",
      "|    total_timesteps    | 331500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 66299    |\n",
      "|    policy_loss        | 6.01     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 53.6     |\n",
      "|    value_loss         | 0.76     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 66400       |\n",
      "|    time_elapsed       | 1502        |\n",
      "|    total_timesteps    | 332000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66399       |\n",
      "|    policy_loss        | -0.65       |\n",
      "|    reward             | 0.042638306 |\n",
      "|    std                | 54          |\n",
      "|    value_loss         | 0.00464     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 66500       |\n",
      "|    time_elapsed       | 1504        |\n",
      "|    total_timesteps    | 332500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66499       |\n",
      "|    policy_loss        | -0.224      |\n",
      "|    reward             | 0.029735938 |\n",
      "|    std                | 54.8        |\n",
      "|    value_loss         | 0.000487    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 66600       |\n",
      "|    time_elapsed       | 1507        |\n",
      "|    total_timesteps    | 333000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | -1.81       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66599       |\n",
      "|    policy_loss        | -2.04       |\n",
      "|    reward             | -0.17844775 |\n",
      "|    std                | 55.5        |\n",
      "|    value_loss         | 0.0419      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 66700       |\n",
      "|    time_elapsed       | 1509        |\n",
      "|    total_timesteps    | 333500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.7       |\n",
      "|    explained_variance | 0.141       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66699       |\n",
      "|    policy_loss        | -0.00691    |\n",
      "|    reward             | 0.059485547 |\n",
      "|    std                | 55.9        |\n",
      "|    value_loss         | 0.000967    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 66800      |\n",
      "|    time_elapsed       | 1511       |\n",
      "|    total_timesteps    | 334000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 66799      |\n",
      "|    policy_loss        | -10.5      |\n",
      "|    reward             | 0.45531407 |\n",
      "|    std                | 56.4       |\n",
      "|    value_loss         | 1.02       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 66900        |\n",
      "|    time_elapsed       | 1513         |\n",
      "|    total_timesteps    | 334500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 66899        |\n",
      "|    policy_loss        | 4.45         |\n",
      "|    reward             | -0.012452739 |\n",
      "|    std                | 56.7         |\n",
      "|    value_loss         | 0.237        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 67000       |\n",
      "|    time_elapsed       | 1515        |\n",
      "|    total_timesteps    | 335000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 66999       |\n",
      "|    policy_loss        | 5.14        |\n",
      "|    reward             | -0.19986442 |\n",
      "|    std                | 56.6        |\n",
      "|    value_loss         | 0.414       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 67100        |\n",
      "|    time_elapsed       | 1518         |\n",
      "|    total_timesteps    | 335500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 67099        |\n",
      "|    policy_loss        | 0.527        |\n",
      "|    reward             | -0.032733984 |\n",
      "|    std                | 56.8         |\n",
      "|    value_loss         | 0.00423      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 67200        |\n",
      "|    time_elapsed       | 1520         |\n",
      "|    total_timesteps    | 336000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.8        |\n",
      "|    explained_variance | -0.113       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 67199        |\n",
      "|    policy_loss        | 1.25         |\n",
      "|    reward             | -0.017170899 |\n",
      "|    std                | 57.9         |\n",
      "|    value_loss         | 0.0573       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 67300       |\n",
      "|    time_elapsed       | 1522        |\n",
      "|    total_timesteps    | 336500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67299       |\n",
      "|    policy_loss        | -2.3        |\n",
      "|    reward             | 0.006907422 |\n",
      "|    std                | 58.4        |\n",
      "|    value_loss         | 0.09        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 67400      |\n",
      "|    time_elapsed       | 1524       |\n",
      "|    total_timesteps    | 337000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 67399      |\n",
      "|    policy_loss        | -0.892     |\n",
      "|    reward             | 0.21635498 |\n",
      "|    std                | 58.8       |\n",
      "|    value_loss         | 0.011      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 67500       |\n",
      "|    time_elapsed       | 1527        |\n",
      "|    total_timesteps    | 337500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67499       |\n",
      "|    policy_loss        | -1.16       |\n",
      "|    reward             | 0.049773145 |\n",
      "|    std                | 59.6        |\n",
      "|    value_loss         | 0.0167      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 67600       |\n",
      "|    time_elapsed       | 1530        |\n",
      "|    total_timesteps    | 338000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | 0.00329     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67599       |\n",
      "|    policy_loss        | 1.34        |\n",
      "|    reward             | 0.098627344 |\n",
      "|    std                | 59.3        |\n",
      "|    value_loss         | 0.0407      |\n",
      "---------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                 |                 |\n",
      "|    fps                | 220             |\n",
      "|    iterations         | 67700           |\n",
      "|    time_elapsed       | 1532            |\n",
      "|    total_timesteps    | 338500          |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -10.8           |\n",
      "|    explained_variance | 0               |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 67699           |\n",
      "|    policy_loss        | 1.53            |\n",
      "|    reward             | -0.000120846096 |\n",
      "|    std                | 59.2            |\n",
      "|    value_loss         | 0.0381          |\n",
      "-------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 67800       |\n",
      "|    time_elapsed       | 1535        |\n",
      "|    total_timesteps    | 339000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67799       |\n",
      "|    policy_loss        | 0.054       |\n",
      "|    reward             | -0.20337598 |\n",
      "|    std                | 59.8        |\n",
      "|    value_loss         | 0.00268     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 67900      |\n",
      "|    time_elapsed       | 1537       |\n",
      "|    total_timesteps    | 339500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 67899      |\n",
      "|    policy_loss        | 7.99       |\n",
      "|    reward             | 0.49941307 |\n",
      "|    std                | 60.1       |\n",
      "|    value_loss         | 0.953      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 68000       |\n",
      "|    time_elapsed       | 1539        |\n",
      "|    total_timesteps    | 340000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 67999       |\n",
      "|    policy_loss        | -0.408      |\n",
      "|    reward             | 0.040829394 |\n",
      "|    std                | 60.9        |\n",
      "|    value_loss         | 0.00336     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 68100      |\n",
      "|    time_elapsed       | 1542       |\n",
      "|    total_timesteps    | 340500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68099      |\n",
      "|    policy_loss        | -0.196     |\n",
      "|    reward             | 0.09595755 |\n",
      "|    std                | 61.2       |\n",
      "|    value_loss         | 0.000486   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 68200       |\n",
      "|    time_elapsed       | 1544        |\n",
      "|    total_timesteps    | 341000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68199       |\n",
      "|    policy_loss        | -0.921      |\n",
      "|    reward             | 0.038398862 |\n",
      "|    std                | 61.8        |\n",
      "|    value_loss         | 0.0125      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 68300       |\n",
      "|    time_elapsed       | 1546        |\n",
      "|    total_timesteps    | 341500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68299       |\n",
      "|    policy_loss        | 0.395       |\n",
      "|    reward             | 0.045091774 |\n",
      "|    std                | 62.1        |\n",
      "|    value_loss         | 0.0215      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 68400      |\n",
      "|    time_elapsed       | 1548       |\n",
      "|    total_timesteps    | 342000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68399      |\n",
      "|    policy_loss        | -12        |\n",
      "|    reward             | -2.6604238 |\n",
      "|    std                | 62.4       |\n",
      "|    value_loss         | 1.59       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 68500       |\n",
      "|    time_elapsed       | 1551        |\n",
      "|    total_timesteps    | 342500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | -0.332      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68499       |\n",
      "|    policy_loss        | 5.4         |\n",
      "|    reward             | 0.117703125 |\n",
      "|    std                | 62.7        |\n",
      "|    value_loss         | 0.267       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 68600        |\n",
      "|    time_elapsed       | 1553         |\n",
      "|    total_timesteps    | 343000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 68599        |\n",
      "|    policy_loss        | 9.29         |\n",
      "|    reward             | -0.019573776 |\n",
      "|    std                | 62           |\n",
      "|    value_loss         | 1.08         |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 68700     |\n",
      "|    time_elapsed       | 1556      |\n",
      "|    total_timesteps    | 343500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 68699     |\n",
      "|    policy_loss        | 0.995     |\n",
      "|    reward             | 0.1584209 |\n",
      "|    std                | 62.1      |\n",
      "|    value_loss         | 0.012     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 68800      |\n",
      "|    time_elapsed       | 1558       |\n",
      "|    total_timesteps    | 344000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | 0.248      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 68799      |\n",
      "|    policy_loss        | 0.526      |\n",
      "|    reward             | 0.09024492 |\n",
      "|    std                | 62.6       |\n",
      "|    value_loss         | 0.0137     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 68900       |\n",
      "|    time_elapsed       | 1560        |\n",
      "|    total_timesteps    | 344500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -10.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 68899       |\n",
      "|    policy_loss        | -1.92       |\n",
      "|    reward             | 0.028980957 |\n",
      "|    std                | 62.8        |\n",
      "|    value_loss         | 0.0859      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 69000        |\n",
      "|    time_elapsed       | 1563         |\n",
      "|    total_timesteps    | 345000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 68999        |\n",
      "|    policy_loss        | -0.642       |\n",
      "|    reward             | -0.003472327 |\n",
      "|    std                | 62.7         |\n",
      "|    value_loss         | 0.00617      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 69100        |\n",
      "|    time_elapsed       | 1565         |\n",
      "|    total_timesteps    | 345500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 69099        |\n",
      "|    policy_loss        | 0.185        |\n",
      "|    reward             | -0.009931933 |\n",
      "|    std                | 62.9         |\n",
      "|    value_loss         | 0.00419      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 390\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 170663.14\n",
      "total_reward: 70663.14\n",
      "total_cost: 18515.03\n",
      "total_trades: 1436\n",
      "Sharpe: 0.620\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 69200        |\n",
      "|    time_elapsed       | 1567         |\n",
      "|    total_timesteps    | 346000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -10.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 69199        |\n",
      "|    policy_loss        | 2.79         |\n",
      "|    reward             | -0.040604882 |\n",
      "|    std                | 62.8         |\n",
      "|    value_loss         | 0.114        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 69300      |\n",
      "|    time_elapsed       | 1569       |\n",
      "|    total_timesteps    | 346500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -10.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 69299      |\n",
      "|    policy_loss        | 1.15       |\n",
      "|    reward             | 0.04636084 |\n",
      "|    std                | 63.1       |\n",
      "|    value_loss         | 0.039      |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 69400    |\n",
      "|    time_elapsed       | 1572     |\n",
      "|    total_timesteps    | 347000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -11      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 69399    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 63.8     |\n",
      "|    value_loss         | 0.01     |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 69500       |\n",
      "|    time_elapsed       | 1574        |\n",
      "|    total_timesteps    | 347500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69499       |\n",
      "|    policy_loss        | 5.67        |\n",
      "|    reward             | 0.023864979 |\n",
      "|    std                | 64.3        |\n",
      "|    value_loss         | 0.458       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 69600       |\n",
      "|    time_elapsed       | 1576        |\n",
      "|    total_timesteps    | 348000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | -0.539      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69599       |\n",
      "|    policy_loss        | -0.214      |\n",
      "|    reward             | -0.02029541 |\n",
      "|    std                | 64.8        |\n",
      "|    value_loss         | 0.00229     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 69700       |\n",
      "|    time_elapsed       | 1579        |\n",
      "|    total_timesteps    | 348500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | -5.39       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69699       |\n",
      "|    policy_loss        | 0.379       |\n",
      "|    reward             | -0.15699206 |\n",
      "|    std                | 65.4        |\n",
      "|    value_loss         | 0.00475     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 69800       |\n",
      "|    time_elapsed       | 1581        |\n",
      "|    total_timesteps    | 349000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | -0.237      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69799       |\n",
      "|    policy_loss        | -0.205      |\n",
      "|    reward             | -0.14858782 |\n",
      "|    std                | 65.9        |\n",
      "|    value_loss         | 0.00924     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 69900       |\n",
      "|    time_elapsed       | 1583        |\n",
      "|    total_timesteps    | 349500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 69899       |\n",
      "|    policy_loss        | 1.83        |\n",
      "|    reward             | -0.11142715 |\n",
      "|    std                | 65.6        |\n",
      "|    value_loss         | 0.0509      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 70000     |\n",
      "|    time_elapsed       | 1585      |\n",
      "|    total_timesteps    | 350000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 69999     |\n",
      "|    policy_loss        | -16       |\n",
      "|    reward             | 1.0440843 |\n",
      "|    std                | 66.7      |\n",
      "|    value_loss         | 3.77      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 70100      |\n",
      "|    time_elapsed       | 1588       |\n",
      "|    total_timesteps    | 350500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.1      |\n",
      "|    explained_variance | 0.498      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 70099      |\n",
      "|    policy_loss        | -0.512     |\n",
      "|    reward             | 0.13830811 |\n",
      "|    std                | 67.3       |\n",
      "|    value_loss         | 0.00306    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 70200      |\n",
      "|    time_elapsed       | 1590       |\n",
      "|    total_timesteps    | 351000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.1      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 70199      |\n",
      "|    policy_loss        | 4.67       |\n",
      "|    reward             | 0.33387995 |\n",
      "|    std                | 67.8       |\n",
      "|    value_loss         | 0.185      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 70300        |\n",
      "|    time_elapsed       | 1592         |\n",
      "|    total_timesteps    | 351500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 70299        |\n",
      "|    policy_loss        | 1.99         |\n",
      "|    reward             | -0.010717305 |\n",
      "|    std                | 68           |\n",
      "|    value_loss         | 0.0475       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 70400       |\n",
      "|    time_elapsed       | 1594        |\n",
      "|    total_timesteps    | 352000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70399       |\n",
      "|    policy_loss        | 6.99        |\n",
      "|    reward             | -0.23716068 |\n",
      "|    std                | 68.6        |\n",
      "|    value_loss         | 0.486       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 70500      |\n",
      "|    time_elapsed       | 1597       |\n",
      "|    total_timesteps    | 352500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 70499      |\n",
      "|    policy_loss        | -3.01      |\n",
      "|    reward             | 0.15619624 |\n",
      "|    std                | 68.6       |\n",
      "|    value_loss         | 0.357      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 70600       |\n",
      "|    time_elapsed       | 1599        |\n",
      "|    total_timesteps    | 353000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | -8.87       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70599       |\n",
      "|    policy_loss        | 0.245       |\n",
      "|    reward             | 0.025297046 |\n",
      "|    std                | 68.9        |\n",
      "|    value_loss         | 0.00159     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 70700        |\n",
      "|    time_elapsed       | 1602         |\n",
      "|    total_timesteps    | 353500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 70699        |\n",
      "|    policy_loss        | 1.09         |\n",
      "|    reward             | -0.019516308 |\n",
      "|    std                | 69.1         |\n",
      "|    value_loss         | 0.0167       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 70800        |\n",
      "|    time_elapsed       | 1604         |\n",
      "|    total_timesteps    | 354000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 70799        |\n",
      "|    policy_loss        | 2.77         |\n",
      "|    reward             | -0.045803614 |\n",
      "|    std                | 69.6         |\n",
      "|    value_loss         | 0.116        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 70900       |\n",
      "|    time_elapsed       | 1606        |\n",
      "|    total_timesteps    | 354500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | -0.0401     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 70899       |\n",
      "|    policy_loss        | 3.68        |\n",
      "|    reward             | -0.02519187 |\n",
      "|    std                | 70.2        |\n",
      "|    value_loss         | 0.125       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 71000      |\n",
      "|    time_elapsed       | 1609       |\n",
      "|    total_timesteps    | 355000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.1      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 70999      |\n",
      "|    policy_loss        | 0.816      |\n",
      "|    reward             | 0.02142456 |\n",
      "|    std                | 70.5       |\n",
      "|    value_loss         | 0.00854    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 71100       |\n",
      "|    time_elapsed       | 1611        |\n",
      "|    total_timesteps    | 355500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 2.38e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 71099       |\n",
      "|    policy_loss        | 16.3        |\n",
      "|    reward             | -0.24279696 |\n",
      "|    std                | 70.4        |\n",
      "|    value_loss         | 2.69        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 71200       |\n",
      "|    time_elapsed       | 1613        |\n",
      "|    total_timesteps    | 356000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 71199       |\n",
      "|    policy_loss        | -1.25       |\n",
      "|    reward             | 0.058665343 |\n",
      "|    std                | 70.4        |\n",
      "|    value_loss         | 0.0231      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 71300        |\n",
      "|    time_elapsed       | 1616         |\n",
      "|    total_timesteps    | 356500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 71299        |\n",
      "|    policy_loss        | -0.345       |\n",
      "|    reward             | -0.035015184 |\n",
      "|    std                | 70.1         |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 71400      |\n",
      "|    time_elapsed       | 1618       |\n",
      "|    total_timesteps    | 357000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.1      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71399      |\n",
      "|    policy_loss        | 0.687      |\n",
      "|    reward             | 0.17133178 |\n",
      "|    std                | 70.5       |\n",
      "|    value_loss         | 0.00878    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 71500        |\n",
      "|    time_elapsed       | 1620         |\n",
      "|    total_timesteps    | 357500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 71499        |\n",
      "|    policy_loss        | 1.23         |\n",
      "|    reward             | 0.0016616455 |\n",
      "|    std                | 71.4         |\n",
      "|    value_loss         | 0.0138       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 71600        |\n",
      "|    time_elapsed       | 1622         |\n",
      "|    total_timesteps    | 358000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 71599        |\n",
      "|    policy_loss        | -8.72        |\n",
      "|    reward             | -0.030362854 |\n",
      "|    std                | 71.9         |\n",
      "|    value_loss         | 0.622        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 71700      |\n",
      "|    time_elapsed       | 1625       |\n",
      "|    total_timesteps    | 358500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.2      |\n",
      "|    explained_variance | -0.044     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 71699      |\n",
      "|    policy_loss        | 1.2        |\n",
      "|    reward             | -0.2951524 |\n",
      "|    std                | 73.3       |\n",
      "|    value_loss         | 0.0224     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 71800       |\n",
      "|    time_elapsed       | 1627        |\n",
      "|    total_timesteps    | 359000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 71799       |\n",
      "|    policy_loss        | 4           |\n",
      "|    reward             | -0.80098474 |\n",
      "|    std                | 73.6        |\n",
      "|    value_loss         | 0.138       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 220           |\n",
      "|    iterations         | 71900         |\n",
      "|    time_elapsed       | 1629          |\n",
      "|    total_timesteps    | 359500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 71899         |\n",
      "|    policy_loss        | 0.453         |\n",
      "|    reward             | -0.0056660916 |\n",
      "|    std                | 73.9          |\n",
      "|    value_loss         | 0.00573       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 72000       |\n",
      "|    time_elapsed       | 1632        |\n",
      "|    total_timesteps    | 360000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 71999       |\n",
      "|    policy_loss        | 3.64        |\n",
      "|    reward             | -0.07345385 |\n",
      "|    std                | 74.9        |\n",
      "|    value_loss         | 0.135       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 72100      |\n",
      "|    time_elapsed       | 1634       |\n",
      "|    total_timesteps    | 360500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72099      |\n",
      "|    policy_loss        | -1.33      |\n",
      "|    reward             | 0.05165304 |\n",
      "|    std                | 76.2       |\n",
      "|    value_loss         | 0.0205     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 72200       |\n",
      "|    time_elapsed       | 1636        |\n",
      "|    total_timesteps    | 361000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | -0.29       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72199       |\n",
      "|    policy_loss        | -0.304      |\n",
      "|    reward             | -0.06954583 |\n",
      "|    std                | 77.3        |\n",
      "|    value_loss         | 0.00258     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 72300       |\n",
      "|    time_elapsed       | 1638        |\n",
      "|    total_timesteps    | 361500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72299       |\n",
      "|    policy_loss        | -0.634      |\n",
      "|    reward             | -0.03898513 |\n",
      "|    std                | 77          |\n",
      "|    value_loss         | 0.00858     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 72400       |\n",
      "|    time_elapsed       | 1641        |\n",
      "|    total_timesteps    | 362000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.3       |\n",
      "|    explained_variance | 2.38e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72399       |\n",
      "|    policy_loss        | 4.55        |\n",
      "|    reward             | 0.032027453 |\n",
      "|    std                | 77.6        |\n",
      "|    value_loss         | 0.186       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 72500      |\n",
      "|    time_elapsed       | 1643       |\n",
      "|    total_timesteps    | 362500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.3      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72499      |\n",
      "|    policy_loss        | 3.34       |\n",
      "|    reward             | 0.23332636 |\n",
      "|    std                | 77.9       |\n",
      "|    value_loss         | 0.225      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 72600       |\n",
      "|    time_elapsed       | 1645        |\n",
      "|    total_timesteps    | 363000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72599       |\n",
      "|    policy_loss        | 1.07        |\n",
      "|    reward             | -0.03622302 |\n",
      "|    std                | 78.4        |\n",
      "|    value_loss         | 0.0255      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 72700        |\n",
      "|    time_elapsed       | 1647         |\n",
      "|    total_timesteps    | 363500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 72699        |\n",
      "|    policy_loss        | 3.88         |\n",
      "|    reward             | -0.011228926 |\n",
      "|    std                | 79.6         |\n",
      "|    value_loss         | 0.131        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 72800      |\n",
      "|    time_elapsed       | 1650       |\n",
      "|    total_timesteps    | 364000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.4      |\n",
      "|    explained_variance | -0.185     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 72799      |\n",
      "|    policy_loss        | -1.23      |\n",
      "|    reward             | 0.09112954 |\n",
      "|    std                | 80.5       |\n",
      "|    value_loss         | 0.0223     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 72900       |\n",
      "|    time_elapsed       | 1652        |\n",
      "|    total_timesteps    | 364500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.4       |\n",
      "|    explained_variance | 0.0215      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 72899       |\n",
      "|    policy_loss        | -14         |\n",
      "|    reward             | 0.027322024 |\n",
      "|    std                | 82          |\n",
      "|    value_loss         | 7.7         |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 220           |\n",
      "|    iterations         | 73000         |\n",
      "|    time_elapsed       | 1654          |\n",
      "|    total_timesteps    | 365000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 72999         |\n",
      "|    policy_loss        | 1.84          |\n",
      "|    reward             | -0.0039352295 |\n",
      "|    std                | 82.3          |\n",
      "|    value_loss         | 0.0468        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 73100        |\n",
      "|    time_elapsed       | 1657         |\n",
      "|    total_timesteps    | 365500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 73099        |\n",
      "|    policy_loss        | 0.044        |\n",
      "|    reward             | -0.050955724 |\n",
      "|    std                | 84.1         |\n",
      "|    value_loss         | 0.00459      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 73200       |\n",
      "|    time_elapsed       | 1659        |\n",
      "|    total_timesteps    | 366000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73199       |\n",
      "|    policy_loss        | -4.3        |\n",
      "|    reward             | -0.61038786 |\n",
      "|    std                | 84.9        |\n",
      "|    value_loss         | 0.179       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 73300        |\n",
      "|    time_elapsed       | 1662         |\n",
      "|    total_timesteps    | 366500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 73299        |\n",
      "|    policy_loss        | 0.935        |\n",
      "|    reward             | -0.049448878 |\n",
      "|    std                | 86.3         |\n",
      "|    value_loss         | 0.00859      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 73400       |\n",
      "|    time_elapsed       | 1664        |\n",
      "|    total_timesteps    | 367000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73399       |\n",
      "|    policy_loss        | -0.199      |\n",
      "|    reward             | 0.060958985 |\n",
      "|    std                | 86.3        |\n",
      "|    value_loss         | 0.00291     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 73500        |\n",
      "|    time_elapsed       | 1666         |\n",
      "|    total_timesteps    | 367500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 73499        |\n",
      "|    policy_loss        | -0.207       |\n",
      "|    reward             | -0.057225782 |\n",
      "|    std                | 87.5         |\n",
      "|    value_loss         | 0.00276      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 73600       |\n",
      "|    time_elapsed       | 1669        |\n",
      "|    total_timesteps    | 368000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73599       |\n",
      "|    policy_loss        | -4.1        |\n",
      "|    reward             | 0.056989845 |\n",
      "|    std                | 88.3        |\n",
      "|    value_loss         | 0.175       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 73700       |\n",
      "|    time_elapsed       | 1671        |\n",
      "|    total_timesteps    | 368500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73699       |\n",
      "|    policy_loss        | -0.104      |\n",
      "|    reward             | -0.11976595 |\n",
      "|    std                | 88.7        |\n",
      "|    value_loss         | 0.000345    |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 220      |\n",
      "|    iterations         | 73800    |\n",
      "|    time_elapsed       | 1673     |\n",
      "|    total_timesteps    | 369000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -11.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 73799    |\n",
      "|    policy_loss        | -1.68    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 89.2     |\n",
      "|    value_loss         | 0.0234   |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 220           |\n",
      "|    iterations         | 73900         |\n",
      "|    time_elapsed       | 1675          |\n",
      "|    total_timesteps    | 369500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 73899         |\n",
      "|    policy_loss        | 0.0254        |\n",
      "|    reward             | -0.0066490048 |\n",
      "|    std                | 90.3          |\n",
      "|    value_loss         | 0.00299       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 74000       |\n",
      "|    time_elapsed       | 1678        |\n",
      "|    total_timesteps    | 370000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | 2.38e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 73999       |\n",
      "|    policy_loss        | 3.52        |\n",
      "|    reward             | 0.027491357 |\n",
      "|    std                | 90.2        |\n",
      "|    value_loss         | 0.1         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 74100       |\n",
      "|    time_elapsed       | 1680        |\n",
      "|    total_timesteps    | 370500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74099       |\n",
      "|    policy_loss        | 2.28        |\n",
      "|    reward             | -0.13474077 |\n",
      "|    std                | 90.6        |\n",
      "|    value_loss         | 0.108       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 74200      |\n",
      "|    time_elapsed       | 1683       |\n",
      "|    total_timesteps    | 371000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.6      |\n",
      "|    explained_variance | -0.144     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 74199      |\n",
      "|    policy_loss        | 3.72       |\n",
      "|    reward             | -0.0520937 |\n",
      "|    std                | 91.6       |\n",
      "|    value_loss         | 0.18       |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 74300        |\n",
      "|    time_elapsed       | 1685         |\n",
      "|    total_timesteps    | 371500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74299        |\n",
      "|    policy_loss        | 6.09         |\n",
      "|    reward             | -0.002747213 |\n",
      "|    std                | 92.1         |\n",
      "|    value_loss         | 0.343        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 74400        |\n",
      "|    time_elapsed       | 1688         |\n",
      "|    total_timesteps    | 372000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74399        |\n",
      "|    policy_loss        | 0.0466       |\n",
      "|    reward             | -0.039075512 |\n",
      "|    std                | 92.7         |\n",
      "|    value_loss         | 0.00552      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 74500       |\n",
      "|    time_elapsed       | 1691        |\n",
      "|    total_timesteps    | 372500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | -0.0391     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74499       |\n",
      "|    policy_loss        | -0.733      |\n",
      "|    reward             | -0.02892798 |\n",
      "|    std                | 93          |\n",
      "|    value_loss         | 0.0504      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 74600       |\n",
      "|    time_elapsed       | 1693        |\n",
      "|    total_timesteps    | 373000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74599       |\n",
      "|    policy_loss        | 7.5         |\n",
      "|    reward             | -0.18846343 |\n",
      "|    std                | 93.7        |\n",
      "|    value_loss         | 1.08        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 74700        |\n",
      "|    time_elapsed       | 1696         |\n",
      "|    total_timesteps    | 373500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74699        |\n",
      "|    policy_loss        | -1.08        |\n",
      "|    reward             | -0.002920112 |\n",
      "|    std                | 93.7         |\n",
      "|    value_loss         | 0.0101       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 74800       |\n",
      "|    time_elapsed       | 1698        |\n",
      "|    total_timesteps    | 374000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74799       |\n",
      "|    policy_loss        | -3.44       |\n",
      "|    reward             | -0.20744577 |\n",
      "|    std                | 94.8        |\n",
      "|    value_loss         | 0.0943      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 74900       |\n",
      "|    time_elapsed       | 1700        |\n",
      "|    total_timesteps    | 374500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.7       |\n",
      "|    explained_variance | -0.0194     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 74899       |\n",
      "|    policy_loss        | 0.0702      |\n",
      "|    reward             | 0.026948437 |\n",
      "|    std                | 95.7        |\n",
      "|    value_loss         | 0.000442    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 75000        |\n",
      "|    time_elapsed       | 1703         |\n",
      "|    total_timesteps    | 375000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 74999        |\n",
      "|    policy_loss        | 0.0146       |\n",
      "|    reward             | -0.010028425 |\n",
      "|    std                | 97.1         |\n",
      "|    value_loss         | 0.000731     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 75100        |\n",
      "|    time_elapsed       | 1705         |\n",
      "|    total_timesteps    | 375500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 75099        |\n",
      "|    policy_loss        | -0.261       |\n",
      "|    reward             | -0.007884432 |\n",
      "|    std                | 98.2         |\n",
      "|    value_loss         | 0.00594      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 220        |\n",
      "|    iterations         | 75200      |\n",
      "|    time_elapsed       | 1708       |\n",
      "|    total_timesteps    | 376000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -11.8      |\n",
      "|    explained_variance | -0.424     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 75199      |\n",
      "|    policy_loss        | -0.627     |\n",
      "|    reward             | 0.25839013 |\n",
      "|    std                | 99.9       |\n",
      "|    value_loss         | 0.00631    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 75300       |\n",
      "|    time_elapsed       | 1710        |\n",
      "|    total_timesteps    | 376500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | 0.0925      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75299       |\n",
      "|    policy_loss        | -0.219      |\n",
      "|    reward             | 0.035928473 |\n",
      "|    std                | 101         |\n",
      "|    value_loss         | 0.00093     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 220         |\n",
      "|    iterations         | 75400       |\n",
      "|    time_elapsed       | 1713        |\n",
      "|    total_timesteps    | 377000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.8       |\n",
      "|    explained_variance | -0.145      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75399       |\n",
      "|    policy_loss        | -0.54       |\n",
      "|    reward             | 0.059031554 |\n",
      "|    std                | 102         |\n",
      "|    value_loss         | 0.00311     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 220       |\n",
      "|    iterations         | 75500     |\n",
      "|    time_elapsed       | 1715      |\n",
      "|    total_timesteps    | 377500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75499     |\n",
      "|    policy_loss        | 1.01      |\n",
      "|    reward             | 0.0755875 |\n",
      "|    std                | 102       |\n",
      "|    value_loss         | 0.011     |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 220          |\n",
      "|    iterations         | 75600        |\n",
      "|    time_elapsed       | 1718         |\n",
      "|    total_timesteps    | 378000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 75599        |\n",
      "|    policy_loss        | 1.19         |\n",
      "|    reward             | -0.019859266 |\n",
      "|    std                | 103          |\n",
      "|    value_loss         | 0.0119       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 75700        |\n",
      "|    time_elapsed       | 1720         |\n",
      "|    total_timesteps    | 378500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -11.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 75699        |\n",
      "|    policy_loss        | 1.33         |\n",
      "|    reward             | -0.009490429 |\n",
      "|    std                | 104          |\n",
      "|    value_loss         | 0.0142       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 75800       |\n",
      "|    time_elapsed       | 1723        |\n",
      "|    total_timesteps    | 379000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -11.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 75799       |\n",
      "|    policy_loss        | 3.21        |\n",
      "|    reward             | -0.07473766 |\n",
      "|    std                | 105         |\n",
      "|    value_loss         | 0.12        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 75900     |\n",
      "|    time_elapsed       | 1725      |\n",
      "|    total_timesteps    | 379500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 75899     |\n",
      "|    policy_loss        | 1.76      |\n",
      "|    reward             | 0.0914228 |\n",
      "|    std                | 105       |\n",
      "|    value_loss         | 0.0262    |\n",
      "-------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 76000         |\n",
      "|    time_elapsed       | 1728          |\n",
      "|    total_timesteps    | 380000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -11.9         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 75999         |\n",
      "|    policy_loss        | -1            |\n",
      "|    reward             | -0.0048071044 |\n",
      "|    std                | 106           |\n",
      "|    value_loss         | 0.0113        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 76100         |\n",
      "|    time_elapsed       | 1730          |\n",
      "|    total_timesteps    | 380500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12           |\n",
      "|    explained_variance | -0.0125       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 76099         |\n",
      "|    policy_loss        | -16.1         |\n",
      "|    reward             | 0.00032683107 |\n",
      "|    std                | 108           |\n",
      "|    value_loss         | 6.89          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 76200       |\n",
      "|    time_elapsed       | 1733        |\n",
      "|    total_timesteps    | 381000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12         |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76199       |\n",
      "|    policy_loss        | 4.99        |\n",
      "|    reward             | -0.06147446 |\n",
      "|    std                | 109         |\n",
      "|    value_loss         | 0.437       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 76300         |\n",
      "|    time_elapsed       | 1735          |\n",
      "|    total_timesteps    | 381500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12           |\n",
      "|    explained_variance | -0.511        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 76299         |\n",
      "|    policy_loss        | -4.47         |\n",
      "|    reward             | -0.0093403235 |\n",
      "|    std                | 112           |\n",
      "|    value_loss         | 0.163         |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 76400     |\n",
      "|    time_elapsed       | 1738      |\n",
      "|    total_timesteps    | 382000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 76399     |\n",
      "|    policy_loss        | -6.98     |\n",
      "|    reward             | -1.125903 |\n",
      "|    std                | 113       |\n",
      "|    value_loss         | 0.441     |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 76500       |\n",
      "|    time_elapsed       | 1740        |\n",
      "|    total_timesteps    | 382500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76499       |\n",
      "|    policy_loss        | 0.38        |\n",
      "|    reward             | 0.020351477 |\n",
      "|    std                | 114         |\n",
      "|    value_loss         | 0.00244     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 76600       |\n",
      "|    time_elapsed       | 1743        |\n",
      "|    total_timesteps    | 383000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76599       |\n",
      "|    policy_loss        | 0.0354      |\n",
      "|    reward             | 0.010629852 |\n",
      "|    std                | 115         |\n",
      "|    value_loss         | 0.00128     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 76700       |\n",
      "|    time_elapsed       | 1745        |\n",
      "|    total_timesteps    | 383500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 76699       |\n",
      "|    policy_loss        | 0.442       |\n",
      "|    reward             | -0.06168302 |\n",
      "|    std                | 115         |\n",
      "|    value_loss         | 0.00412     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 76800      |\n",
      "|    time_elapsed       | 1748       |\n",
      "|    total_timesteps    | 384000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 76799      |\n",
      "|    policy_loss        | -1.82      |\n",
      "|    reward             | 0.07087621 |\n",
      "|    std                | 116        |\n",
      "|    value_loss         | 0.0294     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 76900    |\n",
      "|    time_elapsed       | 1750     |\n",
      "|    total_timesteps    | 384500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.1    |\n",
      "|    explained_variance | -2.82    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 76899    |\n",
      "|    policy_loss        | -0.381   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 118      |\n",
      "|    value_loss         | 0.0044   |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 77000        |\n",
      "|    time_elapsed       | 1753         |\n",
      "|    total_timesteps    | 385000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 76999        |\n",
      "|    policy_loss        | -1.11        |\n",
      "|    reward             | 0.0100736935 |\n",
      "|    std                | 118          |\n",
      "|    value_loss         | 0.00969      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 77100        |\n",
      "|    time_elapsed       | 1755         |\n",
      "|    total_timesteps    | 385500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 77099        |\n",
      "|    policy_loss        | 0.671        |\n",
      "|    reward             | -0.024726171 |\n",
      "|    std                | 120          |\n",
      "|    value_loss         | 0.00328      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 77200      |\n",
      "|    time_elapsed       | 1757       |\n",
      "|    total_timesteps    | 386000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77199      |\n",
      "|    policy_loss        | 0.969      |\n",
      "|    reward             | 0.08240322 |\n",
      "|    std                | 122        |\n",
      "|    value_loss         | 0.00715    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 77300       |\n",
      "|    time_elapsed       | 1760        |\n",
      "|    total_timesteps    | 386500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77299       |\n",
      "|    policy_loss        | 4.98        |\n",
      "|    reward             | -0.07597998 |\n",
      "|    std                | 123         |\n",
      "|    value_loss         | 0.173       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 77400      |\n",
      "|    time_elapsed       | 1762       |\n",
      "|    total_timesteps    | 387000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77399      |\n",
      "|    policy_loss        | 4.58       |\n",
      "|    reward             | 0.07557902 |\n",
      "|    std                | 124        |\n",
      "|    value_loss         | 0.193      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 77500       |\n",
      "|    time_elapsed       | 1765        |\n",
      "|    total_timesteps    | 387500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.2       |\n",
      "|    explained_variance | -0.00774    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77499       |\n",
      "|    policy_loss        | 0.963       |\n",
      "|    reward             | 0.022613395 |\n",
      "|    std                | 124         |\n",
      "|    value_loss         | 0.00803     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 77600       |\n",
      "|    time_elapsed       | 1767        |\n",
      "|    total_timesteps    | 388000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77599       |\n",
      "|    policy_loss        | 1.18        |\n",
      "|    reward             | 0.010674814 |\n",
      "|    std                | 127         |\n",
      "|    value_loss         | 0.0104      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 77700        |\n",
      "|    time_elapsed       | 1770         |\n",
      "|    total_timesteps    | 388500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | -0.0121      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 77699        |\n",
      "|    policy_loss        | -21.1        |\n",
      "|    reward             | -0.011827624 |\n",
      "|    std                | 128          |\n",
      "|    value_loss         | 6.73         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 77800        |\n",
      "|    time_elapsed       | 1772         |\n",
      "|    total_timesteps    | 389000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 77799        |\n",
      "|    policy_loss        | 5.12         |\n",
      "|    reward             | -0.058768805 |\n",
      "|    std                | 130          |\n",
      "|    value_loss         | 0.249        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 77900       |\n",
      "|    time_elapsed       | 1775        |\n",
      "|    total_timesteps    | 389500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | -2.38e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 77899       |\n",
      "|    policy_loss        | -0.604      |\n",
      "|    reward             | 0.012709594 |\n",
      "|    std                | 131         |\n",
      "|    value_loss         | 0.00382     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 78000      |\n",
      "|    time_elapsed       | 1777       |\n",
      "|    total_timesteps    | 390000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 77999      |\n",
      "|    policy_loss        | -1.79      |\n",
      "|    reward             | 0.23876311 |\n",
      "|    std                | 132        |\n",
      "|    value_loss         | 0.0531     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 78100        |\n",
      "|    time_elapsed       | 1780         |\n",
      "|    total_timesteps    | 390500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.4        |\n",
      "|    explained_variance | -0.315       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 78099        |\n",
      "|    policy_loss        | 0.447        |\n",
      "|    reward             | -0.076049805 |\n",
      "|    std                | 133          |\n",
      "|    value_loss         | 0.0109       |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 78200     |\n",
      "|    time_elapsed       | 1782      |\n",
      "|    total_timesteps    | 391000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 78199     |\n",
      "|    policy_loss        | 2.24      |\n",
      "|    reward             | 1.0304567 |\n",
      "|    std                | 132       |\n",
      "|    value_loss         | 0.0673    |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 78300       |\n",
      "|    time_elapsed       | 1785        |\n",
      "|    total_timesteps    | 391500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78299       |\n",
      "|    policy_loss        | 0.374       |\n",
      "|    reward             | 0.043910157 |\n",
      "|    std                | 132         |\n",
      "|    value_loss         | 0.00307     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 78400      |\n",
      "|    time_elapsed       | 1787       |\n",
      "|    total_timesteps    | 392000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78399      |\n",
      "|    policy_loss        | -0.579     |\n",
      "|    reward             | 0.10259956 |\n",
      "|    std                | 133        |\n",
      "|    value_loss         | 0.0152     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 78500      |\n",
      "|    time_elapsed       | 1790       |\n",
      "|    total_timesteps    | 392500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.4      |\n",
      "|    explained_variance | -0.209     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78499      |\n",
      "|    policy_loss        | -0.238     |\n",
      "|    reward             | 0.20684834 |\n",
      "|    std                | 135        |\n",
      "|    value_loss         | 0.00109    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 78600       |\n",
      "|    time_elapsed       | 1792        |\n",
      "|    total_timesteps    | 393000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78599       |\n",
      "|    policy_loss        | -1.11       |\n",
      "|    reward             | -0.18489389 |\n",
      "|    std                | 137         |\n",
      "|    value_loss         | 0.0109      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 78700       |\n",
      "|    time_elapsed       | 1795        |\n",
      "|    total_timesteps    | 393500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | -0.058      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78699       |\n",
      "|    policy_loss        | -1.49       |\n",
      "|    reward             | 0.038511343 |\n",
      "|    std                | 138         |\n",
      "|    value_loss         | 0.019       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 78800       |\n",
      "|    time_elapsed       | 1797        |\n",
      "|    total_timesteps    | 394000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 78799       |\n",
      "|    policy_loss        | 0.64        |\n",
      "|    reward             | -0.10070712 |\n",
      "|    std                | 138         |\n",
      "|    value_loss         | 0.00378     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 78900      |\n",
      "|    time_elapsed       | 1800       |\n",
      "|    total_timesteps    | 394500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78899      |\n",
      "|    policy_loss        | 3.9        |\n",
      "|    reward             | 0.15117419 |\n",
      "|    std                | 139        |\n",
      "|    value_loss         | 0.107      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 79000      |\n",
      "|    time_elapsed       | 1802       |\n",
      "|    total_timesteps    | 395000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | -0.227     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 78999      |\n",
      "|    policy_loss        | 3.86       |\n",
      "|    reward             | 0.08464443 |\n",
      "|    std                | 140        |\n",
      "|    value_loss         | 0.0893     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 79100      |\n",
      "|    time_elapsed       | 1805       |\n",
      "|    total_timesteps    | 395500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79099      |\n",
      "|    policy_loss        | 1.33       |\n",
      "|    reward             | 0.05993457 |\n",
      "|    std                | 142        |\n",
      "|    value_loss         | 0.0148     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 79200       |\n",
      "|    time_elapsed       | 1807        |\n",
      "|    total_timesteps    | 396000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79199       |\n",
      "|    policy_loss        | -0.557      |\n",
      "|    reward             | 0.026525062 |\n",
      "|    std                | 144         |\n",
      "|    value_loss         | 0.00394     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 79300       |\n",
      "|    time_elapsed       | 1810        |\n",
      "|    total_timesteps    | 396500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.5       |\n",
      "|    explained_variance | 0.00985     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79299       |\n",
      "|    policy_loss        | -26.5       |\n",
      "|    reward             | 0.027911328 |\n",
      "|    std                | 146         |\n",
      "|    value_loss         | 8.53        |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 79400        |\n",
      "|    time_elapsed       | 1812         |\n",
      "|    total_timesteps    | 397000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.6        |\n",
      "|    explained_variance | -0.0348      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 79399        |\n",
      "|    policy_loss        | 8.52         |\n",
      "|    reward             | -0.014644043 |\n",
      "|    std                | 147          |\n",
      "|    value_loss         | 0.495        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 79500       |\n",
      "|    time_elapsed       | 1814        |\n",
      "|    total_timesteps    | 397500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79499       |\n",
      "|    policy_loss        | -0.595      |\n",
      "|    reward             | 0.098627634 |\n",
      "|    std                | 150         |\n",
      "|    value_loss         | 0.00366     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 79600      |\n",
      "|    time_elapsed       | 1817       |\n",
      "|    total_timesteps    | 398000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | -0.00758   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79599      |\n",
      "|    policy_loss        | 0.403      |\n",
      "|    reward             | -0.3831731 |\n",
      "|    std                | 153        |\n",
      "|    value_loss         | 0.0332     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 79700       |\n",
      "|    time_elapsed       | 1819        |\n",
      "|    total_timesteps    | 398500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.6       |\n",
      "|    explained_variance | -0.256      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79699       |\n",
      "|    policy_loss        | -0.758      |\n",
      "|    reward             | 0.025179176 |\n",
      "|    std                | 154         |\n",
      "|    value_loss         | 0.0061      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 79800      |\n",
      "|    time_elapsed       | 1821       |\n",
      "|    total_timesteps    | 399000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 79799      |\n",
      "|    policy_loss        | -0.967     |\n",
      "|    reward             | 0.06132715 |\n",
      "|    std                | 154        |\n",
      "|    value_loss         | 0.00686    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 79900       |\n",
      "|    time_elapsed       | 1823        |\n",
      "|    total_timesteps    | 399500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 79899       |\n",
      "|    policy_loss        | -2.06       |\n",
      "|    reward             | 0.076810524 |\n",
      "|    std                | 156         |\n",
      "|    value_loss         | 0.0288      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 80000     |\n",
      "|    time_elapsed       | 1826      |\n",
      "|    total_timesteps    | 400000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.7     |\n",
      "|    explained_variance | -0.0147   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 79999     |\n",
      "|    policy_loss        | -2.79     |\n",
      "|    reward             | 0.5317624 |\n",
      "|    std                | 158       |\n",
      "|    value_loss         | 0.0823    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 80100      |\n",
      "|    time_elapsed       | 1828       |\n",
      "|    total_timesteps    | 400500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | 0.0669     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80099      |\n",
      "|    policy_loss        | -1.11      |\n",
      "|    reward             | -1.1211741 |\n",
      "|    std                | 158        |\n",
      "|    value_loss         | 0.0212     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 80200        |\n",
      "|    time_elapsed       | 1830         |\n",
      "|    total_timesteps    | 401000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 80199        |\n",
      "|    policy_loss        | -0.0111      |\n",
      "|    reward             | 0.0039554075 |\n",
      "|    std                | 160          |\n",
      "|    value_loss         | 0.0011       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 80300         |\n",
      "|    time_elapsed       | 1832          |\n",
      "|    total_timesteps    | 401500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 80299         |\n",
      "|    policy_loss        | 1.3           |\n",
      "|    reward             | -0.0064187697 |\n",
      "|    std                | 162           |\n",
      "|    value_loss         | 0.0141        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 80400      |\n",
      "|    time_elapsed       | 1834       |\n",
      "|    total_timesteps    | 402000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.7      |\n",
      "|    explained_variance | -0.311     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80399      |\n",
      "|    policy_loss        | 0.658      |\n",
      "|    reward             | 0.00940918 |\n",
      "|    std                | 163        |\n",
      "|    value_loss         | 0.00414    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 80500       |\n",
      "|    time_elapsed       | 1837        |\n",
      "|    total_timesteps    | 402500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.7       |\n",
      "|    explained_variance | 0.238       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 80499       |\n",
      "|    policy_loss        | 1.46        |\n",
      "|    reward             | 0.099963844 |\n",
      "|    std                | 164         |\n",
      "|    value_loss         | 0.0175      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 80600         |\n",
      "|    time_elapsed       | 1839          |\n",
      "|    total_timesteps    | 403000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -12.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 80599         |\n",
      "|    policy_loss        | -2.15         |\n",
      "|    reward             | -0.0030659507 |\n",
      "|    std                | 166           |\n",
      "|    value_loss         | 0.0457        |\n",
      "-----------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 80700     |\n",
      "|    time_elapsed       | 1841      |\n",
      "|    total_timesteps    | 403500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 80699     |\n",
      "|    policy_loss        | 1.72      |\n",
      "|    reward             | 0.4677344 |\n",
      "|    std                | 169       |\n",
      "|    value_loss         | 0.0241    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 80800        |\n",
      "|    time_elapsed       | 1843         |\n",
      "|    total_timesteps    | 404000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 80799        |\n",
      "|    policy_loss        | 1.73         |\n",
      "|    reward             | -0.026004797 |\n",
      "|    std                | 169          |\n",
      "|    value_loss         | 0.0211       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 80900       |\n",
      "|    time_elapsed       | 1845        |\n",
      "|    total_timesteps    | 404500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 80899       |\n",
      "|    policy_loss        | -6.77       |\n",
      "|    reward             | 0.005983667 |\n",
      "|    std                | 169         |\n",
      "|    value_loss         | 0.286       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 81000      |\n",
      "|    time_elapsed       | 1848       |\n",
      "|    total_timesteps    | 405000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.8      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 80999      |\n",
      "|    policy_loss        | 4.61       |\n",
      "|    reward             | 0.06987037 |\n",
      "|    std                | 172        |\n",
      "|    value_loss         | 0.145      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 81100      |\n",
      "|    time_elapsed       | 1850       |\n",
      "|    total_timesteps    | 405500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -12.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81099      |\n",
      "|    policy_loss        | 0.442      |\n",
      "|    reward             | 0.08498877 |\n",
      "|    std                | 174        |\n",
      "|    value_loss         | 0.00247    |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 219            |\n",
      "|    iterations         | 81200          |\n",
      "|    time_elapsed       | 1852           |\n",
      "|    total_timesteps    | 406000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -12.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 81199          |\n",
      "|    policy_loss        | -1.89          |\n",
      "|    reward             | -0.00022864988 |\n",
      "|    std                | 174            |\n",
      "|    value_loss         | 0.0646         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 81300        |\n",
      "|    time_elapsed       | 1854         |\n",
      "|    total_timesteps    | 406500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | 0.17         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 81299        |\n",
      "|    policy_loss        | -1.52        |\n",
      "|    reward             | -0.001848913 |\n",
      "|    std                | 175          |\n",
      "|    value_loss         | 0.0164       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 81400        |\n",
      "|    time_elapsed       | 1856         |\n",
      "|    total_timesteps    | 407000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 81399        |\n",
      "|    policy_loss        | -0.266       |\n",
      "|    reward             | -0.004476318 |\n",
      "|    std                | 177          |\n",
      "|    value_loss         | 0.001        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 81500       |\n",
      "|    time_elapsed       | 1859        |\n",
      "|    total_timesteps    | 407500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81499       |\n",
      "|    policy_loss        | -0.475      |\n",
      "|    reward             | 0.010172595 |\n",
      "|    std                | 179         |\n",
      "|    value_loss         | 0.00369     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 81600       |\n",
      "|    time_elapsed       | 1861        |\n",
      "|    total_timesteps    | 408000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -12.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 81599       |\n",
      "|    policy_loss        | -0.638      |\n",
      "|    reward             | -0.09789546 |\n",
      "|    std                | 179         |\n",
      "|    value_loss         | 0.0108      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 81700        |\n",
      "|    time_elapsed       | 1863         |\n",
      "|    total_timesteps    | 408500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -0.0319      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 81699        |\n",
      "|    policy_loss        | 4.74         |\n",
      "|    reward             | -0.064554855 |\n",
      "|    std                | 180          |\n",
      "|    value_loss         | 0.15         |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 81800        |\n",
      "|    time_elapsed       | 1865         |\n",
      "|    total_timesteps    | 409000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -12.9        |\n",
      "|    explained_variance | -0.366       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 81799        |\n",
      "|    policy_loss        | -0.821       |\n",
      "|    reward             | -0.066993326 |\n",
      "|    std                | 181          |\n",
      "|    value_loss         | 0.00629      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 81900        |\n",
      "|    time_elapsed       | 1867         |\n",
      "|    total_timesteps    | 409500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13          |\n",
      "|    explained_variance | -0.855       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 81899        |\n",
      "|    policy_loss        | -0.189       |\n",
      "|    reward             | -0.021834766 |\n",
      "|    std                | 184          |\n",
      "|    value_loss         | 0.0012       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 82000      |\n",
      "|    time_elapsed       | 1870       |\n",
      "|    total_timesteps    | 410000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13        |\n",
      "|    explained_variance | -0.128     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 81999      |\n",
      "|    policy_loss        | -0.699     |\n",
      "|    reward             | 0.27539515 |\n",
      "|    std                | 187        |\n",
      "|    value_loss         | 0.00386    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 82100      |\n",
      "|    time_elapsed       | 1872       |\n",
      "|    total_timesteps    | 410500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13        |\n",
      "|    explained_variance | 0.000805   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 82099      |\n",
      "|    policy_loss        | 2.72       |\n",
      "|    reward             | 0.13483772 |\n",
      "|    std                | 189        |\n",
      "|    value_loss         | 0.0628     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 82200       |\n",
      "|    time_elapsed       | 1874        |\n",
      "|    total_timesteps    | 411000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13         |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82199       |\n",
      "|    policy_loss        | -1.75       |\n",
      "|    reward             | 0.072379924 |\n",
      "|    std                | 190         |\n",
      "|    value_loss         | 0.0329      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 82300      |\n",
      "|    time_elapsed       | 1876       |\n",
      "|    total_timesteps    | 411500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13        |\n",
      "|    explained_variance | 0.00185    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 82299      |\n",
      "|    policy_loss        | 2.71       |\n",
      "|    reward             | 0.11733238 |\n",
      "|    std                | 192        |\n",
      "|    value_loss         | 0.054      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 82400       |\n",
      "|    time_elapsed       | 1878        |\n",
      "|    total_timesteps    | 412000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0.259       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82399       |\n",
      "|    policy_loss        | 0.573       |\n",
      "|    reward             | 0.039233595 |\n",
      "|    std                | 194         |\n",
      "|    value_loss         | 0.00399     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 82500       |\n",
      "|    time_elapsed       | 1881        |\n",
      "|    total_timesteps    | 412500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.1       |\n",
      "|    explained_variance | 0.00417     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82499       |\n",
      "|    policy_loss        | -1.6        |\n",
      "|    reward             | 0.016763536 |\n",
      "|    std                | 197         |\n",
      "|    value_loss         | 0.0384      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 82600         |\n",
      "|    time_elapsed       | 1883          |\n",
      "|    total_timesteps    | 413000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.1         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 82599         |\n",
      "|    policy_loss        | 0.414         |\n",
      "|    reward             | -0.0066377814 |\n",
      "|    std                | 202           |\n",
      "|    value_loss         | 0.00189       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 82700        |\n",
      "|    time_elapsed       | 1885         |\n",
      "|    total_timesteps    | 413500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 82699        |\n",
      "|    policy_loss        | 0.686        |\n",
      "|    reward             | 0.0018229694 |\n",
      "|    std                | 205          |\n",
      "|    value_loss         | 0.00393      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 82800       |\n",
      "|    time_elapsed       | 1887        |\n",
      "|    total_timesteps    | 414000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0.12        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82799       |\n",
      "|    policy_loss        | -6.09       |\n",
      "|    reward             | -0.25741047 |\n",
      "|    std                | 208         |\n",
      "|    value_loss         | 0.245       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 82900       |\n",
      "|    time_elapsed       | 1889        |\n",
      "|    total_timesteps    | 414500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82899       |\n",
      "|    policy_loss        | -0.471      |\n",
      "|    reward             | -0.19680572 |\n",
      "|    std                | 210         |\n",
      "|    value_loss         | 0.167       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 83000       |\n",
      "|    time_elapsed       | 1892        |\n",
      "|    total_timesteps    | 415000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 82999       |\n",
      "|    policy_loss        | -0.217      |\n",
      "|    reward             | -0.06154713 |\n",
      "|    std                | 211         |\n",
      "|    value_loss         | 0.0138      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 83100       |\n",
      "|    time_elapsed       | 1894        |\n",
      "|    total_timesteps    | 415500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 83099       |\n",
      "|    policy_loss        | -1.2        |\n",
      "|    reward             | -0.06465065 |\n",
      "|    std                | 213         |\n",
      "|    value_loss         | 0.0118      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 83200      |\n",
      "|    time_elapsed       | 1896       |\n",
      "|    total_timesteps    | 416000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 83199      |\n",
      "|    policy_loss        | 3.54       |\n",
      "|    reward             | -0.2718354 |\n",
      "|    std                | 215        |\n",
      "|    value_loss         | 0.127      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 83300       |\n",
      "|    time_elapsed       | 1898        |\n",
      "|    total_timesteps    | 416500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 83299       |\n",
      "|    policy_loss        | -0.42       |\n",
      "|    reward             | 0.018426256 |\n",
      "|    std                | 217         |\n",
      "|    value_loss         | 0.0017      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 83400        |\n",
      "|    time_elapsed       | 1901         |\n",
      "|    total_timesteps    | 417000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 83399        |\n",
      "|    policy_loss        | -0.655       |\n",
      "|    reward             | -0.030561768 |\n",
      "|    std                | 220          |\n",
      "|    value_loss         | 0.00392      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 219      |\n",
      "|    iterations         | 83500    |\n",
      "|    time_elapsed       | 1903     |\n",
      "|    total_timesteps    | 417500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.3    |\n",
      "|    explained_variance | -0.0155  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 83499    |\n",
      "|    policy_loss        | 0.569    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 223      |\n",
      "|    value_loss         | 0.00271  |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 83600       |\n",
      "|    time_elapsed       | 1905        |\n",
      "|    total_timesteps    | 418000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 83599       |\n",
      "|    policy_loss        | -1.65       |\n",
      "|    reward             | 0.020606793 |\n",
      "|    std                | 225         |\n",
      "|    value_loss         | 0.0243      |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 219       |\n",
      "|    iterations         | 83700     |\n",
      "|    time_elapsed       | 1907      |\n",
      "|    total_timesteps    | 418500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.4     |\n",
      "|    explained_variance | 0.0234    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 83699     |\n",
      "|    policy_loss        | 1.47      |\n",
      "|    reward             | 0.1827632 |\n",
      "|    std                | 228       |\n",
      "|    value_loss         | 0.0192    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 83800        |\n",
      "|    time_elapsed       | 1910         |\n",
      "|    total_timesteps    | 419000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -0.0451      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 83799        |\n",
      "|    policy_loss        | -0.939       |\n",
      "|    reward             | -0.080150194 |\n",
      "|    std                | 229          |\n",
      "|    value_loss         | 0.00714      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 83900         |\n",
      "|    time_elapsed       | 1912          |\n",
      "|    total_timesteps    | 419500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.4         |\n",
      "|    explained_variance | -0.523        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 83899         |\n",
      "|    policy_loss        | -0.161        |\n",
      "|    reward             | -0.0022304016 |\n",
      "|    std                | 231           |\n",
      "|    value_loss         | 0.00335       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 84000       |\n",
      "|    time_elapsed       | 1914        |\n",
      "|    total_timesteps    | 420000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 83999       |\n",
      "|    policy_loss        | 2.36        |\n",
      "|    reward             | -0.16706476 |\n",
      "|    std                | 233         |\n",
      "|    value_loss         | 0.0341      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 84100       |\n",
      "|    time_elapsed       | 1916        |\n",
      "|    total_timesteps    | 420500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84099       |\n",
      "|    policy_loss        | -4.28       |\n",
      "|    reward             | 0.049682423 |\n",
      "|    std                | 234         |\n",
      "|    value_loss         | 0.277       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 84200      |\n",
      "|    time_elapsed       | 1918       |\n",
      "|    total_timesteps    | 421000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.4      |\n",
      "|    explained_variance | 0.0604     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 84199      |\n",
      "|    policy_loss        | -1.17      |\n",
      "|    reward             | 0.08594796 |\n",
      "|    std                | 235        |\n",
      "|    value_loss         | 0.00834    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 84300        |\n",
      "|    time_elapsed       | 1921         |\n",
      "|    total_timesteps    | 421500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.4        |\n",
      "|    explained_variance | -6.05        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 84299        |\n",
      "|    policy_loss        | 1.15         |\n",
      "|    reward             | -0.008266085 |\n",
      "|    std                | 235          |\n",
      "|    value_loss         | 0.0084       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 84400       |\n",
      "|    time_elapsed       | 1923        |\n",
      "|    total_timesteps    | 422000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0.0548      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84399       |\n",
      "|    policy_loss        | -16.4       |\n",
      "|    reward             | -0.36505443 |\n",
      "|    std                | 236         |\n",
      "|    value_loss         | 1.4         |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 84500       |\n",
      "|    time_elapsed       | 1925        |\n",
      "|    total_timesteps    | 422500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.4       |\n",
      "|    explained_variance | 0.0428      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84499       |\n",
      "|    policy_loss        | 1.73        |\n",
      "|    reward             | 0.043992996 |\n",
      "|    std                | 236         |\n",
      "|    value_loss         | 0.0658      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 84600       |\n",
      "|    time_elapsed       | 1927        |\n",
      "|    total_timesteps    | 423000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | -0.656      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84599       |\n",
      "|    policy_loss        | -0.303      |\n",
      "|    reward             | -0.01110911 |\n",
      "|    std                | 239         |\n",
      "|    value_loss         | 0.00173     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 84700       |\n",
      "|    time_elapsed       | 1929        |\n",
      "|    total_timesteps    | 423500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 0.045       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84699       |\n",
      "|    policy_loss        | -0.0951     |\n",
      "|    reward             | -0.04441517 |\n",
      "|    std                | 241         |\n",
      "|    value_loss         | 0.000272    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 84800       |\n",
      "|    time_elapsed       | 1932        |\n",
      "|    total_timesteps    | 424000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.5       |\n",
      "|    explained_variance | 0.0512      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84799       |\n",
      "|    policy_loss        | 0.782       |\n",
      "|    reward             | -0.04435703 |\n",
      "|    std                | 244         |\n",
      "|    value_loss         | 0.00638     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 84900        |\n",
      "|    time_elapsed       | 1934         |\n",
      "|    total_timesteps    | 424500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.5        |\n",
      "|    explained_variance | 0.0233       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 84899        |\n",
      "|    policy_loss        | -0.0635      |\n",
      "|    reward             | -0.003952049 |\n",
      "|    std                | 247          |\n",
      "|    value_loss         | 0.000798     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 85000       |\n",
      "|    time_elapsed       | 1936        |\n",
      "|    total_timesteps    | 425000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 84999       |\n",
      "|    policy_loss        | -0.745      |\n",
      "|    reward             | -0.06473487 |\n",
      "|    std                | 251         |\n",
      "|    value_loss         | 0.0043      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 85100      |\n",
      "|    time_elapsed       | 1939       |\n",
      "|    total_timesteps    | 425500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85099      |\n",
      "|    policy_loss        | -0.961     |\n",
      "|    reward             | 0.12424934 |\n",
      "|    std                | 253        |\n",
      "|    value_loss         | 0.0109     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 85200      |\n",
      "|    time_elapsed       | 1941       |\n",
      "|    total_timesteps    | 426000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 0.213      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85199      |\n",
      "|    policy_loss        | -0.0902    |\n",
      "|    reward             | 0.08519125 |\n",
      "|    std                | 255        |\n",
      "|    value_loss         | 0.000842   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 85300      |\n",
      "|    time_elapsed       | 1944       |\n",
      "|    total_timesteps    | 426500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85299      |\n",
      "|    policy_loss        | -2.8       |\n",
      "|    reward             | 0.33188334 |\n",
      "|    std                | 256        |\n",
      "|    value_loss         | 0.0476     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 85400       |\n",
      "|    time_elapsed       | 1946        |\n",
      "|    total_timesteps    | 427000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 85399       |\n",
      "|    policy_loss        | -1.07       |\n",
      "|    reward             | 0.022084897 |\n",
      "|    std                | 259         |\n",
      "|    value_loss         | 0.0134      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 85500      |\n",
      "|    time_elapsed       | 1949       |\n",
      "|    total_timesteps    | 427500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.6      |\n",
      "|    explained_variance | 0.0841     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85499      |\n",
      "|    policy_loss        | 0.223      |\n",
      "|    reward             | 0.03184204 |\n",
      "|    std                | 262        |\n",
      "|    value_loss         | 0.00192    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 85600       |\n",
      "|    time_elapsed       | 1951        |\n",
      "|    total_timesteps    | 428000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 85599       |\n",
      "|    policy_loss        | 7.85        |\n",
      "|    reward             | -0.08410949 |\n",
      "|    std                | 261         |\n",
      "|    value_loss         | 0.41        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 85700       |\n",
      "|    time_elapsed       | 1954        |\n",
      "|    total_timesteps    | 428500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | 0.0226      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 85699       |\n",
      "|    policy_loss        | -12.4       |\n",
      "|    reward             | 0.047915187 |\n",
      "|    std                | 262         |\n",
      "|    value_loss         | 0.875       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 85800      |\n",
      "|    time_elapsed       | 1956       |\n",
      "|    total_timesteps    | 429000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.7      |\n",
      "|    explained_variance | -0.000953  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85799      |\n",
      "|    policy_loss        | -0.0143    |\n",
      "|    reward             | 0.07337338 |\n",
      "|    std                | 267        |\n",
      "|    value_loss         | 0.00163    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 85900       |\n",
      "|    time_elapsed       | 1959        |\n",
      "|    total_timesteps    | 429500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 85899       |\n",
      "|    policy_loss        | -0.0456     |\n",
      "|    reward             | 0.016729927 |\n",
      "|    std                | 269         |\n",
      "|    value_loss         | 0.00175     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 86000      |\n",
      "|    time_elapsed       | 1961       |\n",
      "|    total_timesteps    | 430000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.7      |\n",
      "|    explained_variance | -0.461     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 85999      |\n",
      "|    policy_loss        | -0.785     |\n",
      "|    reward             | 0.05288203 |\n",
      "|    std                | 272        |\n",
      "|    value_loss         | 0.00582    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 86100       |\n",
      "|    time_elapsed       | 1964        |\n",
      "|    total_timesteps    | 430500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0.0547      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 86099       |\n",
      "|    policy_loss        | 2.28        |\n",
      "|    reward             | 0.029573731 |\n",
      "|    std                | 276         |\n",
      "|    value_loss         | 0.062       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 86200       |\n",
      "|    time_elapsed       | 1966        |\n",
      "|    total_timesteps    | 431000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.8       |\n",
      "|    explained_variance | 0.322       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 86199       |\n",
      "|    policy_loss        | 0.817       |\n",
      "|    reward             | 0.027933007 |\n",
      "|    std                | 279         |\n",
      "|    value_loss         | 0.00719     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 219           |\n",
      "|    iterations         | 86300         |\n",
      "|    time_elapsed       | 1969          |\n",
      "|    total_timesteps    | 431500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -13.8         |\n",
      "|    explained_variance | 0.164         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 86299         |\n",
      "|    policy_loss        | -1.23         |\n",
      "|    reward             | -0.0040444843 |\n",
      "|    std                | 283           |\n",
      "|    value_loss         | 0.0113        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 86400        |\n",
      "|    time_elapsed       | 1971         |\n",
      "|    total_timesteps    | 432000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.8        |\n",
      "|    explained_variance | 0.0822       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 86399        |\n",
      "|    policy_loss        | 1.08         |\n",
      "|    reward             | -0.013322573 |\n",
      "|    std                | 288          |\n",
      "|    value_loss         | 0.00752      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 86500       |\n",
      "|    time_elapsed       | 1974        |\n",
      "|    total_timesteps    | 432500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 86499       |\n",
      "|    policy_loss        | -0.0829     |\n",
      "|    reward             | 0.015584448 |\n",
      "|    std                | 295         |\n",
      "|    value_loss         | 0.000875    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 219          |\n",
      "|    iterations         | 86600        |\n",
      "|    time_elapsed       | 1976         |\n",
      "|    total_timesteps    | 433000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -13.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 86599        |\n",
      "|    policy_loss        | 0.119        |\n",
      "|    reward             | -0.018980054 |\n",
      "|    std                | 296          |\n",
      "|    value_loss         | 0.00511      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 219        |\n",
      "|    iterations         | 86700      |\n",
      "|    time_elapsed       | 1979       |\n",
      "|    total_timesteps    | 433500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86699      |\n",
      "|    policy_loss        | 0.189      |\n",
      "|    reward             | 0.18112554 |\n",
      "|    std                | 301        |\n",
      "|    value_loss         | 0.00428    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 219         |\n",
      "|    iterations         | 86800       |\n",
      "|    time_elapsed       | 1981        |\n",
      "|    total_timesteps    | 434000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -13.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 86799       |\n",
      "|    policy_loss        | -0.947      |\n",
      "|    reward             | 0.004885724 |\n",
      "|    std                | 304         |\n",
      "|    value_loss         | 0.0051      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 86900      |\n",
      "|    time_elapsed       | 1984       |\n",
      "|    total_timesteps    | 434500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -13.9      |\n",
      "|    explained_variance | -0.0751    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 86899      |\n",
      "|    policy_loss        | -3.75      |\n",
      "|    reward             | 0.11354445 |\n",
      "|    std                | 306        |\n",
      "|    value_loss         | 0.0886     |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 87000     |\n",
      "|    time_elapsed       | 1986      |\n",
      "|    total_timesteps    | 435000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 86999     |\n",
      "|    policy_loss        | 2.18      |\n",
      "|    reward             | 0.4300392 |\n",
      "|    std                | 314       |\n",
      "|    value_loss         | 0.0498    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 87100        |\n",
      "|    time_elapsed       | 1988         |\n",
      "|    total_timesteps    | 435500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14          |\n",
      "|    explained_variance | 0.0251       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 87099        |\n",
      "|    policy_loss        | 2.58         |\n",
      "|    reward             | -0.005903292 |\n",
      "|    std                | 312          |\n",
      "|    value_loss         | 0.0452       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 87200       |\n",
      "|    time_elapsed       | 1991        |\n",
      "|    total_timesteps    | 436000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | 0.0812      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87199       |\n",
      "|    policy_loss        | 0.861       |\n",
      "|    reward             | -0.12005726 |\n",
      "|    std                | 315         |\n",
      "|    value_loss         | 0.00462     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 87300      |\n",
      "|    time_elapsed       | 1994       |\n",
      "|    total_timesteps    | 436500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 87299      |\n",
      "|    policy_loss        | -0.301     |\n",
      "|    reward             | -6.2928367 |\n",
      "|    std                | 316        |\n",
      "|    value_loss         | 0.0103     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 87400       |\n",
      "|    time_elapsed       | 1996        |\n",
      "|    total_timesteps    | 437000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14         |\n",
      "|    explained_variance | -0.161      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87399       |\n",
      "|    policy_loss        | -0.495      |\n",
      "|    reward             | -0.13168548 |\n",
      "|    std                | 320         |\n",
      "|    value_loss         | 0.00339     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 87500       |\n",
      "|    time_elapsed       | 1998        |\n",
      "|    total_timesteps    | 437500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 8.11e-05    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87499       |\n",
      "|    policy_loss        | -0.0997     |\n",
      "|    reward             | -0.07726465 |\n",
      "|    std                | 324         |\n",
      "|    value_loss         | 0.00252     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 87600     |\n",
      "|    time_elapsed       | 2001      |\n",
      "|    total_timesteps    | 438000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.1     |\n",
      "|    explained_variance | 0.0116    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 87599     |\n",
      "|    policy_loss        | -1.54     |\n",
      "|    reward             | 0.1124689 |\n",
      "|    std                | 326       |\n",
      "|    value_loss         | 0.0215    |\n",
      "-------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 87700        |\n",
      "|    time_elapsed       | 2004         |\n",
      "|    total_timesteps    | 438500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.1        |\n",
      "|    explained_variance | 0.00433      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 87699        |\n",
      "|    policy_loss        | 11.4         |\n",
      "|    reward             | 0.0052053956 |\n",
      "|    std                | 330          |\n",
      "|    value_loss         | 0.784        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 87800       |\n",
      "|    time_elapsed       | 2006        |\n",
      "|    total_timesteps    | 439000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0.126       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87799       |\n",
      "|    policy_loss        | 2.6         |\n",
      "|    reward             | 0.026322495 |\n",
      "|    std                | 332         |\n",
      "|    value_loss         | 0.0511      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 87900       |\n",
      "|    time_elapsed       | 2009        |\n",
      "|    total_timesteps    | 439500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87899       |\n",
      "|    policy_loss        | -0.733      |\n",
      "|    reward             | 0.036380567 |\n",
      "|    std                | 335         |\n",
      "|    value_loss         | 0.00276     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 88000       |\n",
      "|    time_elapsed       | 2011        |\n",
      "|    total_timesteps    | 440000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | -0.48       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 87999       |\n",
      "|    policy_loss        | 0.794       |\n",
      "|    reward             | -0.08444612 |\n",
      "|    std                | 340         |\n",
      "|    value_loss         | 0.00513     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 88100       |\n",
      "|    time_elapsed       | 2014        |\n",
      "|    total_timesteps    | 440500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88099       |\n",
      "|    policy_loss        | 0.236       |\n",
      "|    reward             | 0.026601197 |\n",
      "|    std                | 340         |\n",
      "|    value_loss         | 0.00385     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 218            |\n",
      "|    iterations         | 88200          |\n",
      "|    time_elapsed       | 2016           |\n",
      "|    total_timesteps    | 441000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -14.2          |\n",
      "|    explained_variance | -0.418         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 88199          |\n",
      "|    policy_loss        | -0.542         |\n",
      "|    reward             | -0.00065444334 |\n",
      "|    std                | 343            |\n",
      "|    value_loss         | 0.00364        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 88300       |\n",
      "|    time_elapsed       | 2019        |\n",
      "|    total_timesteps    | 441500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | 0.0131      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88299       |\n",
      "|    policy_loss        | -0.592      |\n",
      "|    reward             | 0.013220068 |\n",
      "|    std                | 347         |\n",
      "|    value_loss         | 0.00332     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 88400      |\n",
      "|    time_elapsed       | 2021       |\n",
      "|    total_timesteps    | 442000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.2      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88399      |\n",
      "|    policy_loss        | -1.39      |\n",
      "|    reward             | 0.05658347 |\n",
      "|    std                | 352        |\n",
      "|    value_loss         | 0.0125     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 88500       |\n",
      "|    time_elapsed       | 2024        |\n",
      "|    total_timesteps    | 442500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | -0.48       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88499       |\n",
      "|    policy_loss        | 3.27        |\n",
      "|    reward             | 0.024267675 |\n",
      "|    std                | 352         |\n",
      "|    value_loss         | 0.0596      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 218      |\n",
      "|    iterations         | 88600    |\n",
      "|    time_elapsed       | 2026     |\n",
      "|    total_timesteps    | 443000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.2    |\n",
      "|    explained_variance | -0.201   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 88599    |\n",
      "|    policy_loss        | 0.563    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 351      |\n",
      "|    value_loss         | 0.0124   |\n",
      "------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 88700       |\n",
      "|    time_elapsed       | 2029        |\n",
      "|    total_timesteps    | 443500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.2       |\n",
      "|    explained_variance | -0.449      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 88699       |\n",
      "|    policy_loss        | 0.471       |\n",
      "|    reward             | 0.048781943 |\n",
      "|    std                | 358         |\n",
      "|    value_loss         | 0.00465     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 88800        |\n",
      "|    time_elapsed       | 2031         |\n",
      "|    total_timesteps    | 444000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 88799        |\n",
      "|    policy_loss        | 0.129        |\n",
      "|    reward             | -0.004690632 |\n",
      "|    std                | 361          |\n",
      "|    value_loss         | 0.00194      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 88900      |\n",
      "|    time_elapsed       | 2034       |\n",
      "|    total_timesteps    | 444500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 88899      |\n",
      "|    policy_loss        | 3.01       |\n",
      "|    reward             | 0.21914579 |\n",
      "|    std                | 368        |\n",
      "|    value_loss         | 0.065      |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 89000        |\n",
      "|    time_elapsed       | 2036         |\n",
      "|    total_timesteps    | 445000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.3        |\n",
      "|    explained_variance | -2.41        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 88999        |\n",
      "|    policy_loss        | -0.721       |\n",
      "|    reward             | -0.068700925 |\n",
      "|    std                | 374          |\n",
      "|    value_loss         | 0.00382      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 89100       |\n",
      "|    time_elapsed       | 2039        |\n",
      "|    total_timesteps    | 445500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.3       |\n",
      "|    explained_variance | 0.0934      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89099       |\n",
      "|    policy_loss        | -2.4        |\n",
      "|    reward             | 0.008261109 |\n",
      "|    std                | 381         |\n",
      "|    value_loss         | 0.0363      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 89200       |\n",
      "|    time_elapsed       | 2041        |\n",
      "|    total_timesteps    | 446000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | 0.0339      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89199       |\n",
      "|    policy_loss        | -1.31       |\n",
      "|    reward             | 0.095886156 |\n",
      "|    std                | 385         |\n",
      "|    value_loss         | 0.0118      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 89300       |\n",
      "|    time_elapsed       | 2043        |\n",
      "|    total_timesteps    | 446500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89299       |\n",
      "|    policy_loss        | -0.0645     |\n",
      "|    reward             | 0.041279443 |\n",
      "|    std                | 389         |\n",
      "|    value_loss         | 0.000313    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 89400        |\n",
      "|    time_elapsed       | 2046         |\n",
      "|    total_timesteps    | 447000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.4        |\n",
      "|    explained_variance | -0.0176      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 89399        |\n",
      "|    policy_loss        | 0.523        |\n",
      "|    reward             | -0.061660327 |\n",
      "|    std                | 394          |\n",
      "|    value_loss         | 0.00242      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 218           |\n",
      "|    iterations         | 89500         |\n",
      "|    time_elapsed       | 2049          |\n",
      "|    total_timesteps    | 447500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 89499         |\n",
      "|    policy_loss        | -0.558        |\n",
      "|    reward             | -0.0006687012 |\n",
      "|    std                | 404           |\n",
      "|    value_loss         | 0.00295       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 218           |\n",
      "|    iterations         | 89600         |\n",
      "|    time_elapsed       | 2051          |\n",
      "|    total_timesteps    | 448000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 89599         |\n",
      "|    policy_loss        | 1.62          |\n",
      "|    reward             | -0.0039646947 |\n",
      "|    std                | 406           |\n",
      "|    value_loss         | 0.0138        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 89700       |\n",
      "|    time_elapsed       | 2053        |\n",
      "|    total_timesteps    | 448500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89699       |\n",
      "|    policy_loss        | 0.659       |\n",
      "|    reward             | -0.04522334 |\n",
      "|    std                | 410         |\n",
      "|    value_loss         | 0.00381     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 89800       |\n",
      "|    time_elapsed       | 2056        |\n",
      "|    total_timesteps    | 449000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | -0.535      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89799       |\n",
      "|    policy_loss        | 0.905       |\n",
      "|    reward             | -0.03986067 |\n",
      "|    std                | 411         |\n",
      "|    value_loss         | 0.00631     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 89900       |\n",
      "|    time_elapsed       | 2058        |\n",
      "|    total_timesteps    | 449500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 89899       |\n",
      "|    policy_loss        | -0.654      |\n",
      "|    reward             | 0.026064113 |\n",
      "|    std                | 416         |\n",
      "|    value_loss         | 0.00851     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 90000        |\n",
      "|    time_elapsed       | 2061         |\n",
      "|    total_timesteps    | 450000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 89999        |\n",
      "|    policy_loss        | -0.399       |\n",
      "|    reward             | -0.026615089 |\n",
      "|    std                | 419          |\n",
      "|    value_loss         | 0.00239      |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 218      |\n",
      "|    iterations         | 90100    |\n",
      "|    time_elapsed       | 2063     |\n",
      "|    total_timesteps    | 450500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.5    |\n",
      "|    explained_variance | 0.00212  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 90099    |\n",
      "|    policy_loss        | -0.28    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 424      |\n",
      "|    value_loss         | 0.0193   |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 90200        |\n",
      "|    time_elapsed       | 2066         |\n",
      "|    total_timesteps    | 451000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | -0.00106     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 90199        |\n",
      "|    policy_loss        | 2.26         |\n",
      "|    reward             | -0.031203162 |\n",
      "|    std                | 431          |\n",
      "|    value_loss         | 0.0748       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 90300        |\n",
      "|    time_elapsed       | 2068         |\n",
      "|    total_timesteps    | 451500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.6        |\n",
      "|    explained_variance | -0.0788      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 90299        |\n",
      "|    policy_loss        | -0.38        |\n",
      "|    reward             | -0.080010906 |\n",
      "|    std                | 435          |\n",
      "|    value_loss         | 0.00106      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 218           |\n",
      "|    iterations         | 90400         |\n",
      "|    time_elapsed       | 2071          |\n",
      "|    total_timesteps    | 452000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 90399         |\n",
      "|    policy_loss        | 0.721         |\n",
      "|    reward             | -0.0077874023 |\n",
      "|    std                | 441           |\n",
      "|    value_loss         | 0.00393       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 218        |\n",
      "|    iterations         | 90500      |\n",
      "|    time_elapsed       | 2073       |\n",
      "|    total_timesteps    | 452500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 90499      |\n",
      "|    policy_loss        | 0.272      |\n",
      "|    reward             | 0.11723739 |\n",
      "|    std                | 445        |\n",
      "|    value_loss         | 0.00452    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 90600       |\n",
      "|    time_elapsed       | 2076        |\n",
      "|    total_timesteps    | 453000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 90599       |\n",
      "|    policy_loss        | 0.314       |\n",
      "|    reward             | -0.14997393 |\n",
      "|    std                | 447         |\n",
      "|    value_loss         | 0.0238      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 218         |\n",
      "|    iterations         | 90700       |\n",
      "|    time_elapsed       | 2079        |\n",
      "|    total_timesteps    | 453500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.7       |\n",
      "|    explained_variance | 0.0409      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 90699       |\n",
      "|    policy_loss        | -3.15       |\n",
      "|    reward             | 0.019991064 |\n",
      "|    std                | 449         |\n",
      "|    value_loss         | 0.0512      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 90800        |\n",
      "|    time_elapsed       | 2081         |\n",
      "|    total_timesteps    | 454000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0.0623       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 90799        |\n",
      "|    policy_loss        | 0.711        |\n",
      "|    reward             | 0.0025442627 |\n",
      "|    std                | 458          |\n",
      "|    value_loss         | 0.00458      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 90900        |\n",
      "|    time_elapsed       | 2084         |\n",
      "|    total_timesteps    | 454500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 90899        |\n",
      "|    policy_loss        | 1.73         |\n",
      "|    reward             | -0.005896044 |\n",
      "|    std                | 460          |\n",
      "|    value_loss         | 0.0168       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 218          |\n",
      "|    iterations         | 91000        |\n",
      "|    time_elapsed       | 2086         |\n",
      "|    total_timesteps    | 455000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 90999        |\n",
      "|    policy_loss        | 1.33         |\n",
      "|    reward             | -0.015071534 |\n",
      "|    std                | 468          |\n",
      "|    value_loss         | 0.013        |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 218      |\n",
      "|    iterations         | 91100    |\n",
      "|    time_elapsed       | 2089     |\n",
      "|    total_timesteps    | 455500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.8    |\n",
      "|    explained_variance | 0.0953   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 91099    |\n",
      "|    policy_loss        | -1.48    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 476      |\n",
      "|    value_loss         | 0.0119   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 218       |\n",
      "|    iterations         | 91200     |\n",
      "|    time_elapsed       | 2091      |\n",
      "|    total_timesteps    | 456000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91199     |\n",
      "|    policy_loss        | -3.25     |\n",
      "|    reward             | 0.1084313 |\n",
      "|    std                | 477       |\n",
      "|    value_loss         | 0.051     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 91300      |\n",
      "|    time_elapsed       | 2094       |\n",
      "|    total_timesteps    | 456500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.8      |\n",
      "|    explained_variance | -0.377     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 91299      |\n",
      "|    policy_loss        | 2.17       |\n",
      "|    reward             | 0.03157135 |\n",
      "|    std                | 482        |\n",
      "|    value_loss         | 0.0206     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 91400        |\n",
      "|    time_elapsed       | 2096         |\n",
      "|    total_timesteps    | 457000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -14.8        |\n",
      "|    explained_variance | -0.0285      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 91399        |\n",
      "|    policy_loss        | 0.558        |\n",
      "|    reward             | 0.0054678814 |\n",
      "|    std                | 483          |\n",
      "|    value_loss         | 0.00319      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 91500       |\n",
      "|    time_elapsed       | 2098        |\n",
      "|    total_timesteps    | 457500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.8       |\n",
      "|    explained_variance | 0.432       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91499       |\n",
      "|    policy_loss        | 0.399       |\n",
      "|    reward             | 0.045542378 |\n",
      "|    std                | 487         |\n",
      "|    value_loss         | 0.00208     |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 217       |\n",
      "|    iterations         | 91600     |\n",
      "|    time_elapsed       | 2101      |\n",
      "|    total_timesteps    | 458000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.9     |\n",
      "|    explained_variance | -0.0419   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 91599     |\n",
      "|    policy_loss        | 3.04      |\n",
      "|    reward             | 0.1501188 |\n",
      "|    std                | 495       |\n",
      "|    value_loss         | 0.0628    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 91700      |\n",
      "|    time_elapsed       | 2103       |\n",
      "|    total_timesteps    | 458500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -14.9      |\n",
      "|    explained_variance | -0.0138    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 91699      |\n",
      "|    policy_loss        | -6.69      |\n",
      "|    reward             | 0.40261024 |\n",
      "|    std                | 501        |\n",
      "|    value_loss         | 0.27       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 91800       |\n",
      "|    time_elapsed       | 2105        |\n",
      "|    total_timesteps    | 459000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91799       |\n",
      "|    policy_loss        | 3.46        |\n",
      "|    reward             | -0.03009518 |\n",
      "|    std                | 505         |\n",
      "|    value_loss         | 0.112       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 91900       |\n",
      "|    time_elapsed       | 2108        |\n",
      "|    total_timesteps    | 459500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -14.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 91899       |\n",
      "|    policy_loss        | 1.34        |\n",
      "|    reward             | 0.065923005 |\n",
      "|    std                | 513         |\n",
      "|    value_loss         | 0.0119      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 92000         |\n",
      "|    time_elapsed       | 2110          |\n",
      "|    total_timesteps    | 460000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -14.9         |\n",
      "|    explained_variance | -0.115        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 91999         |\n",
      "|    policy_loss        | 1.42          |\n",
      "|    reward             | -0.0048415153 |\n",
      "|    std                | 518           |\n",
      "|    value_loss         | 0.0104        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 92100       |\n",
      "|    time_elapsed       | 2112        |\n",
      "|    total_timesteps    | 460500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 92099       |\n",
      "|    policy_loss        | -4.21       |\n",
      "|    reward             | -0.23743306 |\n",
      "|    std                | 523         |\n",
      "|    value_loss         | 0.105       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 92200      |\n",
      "|    time_elapsed       | 2115       |\n",
      "|    total_timesteps    | 461000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15        |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 92199      |\n",
      "|    policy_loss        | 1.78       |\n",
      "|    reward             | 0.06464881 |\n",
      "|    std                | 537        |\n",
      "|    value_loss         | 0.0233     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 92300         |\n",
      "|    time_elapsed       | 2117          |\n",
      "|    total_timesteps    | 461500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 92299         |\n",
      "|    policy_loss        | -2.01         |\n",
      "|    reward             | -0.0027638527 |\n",
      "|    std                | 538           |\n",
      "|    value_loss         | 0.0187        |\n",
      "-----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 217      |\n",
      "|    iterations         | 92400    |\n",
      "|    time_elapsed       | 2119     |\n",
      "|    total_timesteps    | 462000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15      |\n",
      "|    explained_variance | -0.0613  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 92399    |\n",
      "|    policy_loss        | -0.431   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 546      |\n",
      "|    value_loss         | 0.00114  |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 92500        |\n",
      "|    time_elapsed       | 2122         |\n",
      "|    total_timesteps    | 462500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | -0.374       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 92499        |\n",
      "|    policy_loss        | 1.8          |\n",
      "|    reward             | -0.015623975 |\n",
      "|    std                | 553          |\n",
      "|    value_loss         | 0.0221       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 92600        |\n",
      "|    time_elapsed       | 2124         |\n",
      "|    total_timesteps    | 463000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.1        |\n",
      "|    explained_variance | -1.27        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 92599        |\n",
      "|    policy_loss        | -0.0687      |\n",
      "|    reward             | -0.026605347 |\n",
      "|    std                | 557          |\n",
      "|    value_loss         | 0.00242      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 92700       |\n",
      "|    time_elapsed       | 2127        |\n",
      "|    total_timesteps    | 463500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.1       |\n",
      "|    explained_variance | -0.917      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 92699       |\n",
      "|    policy_loss        | -0.797      |\n",
      "|    reward             | -0.00281573 |\n",
      "|    std                | 558         |\n",
      "|    value_loss         | 0.00294     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 92800      |\n",
      "|    time_elapsed       | 2129       |\n",
      "|    total_timesteps    | 464000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.1      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 92799      |\n",
      "|    policy_loss        | -0.377     |\n",
      "|    reward             | 0.05726294 |\n",
      "|    std                | 568        |\n",
      "|    value_loss         | 0.00274    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 92900        |\n",
      "|    time_elapsed       | 2131         |\n",
      "|    total_timesteps    | 464500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0.162        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 92899        |\n",
      "|    policy_loss        | -0.603       |\n",
      "|    reward             | -0.040225428 |\n",
      "|    std                | 578          |\n",
      "|    value_loss         | 0.00354      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 93000       |\n",
      "|    time_elapsed       | 2134        |\n",
      "|    total_timesteps    | 465000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | -0.0414     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 92999       |\n",
      "|    policy_loss        | 0.856       |\n",
      "|    reward             | 0.002256201 |\n",
      "|    std                | 589         |\n",
      "|    value_loss         | 0.0161      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 93100       |\n",
      "|    time_elapsed       | 2136        |\n",
      "|    total_timesteps    | 465500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93099       |\n",
      "|    policy_loss        | -2.91       |\n",
      "|    reward             | -0.20306818 |\n",
      "|    std                | 593         |\n",
      "|    value_loss         | 0.0518      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 93200         |\n",
      "|    time_elapsed       | 2139          |\n",
      "|    total_timesteps    | 466000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.2         |\n",
      "|    explained_variance | -0.00855      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 93199         |\n",
      "|    policy_loss        | 2.41          |\n",
      "|    reward             | -0.0036112033 |\n",
      "|    std                | 596           |\n",
      "|    value_loss         | 0.0291        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 93300       |\n",
      "|    time_elapsed       | 2141        |\n",
      "|    total_timesteps    | 466500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.2       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93299       |\n",
      "|    policy_loss        | -2.44       |\n",
      "|    reward             | -0.08460733 |\n",
      "|    std                | 599         |\n",
      "|    value_loss         | 0.0291      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 93400        |\n",
      "|    time_elapsed       | 2143         |\n",
      "|    total_timesteps    | 467000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.2        |\n",
      "|    explained_variance | 0.0977       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 93399        |\n",
      "|    policy_loss        | 5.93         |\n",
      "|    reward             | -0.010979934 |\n",
      "|    std                | 602          |\n",
      "|    value_loss         | 0.19         |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 93500      |\n",
      "|    time_elapsed       | 2145       |\n",
      "|    total_timesteps    | 467500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.2      |\n",
      "|    explained_variance | -1.34      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93499      |\n",
      "|    policy_loss        | -1.23      |\n",
      "|    reward             | 0.03680664 |\n",
      "|    std                | 598        |\n",
      "|    value_loss         | 0.0166     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 93600      |\n",
      "|    time_elapsed       | 2148       |\n",
      "|    total_timesteps    | 468000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.3      |\n",
      "|    explained_variance | 0.112      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93599      |\n",
      "|    policy_loss        | -1.74      |\n",
      "|    reward             | 0.12870201 |\n",
      "|    std                | 605        |\n",
      "|    value_loss         | 0.0147     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 93700        |\n",
      "|    time_elapsed       | 2150         |\n",
      "|    total_timesteps    | 468500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.3        |\n",
      "|    explained_variance | 0.169        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 93699        |\n",
      "|    policy_loss        | -10.1        |\n",
      "|    reward             | -0.010662942 |\n",
      "|    std                | 613          |\n",
      "|    value_loss         | 0.454        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 93800       |\n",
      "|    time_elapsed       | 2153        |\n",
      "|    total_timesteps    | 469000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.3       |\n",
      "|    explained_variance | -0.0751     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 93799       |\n",
      "|    policy_loss        | -1.1        |\n",
      "|    reward             | -0.06692207 |\n",
      "|    std                | 616         |\n",
      "|    value_loss         | 0.0135      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 93900         |\n",
      "|    time_elapsed       | 2155          |\n",
      "|    total_timesteps    | 469500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.3         |\n",
      "|    explained_variance | -0.0417       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 93899         |\n",
      "|    policy_loss        | -7.73         |\n",
      "|    reward             | -0.0072286665 |\n",
      "|    std                | 627           |\n",
      "|    value_loss         | 0.29          |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 94000      |\n",
      "|    time_elapsed       | 2157       |\n",
      "|    total_timesteps    | 470000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 93999      |\n",
      "|    policy_loss        | 0.14       |\n",
      "|    reward             | -0.1366055 |\n",
      "|    std                | 632        |\n",
      "|    value_loss         | 0.00255    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "day: 888, episode: 530\n",
      "begin_total_asset: 100000.00\n",
      "end_total_asset: 148817.49\n",
      "total_reward: 48817.49\n",
      "total_cost: 63143.07\n",
      "total_trades: 1329\n",
      "Sharpe: 0.512\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 94100        |\n",
      "|    time_elapsed       | 2160         |\n",
      "|    total_timesteps    | 470500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 94099        |\n",
      "|    policy_loss        | 1.98         |\n",
      "|    reward             | -0.017661208 |\n",
      "|    std                | 632          |\n",
      "|    value_loss         | 0.029        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 94200         |\n",
      "|    time_elapsed       | 2162          |\n",
      "|    total_timesteps    | 471000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.4         |\n",
      "|    explained_variance | -0.598        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 94199         |\n",
      "|    policy_loss        | 0.694         |\n",
      "|    reward             | -0.0050488794 |\n",
      "|    std                | 638           |\n",
      "|    value_loss         | 0.00228       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 94300        |\n",
      "|    time_elapsed       | 2165         |\n",
      "|    total_timesteps    | 471500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 94299        |\n",
      "|    policy_loss        | 0.846        |\n",
      "|    reward             | -0.009825711 |\n",
      "|    std                | 646          |\n",
      "|    value_loss         | 0.00426      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 94400        |\n",
      "|    time_elapsed       | 2167         |\n",
      "|    total_timesteps    | 472000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 94399        |\n",
      "|    policy_loss        | 0.324        |\n",
      "|    reward             | -0.051909864 |\n",
      "|    std                | 655          |\n",
      "|    value_loss         | 0.000793     |\n",
      "----------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 217      |\n",
      "|    iterations         | 94500    |\n",
      "|    time_elapsed       | 2169     |\n",
      "|    total_timesteps    | 472500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.5    |\n",
      "|    explained_variance | -0.43    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 94499    |\n",
      "|    policy_loss        | -0.389   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 671      |\n",
      "|    value_loss         | 0.00308  |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 94600         |\n",
      "|    time_elapsed       | 2171          |\n",
      "|    total_timesteps    | 473000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.5         |\n",
      "|    explained_variance | 0.00332       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 94599         |\n",
      "|    policy_loss        | -0.481        |\n",
      "|    reward             | -0.0037588486 |\n",
      "|    std                | 683           |\n",
      "|    value_loss         | 0.00153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 94700         |\n",
      "|    time_elapsed       | 2174          |\n",
      "|    total_timesteps    | 473500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.5         |\n",
      "|    explained_variance | -0.0225       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 94699         |\n",
      "|    policy_loss        | -2.64         |\n",
      "|    reward             | -0.0059112785 |\n",
      "|    std                | 694           |\n",
      "|    value_loss         | 0.0335        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 94800       |\n",
      "|    time_elapsed       | 2176        |\n",
      "|    total_timesteps    | 474000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0.0407      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94799       |\n",
      "|    policy_loss        | 0.93        |\n",
      "|    reward             | -0.08264289 |\n",
      "|    std                | 703         |\n",
      "|    value_loss         | 0.00545     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 94900       |\n",
      "|    time_elapsed       | 2179        |\n",
      "|    total_timesteps    | 474500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.6       |\n",
      "|    explained_variance | 0.166       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 94899       |\n",
      "|    policy_loss        | 1.03        |\n",
      "|    reward             | 0.045197852 |\n",
      "|    std                | 715         |\n",
      "|    value_loss         | 0.00788     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 95000        |\n",
      "|    time_elapsed       | 2181         |\n",
      "|    total_timesteps    | 475000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | 0.0152       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 94999        |\n",
      "|    policy_loss        | -6.09        |\n",
      "|    reward             | 0.0019415778 |\n",
      "|    std                | 723          |\n",
      "|    value_loss         | 0.524        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 95100        |\n",
      "|    time_elapsed       | 2183         |\n",
      "|    total_timesteps    | 475500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.6        |\n",
      "|    explained_variance | -0.00206     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 95099        |\n",
      "|    policy_loss        | -2.63        |\n",
      "|    reward             | -0.038885497 |\n",
      "|    std                | 729          |\n",
      "|    value_loss         | 0.0786       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 95200      |\n",
      "|    time_elapsed       | 2186       |\n",
      "|    total_timesteps    | 476000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.6      |\n",
      "|    explained_variance | -0.073     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95199      |\n",
      "|    policy_loss        | -0.567     |\n",
      "|    reward             | 0.10219427 |\n",
      "|    std                | 740        |\n",
      "|    value_loss         | 0.00313    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 95300         |\n",
      "|    time_elapsed       | 2188          |\n",
      "|    total_timesteps    | 476500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -15.7         |\n",
      "|    explained_variance | -0.0112       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 95299         |\n",
      "|    policy_loss        | -2.03         |\n",
      "|    reward             | -0.0074782115 |\n",
      "|    std                | 743           |\n",
      "|    value_loss         | 0.028         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 95400       |\n",
      "|    time_elapsed       | 2190        |\n",
      "|    total_timesteps    | 477000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0.104       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95399       |\n",
      "|    policy_loss        | -4.35       |\n",
      "|    reward             | 0.046969995 |\n",
      "|    std                | 750         |\n",
      "|    value_loss         | 0.0807      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 95500      |\n",
      "|    time_elapsed       | 2193       |\n",
      "|    total_timesteps    | 477500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.7      |\n",
      "|    explained_variance | -0.23      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95499      |\n",
      "|    policy_loss        | 3.52       |\n",
      "|    reward             | -0.1237547 |\n",
      "|    std                | 758        |\n",
      "|    value_loss         | 0.0692     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 95600       |\n",
      "|    time_elapsed       | 2195        |\n",
      "|    total_timesteps    | 478000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | -1.17       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95599       |\n",
      "|    policy_loss        | -0.127      |\n",
      "|    reward             | -0.11586257 |\n",
      "|    std                | 772         |\n",
      "|    value_loss         | 0.00358     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 95700      |\n",
      "|    time_elapsed       | 2198       |\n",
      "|    total_timesteps    | 478500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -15.7      |\n",
      "|    explained_variance | -0.157     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 95699      |\n",
      "|    policy_loss        | 5.76       |\n",
      "|    reward             | 0.15017685 |\n",
      "|    std                | 775        |\n",
      "|    value_loss         | 0.179      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 95800       |\n",
      "|    time_elapsed       | 2200        |\n",
      "|    total_timesteps    | 479000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.7       |\n",
      "|    explained_variance | 0.0187      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 95799       |\n",
      "|    policy_loss        | -1.85       |\n",
      "|    reward             | -0.05674815 |\n",
      "|    std                | 778         |\n",
      "|    value_loss         | 0.0214      |\n",
      "---------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 217      |\n",
      "|    iterations         | 95900    |\n",
      "|    time_elapsed       | 2202     |\n",
      "|    total_timesteps    | 479500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 95899    |\n",
      "|    policy_loss        | -0.062   |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 786      |\n",
      "|    value_loss         | 0.000405 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 217      |\n",
      "|    iterations         | 96000    |\n",
      "|    time_elapsed       | 2205     |\n",
      "|    total_timesteps    | 480000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.8    |\n",
      "|    explained_variance | -0.00525 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 95999    |\n",
      "|    policy_loss        | 2.09     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 799      |\n",
      "|    value_loss         | 0.0256   |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 96100        |\n",
      "|    time_elapsed       | 2207         |\n",
      "|    total_timesteps    | 480500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | -1.94        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96099        |\n",
      "|    policy_loss        | -0.451       |\n",
      "|    reward             | -0.016248047 |\n",
      "|    std                | 805          |\n",
      "|    value_loss         | 0.00136      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 96200        |\n",
      "|    time_elapsed       | 2209         |\n",
      "|    total_timesteps    | 481000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | 0.00899      |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96199        |\n",
      "|    policy_loss        | 0.801        |\n",
      "|    reward             | -0.115546025 |\n",
      "|    std                | 809          |\n",
      "|    value_loss         | 0.00533      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 96300        |\n",
      "|    time_elapsed       | 2212         |\n",
      "|    total_timesteps    | 481500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.8        |\n",
      "|    explained_variance | 0.0142       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96299        |\n",
      "|    policy_loss        | -2.13        |\n",
      "|    reward             | -0.120386325 |\n",
      "|    std                | 816          |\n",
      "|    value_loss         | 0.0211       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 96400        |\n",
      "|    time_elapsed       | 2214         |\n",
      "|    total_timesteps    | 482000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96399        |\n",
      "|    policy_loss        | 2.14         |\n",
      "|    reward             | -0.003835294 |\n",
      "|    std                | 828          |\n",
      "|    value_loss         | 0.0188       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 96500       |\n",
      "|    time_elapsed       | 2216        |\n",
      "|    total_timesteps    | 482500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | -0.116      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 96499       |\n",
      "|    policy_loss        | -0.582      |\n",
      "|    reward             | -0.07325459 |\n",
      "|    std                | 841         |\n",
      "|    value_loss         | 0.00256     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 96600       |\n",
      "|    time_elapsed       | 2219        |\n",
      "|    total_timesteps    | 483000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -15.9       |\n",
      "|    explained_variance | 0.0595      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 96599       |\n",
      "|    policy_loss        | -2.74       |\n",
      "|    reward             | 0.029880859 |\n",
      "|    std                | 851         |\n",
      "|    value_loss         | 0.0438      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 96700        |\n",
      "|    time_elapsed       | 2221         |\n",
      "|    total_timesteps    | 483500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -15.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 96699        |\n",
      "|    policy_loss        | -0.0553      |\n",
      "|    reward             | -0.105269976 |\n",
      "|    std                | 864          |\n",
      "|    value_loss         | 0.00607      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 96800      |\n",
      "|    time_elapsed       | 2224       |\n",
      "|    total_timesteps    | 484000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16        |\n",
      "|    explained_variance | 0.021      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 96799      |\n",
      "|    policy_loss        | -0.0646    |\n",
      "|    reward             | 0.07242422 |\n",
      "|    std                | 873        |\n",
      "|    value_loss         | 0.00806    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 96900         |\n",
      "|    time_elapsed       | 2226          |\n",
      "|    total_timesteps    | 484500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16           |\n",
      "|    explained_variance | -0.04         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 96899         |\n",
      "|    policy_loss        | 1.29          |\n",
      "|    reward             | -0.0048095393 |\n",
      "|    std                | 882           |\n",
      "|    value_loss         | 0.0112        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 97000       |\n",
      "|    time_elapsed       | 2228        |\n",
      "|    total_timesteps    | 485000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16         |\n",
      "|    explained_variance | -10.1       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 96999       |\n",
      "|    policy_loss        | -0.102      |\n",
      "|    reward             | 0.012572852 |\n",
      "|    std                | 886         |\n",
      "|    value_loss         | 0.000849    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 97100         |\n",
      "|    time_elapsed       | 2231          |\n",
      "|    total_timesteps    | 485500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.1         |\n",
      "|    explained_variance | 0.0334        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 97099         |\n",
      "|    policy_loss        | -1.57         |\n",
      "|    reward             | -0.0040324316 |\n",
      "|    std                | 905           |\n",
      "|    value_loss         | 0.0133        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 97200       |\n",
      "|    time_elapsed       | 2233        |\n",
      "|    total_timesteps    | 486000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.1       |\n",
      "|    explained_variance | -3.43       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97199       |\n",
      "|    policy_loss        | 0.202       |\n",
      "|    reward             | 0.016822288 |\n",
      "|    std                | 920         |\n",
      "|    value_loss         | 0.000427    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 97300      |\n",
      "|    time_elapsed       | 2235       |\n",
      "|    total_timesteps    | 486500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 97299      |\n",
      "|    policy_loss        | 1.66       |\n",
      "|    reward             | 0.03524109 |\n",
      "|    std                | 936        |\n",
      "|    value_loss         | 0.0124     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 97400        |\n",
      "|    time_elapsed       | 2238         |\n",
      "|    total_timesteps    | 487000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 97399        |\n",
      "|    policy_loss        | -0.0815      |\n",
      "|    reward             | -0.014668006 |\n",
      "|    std                | 945          |\n",
      "|    value_loss         | 0.00187      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 97500        |\n",
      "|    time_elapsed       | 2240         |\n",
      "|    total_timesteps    | 487500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 97499        |\n",
      "|    policy_loss        | -2.34        |\n",
      "|    reward             | -0.064405516 |\n",
      "|    std                | 956          |\n",
      "|    value_loss         | 0.0353       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 97600      |\n",
      "|    time_elapsed       | 2242       |\n",
      "|    total_timesteps    | 488000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 97599      |\n",
      "|    policy_loss        | -1.36      |\n",
      "|    reward             | 0.14834699 |\n",
      "|    std                | 964        |\n",
      "|    value_loss         | 0.0141     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 97700        |\n",
      "|    time_elapsed       | 2245         |\n",
      "|    total_timesteps    | 488500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 97699        |\n",
      "|    policy_loss        | 0.503        |\n",
      "|    reward             | -0.052945312 |\n",
      "|    std                | 990          |\n",
      "|    value_loss         | 0.00438      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 97800      |\n",
      "|    time_elapsed       | 2247       |\n",
      "|    total_timesteps    | 489000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.2      |\n",
      "|    explained_variance | -0.531     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 97799      |\n",
      "|    policy_loss        | 0.917      |\n",
      "|    reward             | 0.03540796 |\n",
      "|    std                | 995        |\n",
      "|    value_loss         | 0.00324    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 97900         |\n",
      "|    time_elapsed       | 2249          |\n",
      "|    total_timesteps    | 489500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.3         |\n",
      "|    explained_variance | -0.00323      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 97899         |\n",
      "|    policy_loss        | -0.147        |\n",
      "|    reward             | -0.0019804265 |\n",
      "|    std                | 1e+03         |\n",
      "|    value_loss         | 0.000261      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 98000       |\n",
      "|    time_elapsed       | 2252        |\n",
      "|    total_timesteps    | 490000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 97999       |\n",
      "|    policy_loss        | 3.4         |\n",
      "|    reward             | -0.01725194 |\n",
      "|    std                | 1.02e+03    |\n",
      "|    value_loss         | 0.0584      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 98100      |\n",
      "|    time_elapsed       | 2254       |\n",
      "|    total_timesteps    | 490500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.3      |\n",
      "|    explained_variance | -0.0739    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98099      |\n",
      "|    policy_loss        | 0.191      |\n",
      "|    reward             | 0.19116974 |\n",
      "|    std                | 1.03e+03   |\n",
      "|    value_loss         | 0.00298    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 98200      |\n",
      "|    time_elapsed       | 2257       |\n",
      "|    total_timesteps    | 491000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98199      |\n",
      "|    policy_loss        | -2.5       |\n",
      "|    reward             | 0.22580133 |\n",
      "|    std                | 1.05e+03   |\n",
      "|    value_loss         | 0.0399     |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 217      |\n",
      "|    iterations         | 98300    |\n",
      "|    time_elapsed       | 2259     |\n",
      "|    total_timesteps    | 491500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0892  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 98299    |\n",
      "|    policy_loss        | -2.24    |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.05e+03 |\n",
      "|    value_loss         | 0.0209   |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 98400        |\n",
      "|    time_elapsed       | 2261         |\n",
      "|    total_timesteps    | 492000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | 0.0689       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 98399        |\n",
      "|    policy_loss        | -0.182       |\n",
      "|    reward             | -0.012210234 |\n",
      "|    std                | 1.06e+03     |\n",
      "|    value_loss         | 0.00537      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 98500        |\n",
      "|    time_elapsed       | 2264         |\n",
      "|    total_timesteps    | 492500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | 0.179        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 98499        |\n",
      "|    policy_loss        | 5.93         |\n",
      "|    reward             | -0.013119152 |\n",
      "|    std                | 1.06e+03     |\n",
      "|    value_loss         | 0.132        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 98600        |\n",
      "|    time_elapsed       | 2267         |\n",
      "|    total_timesteps    | 493000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 98599        |\n",
      "|    policy_loss        | -0.392       |\n",
      "|    reward             | -0.038206566 |\n",
      "|    std                | 1.08e+03     |\n",
      "|    value_loss         | 0.0014       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 98700       |\n",
      "|    time_elapsed       | 2269        |\n",
      "|    total_timesteps    | 493500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.4       |\n",
      "|    explained_variance | -0.177      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 98699       |\n",
      "|    policy_loss        | -1.47       |\n",
      "|    reward             | -0.05755085 |\n",
      "|    std                | 1.09e+03    |\n",
      "|    value_loss         | 0.00898     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 98800         |\n",
      "|    time_elapsed       | 2272          |\n",
      "|    total_timesteps    | 494000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.4         |\n",
      "|    explained_variance | -0.0586       |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 98799         |\n",
      "|    policy_loss        | 0.123         |\n",
      "|    reward             | -0.0029049166 |\n",
      "|    std                | 1.1e+03       |\n",
      "|    value_loss         | 0.000527      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 98900      |\n",
      "|    time_elapsed       | 2274       |\n",
      "|    total_timesteps    | 494500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | -0.0534    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 98899      |\n",
      "|    policy_loss        | 1.13       |\n",
      "|    reward             | 0.05920198 |\n",
      "|    std                | 1.11e+03   |\n",
      "|    value_loss         | 0.00549    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 217           |\n",
      "|    iterations         | 99000         |\n",
      "|    time_elapsed       | 2276          |\n",
      "|    total_timesteps    | 495000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -16.5         |\n",
      "|    explained_variance | -0.199        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 98999         |\n",
      "|    policy_loss        | 1.28          |\n",
      "|    reward             | -0.0055166217 |\n",
      "|    std                | 1.13e+03      |\n",
      "|    value_loss         | 0.0162        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 99100        |\n",
      "|    time_elapsed       | 2279         |\n",
      "|    total_timesteps    | 495500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99099        |\n",
      "|    policy_loss        | 0.0404       |\n",
      "|    reward             | -0.030351782 |\n",
      "|    std                | 1.14e+03     |\n",
      "|    value_loss         | 0.00144      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 99200      |\n",
      "|    time_elapsed       | 2281       |\n",
      "|    total_timesteps    | 496000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.5      |\n",
      "|    explained_variance | 0.0688     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99199      |\n",
      "|    policy_loss        | -1.24      |\n",
      "|    reward             | -0.0692854 |\n",
      "|    std                | 1.16e+03   |\n",
      "|    value_loss         | 0.00609    |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 217      |\n",
      "|    iterations         | 99300    |\n",
      "|    time_elapsed       | 2283     |\n",
      "|    total_timesteps    | 496500   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.6    |\n",
      "|    explained_variance | -0.187   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99299    |\n",
      "|    policy_loss        | 0.79     |\n",
      "|    reward             | 0.0      |\n",
      "|    std                | 1.17e+03 |\n",
      "|    value_loss         | 0.00383  |\n",
      "------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 99400        |\n",
      "|    time_elapsed       | 2286         |\n",
      "|    total_timesteps    | 497000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | -0.271       |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99399        |\n",
      "|    policy_loss        | -0.703       |\n",
      "|    reward             | -0.059459217 |\n",
      "|    std                | 1.19e+03     |\n",
      "|    value_loss         | 0.00312      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 99500        |\n",
      "|    time_elapsed       | 2289         |\n",
      "|    total_timesteps    | 497500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99499        |\n",
      "|    policy_loss        | -0.694       |\n",
      "|    reward             | -0.003937371 |\n",
      "|    std                | 1.2e+03      |\n",
      "|    value_loss         | 0.00364      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 217          |\n",
      "|    iterations         | 99600        |\n",
      "|    time_elapsed       | 2291         |\n",
      "|    total_timesteps    | 498000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -16.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99599        |\n",
      "|    policy_loss        | 1.45         |\n",
      "|    reward             | -0.010377428 |\n",
      "|    std                | 1.21e+03     |\n",
      "|    value_loss         | 0.0127       |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 99700      |\n",
      "|    time_elapsed       | 2293       |\n",
      "|    total_timesteps    | 498500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.7      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99699      |\n",
      "|    policy_loss        | 3.13       |\n",
      "|    reward             | 0.07368928 |\n",
      "|    std                | 1.22e+03   |\n",
      "|    value_loss         | 0.0505     |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 99800       |\n",
      "|    time_elapsed       | 2296        |\n",
      "|    total_timesteps    | 499000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | 0.0658      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99799       |\n",
      "|    policy_loss        | 0.0765      |\n",
      "|    reward             | -0.11215822 |\n",
      "|    std                | 1.24e+03    |\n",
      "|    value_loss         | 0.000695    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 217         |\n",
      "|    iterations         | 99900       |\n",
      "|    time_elapsed       | 2298        |\n",
      "|    total_timesteps    | 499500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -16.7       |\n",
      "|    explained_variance | -0.0164     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99899       |\n",
      "|    policy_loss        | 0.122       |\n",
      "|    reward             | 0.015309814 |\n",
      "|    std                | 1.25e+03    |\n",
      "|    value_loss         | 0.00096     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 217        |\n",
      "|    iterations         | 100000     |\n",
      "|    time_elapsed       | 2301       |\n",
      "|    total_timesteps    | 500000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -16.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99999      |\n",
      "|    policy_loss        | 0.996      |\n",
      "|    reward             | 0.12531789 |\n",
      "|    std                | 1.27e+03   |\n",
      "|    value_loss         | 0.00791    |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "e_train_gym = StockTradingEnv(train, mode=\"train\", model_name=\"a2c\")\n",
    "e_trade_gym = StockTradingEnv(trade, mode=\"trade\", model_name=\"a2c\")\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "agent = DRLAgent(env=env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "trained_a2c = agent.train_model(model=model_a2c, tb_log_name=\"a2c\", total_timesteps=500_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hit end!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-16</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-19</td>\n",
       "      <td>97005.813561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-20</td>\n",
       "      <td>99789.207848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-22</td>\n",
       "      <td>101331.771081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-23</td>\n",
       "      <td>100886.054772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2022-07-12</td>\n",
       "      <td>126748.882653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>126815.405846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2022-07-14</td>\n",
       "      <td>125774.359948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>127541.562096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>130647.053795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  account_value\n",
       "0    2021-04-16  100000.000000\n",
       "1    2021-04-19   97005.813561\n",
       "2    2021-04-20   99789.207848\n",
       "3    2021-04-22  101331.771081\n",
       "4    2021-04-23  100886.054772\n",
       "..          ...            ...\n",
       "308  2022-07-12  126748.882653\n",
       "309  2022-07-13  126815.405846\n",
       "310  2022-07-14  125774.359948\n",
       "311  2022-07-15  127541.562096\n",
       "312  2022-07-18  130647.053795\n",
       "\n",
       "[313 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value_a2c, df_actions_a2c = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, environment=e_trade_gym\n",
    ")\n",
    "df_account_value_a2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actions_a2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_account_value_a2c.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_actions_a2c.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.240147\n",
      "Cumulative returns     0.306471\n",
      "Annual volatility      0.321163\n",
      "Sharpe ratio           0.832694\n",
      "Calmar ratio           0.730631\n",
      "Stability              0.015074\n",
      "Max drawdown          -0.328685\n",
      "Omega ratio            1.161010\n",
      "Sortino ratio          1.221260\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.076047\n",
      "Daily value at risk   -0.039401\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dhruv\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pyfolio\\timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Annual return          0.240147\n",
       "Cumulative returns     0.306471\n",
       "Annual volatility      0.321163\n",
       "Sharpe ratio           0.832694\n",
       "Calmar ratio           0.730631\n",
       "Stability              0.015074\n",
       "Max drawdown          -0.328685\n",
       "Omega ratio            1.161010\n",
       "Sortino ratio          1.221260\n",
       "Skew                        NaN\n",
       "Kurtosis                    NaN\n",
       "Tail ratio             1.076047\n",
       "Daily value at risk   -0.039401\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plot import backtest_stats\n",
    " \n",
    "backtest_stats(df_account_value_a2c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac0f8035830d686df2ddeba5cc2d200fae22f9983559a92bc6af7598820e6e82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
